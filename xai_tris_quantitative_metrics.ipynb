{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5750238f-381e-4838-9279-96a2d244edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot.lp import emd # Needs POT (Python Optimal Transport) library\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from interpret.utils import measure_interactions\n",
    "def FAST(X_train, y_train, n_interactions, init_score=None, feature_names=None, feature_types=None):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    interactions = measure_interactions(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        interactions=n_interactions, \n",
    "        init_score=init_score,  # Can be a model or initial scores; set to None if not used\n",
    "        feature_names = feature_names,\n",
    "        feature_types = feature_types\n",
    "    )\n",
    "    \n",
    "    pairs = []\n",
    "    for (i, j), _ in interactions:\n",
    "        pairs.append((i,j))\n",
    "    return pairs, time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fc5b9f-587c-4f60-ab0a-e4fd454a591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEEDS = [2025]  # Define the seed(s) to process\n",
    "SEEDS = [2025, 1283123, 3043040, 8238238, 123123]\n",
    "SAVE_DIR = \"./models/xai_tris\"  # Directory where models are saved\n",
    "EXPLANATIONS_DIR = \"./explanations/xai_tris\" # Directory to save MLP SHAP/IG .npy files\n",
    "os.makedirs(EXPLANATIONS_DIR, exist_ok=True)\n",
    "# CSV for storing metadata about generated MLP explanations\n",
    "DEVICE_STR = 'cpu' # Use 'cuda:0' or similar if GPU is available and desired\n",
    "\n",
    "seed = SEEDS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c04eef-4a14-4065-a76a-007bb847a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./models/old_xai_tris/explanations.pkl', \"rb\") as f:\n",
    "#     explanations = pkl.load(f)\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09c68a6-fbff-40f7-9404-af2f1ba749a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_3', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_2', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_0', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_1', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_4'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768a42e6-f7f0-4c10-850b-0a65fb58dd6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "D_2D_EDGE (grid edge for main effects): 8\n",
      "D_FLAT (total main effect features): 64\n",
      "Sum of GT_MASK_2D_FLAT: 8\n",
      "Cost matrix for main effects shape: (64, 64)\n",
      "--- Starting Metric Calculation ---\n",
      "\n",
      "--- Aggregated Results ---\n",
      "\n",
      "Scenario Type: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated\n",
      "  Method: pattern_gam\n",
      "    IMA    : Mean = 0.5688, Std = 0.0803\n",
      "    EMD    : Mean = 0.8095, Std = 0.0182\n",
      "    FNI-EMD: Mean = 0.8196, Std = 0.0202\n",
      "  Method: pattern_qlr\n",
      "    IMA    : Mean = 0.2278, Std = 0.0385\n",
      "    EMD    : Mean = 0.7832, Std = 0.0221\n",
      "    FNI-EMD: Mean = 0.7941, Std = 0.0250\n",
      "  Method: kernel_svm\n",
      "    IMA    : Mean = 0.1231, Std = 0.0520\n",
      "    EMD    : Mean = 0.7781, Std = 0.0351\n",
      "    FNI-EMD: Mean = 0.7869, Std = 0.0377\n",
      "  Method: ebm\n",
      "    IMA    : Mean = 0.0304, Std = 0.0184\n",
      "    EMD    : Mean = 0.8151, Std = 0.0017\n",
      "    FNI-EMD: Mean = 0.8213, Std = 0.0017\n",
      "  Method: shap\n",
      "    IMA    : Mean = 0.4130, Std = 0.0354\n",
      "    EMD    : Mean = 0.8734, Std = 0.0237\n",
      "    FNI-EMD: Mean = 0.9112, Std = 0.0105\n",
      "  Method: ig\n",
      "    IMA    : Mean = 0.7278, Std = 0.0947\n",
      "    EMD    : Mean = 0.8995, Std = 0.0460\n",
      "    FNI-EMD: Mean = 0.9580, Std = 0.0128\n",
      "  Method: nam\n",
      "    IMA    : Mean = 0.3641, Std = 0.0440\n",
      "    EMD    : Mean = 0.8256, Std = 0.0312\n",
      "    FNI-EMD: Mean = 0.8414, Std = 0.0304\n",
      "  Method: pattern_net\n",
      "    IMA    : Mean = 0.6141, Std = 0.1915\n",
      "    EMD    : Mean = 0.8891, Std = 0.0687\n",
      "    FNI-EMD: Mean = 0.9235, Std = 0.0400\n",
      "  Method: pattern_attribution\n",
      "    IMA    : Mean = 0.7687, Std = 0.1277\n",
      "    EMD    : Mean = 0.9095, Std = 0.0230\n",
      "    FNI-EMD: Mean = 0.9603, Std = 0.0289\n",
      "  Method: discr\n",
      "    IMA    : Mean = 0.1178, Std = 0.0273\n",
      "    EMD    : Mean = 0.7986, Std = 0.0207\n",
      "    FNI-EMD: Mean = 0.8052, Std = 0.0216\n"
     ]
    }
   ],
   "source": [
    "from interpret.utils import measure_interactions\n",
    "def FAST(X_train, y_train, n_interactions, init_score=None, feature_names=None, feature_types=None):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    interactions = measure_interactions(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        interactions=n_interactions, \n",
    "        init_score=init_score,  # Can be a model or initial scores; set to None if not used\n",
    "        feature_names = feature_names,\n",
    "        feature_types = feature_types\n",
    "    )\n",
    "    \n",
    "    pairs = []\n",
    "    for (i, j), _ in interactions:\n",
    "        pairs.append((i,j))\n",
    "    return pairs, time.time() - t0\n",
    "\n",
    "\n",
    "D_2D_EDGE = 8 \n",
    "D_FLAT = D_2D_EDGE * D_2D_EDGE \n",
    "\n",
    "normal_t = np.array([[1,0],[1,1],[1,0]])\n",
    "normal_l = np.array([[1,0],[1,0],[1,1]])\n",
    "GT_MASK_2D = np.zeros((D_2D_EDGE, D_2D_EDGE), dtype=int)\n",
    "\n",
    "GT_MASK_2D[1:4, 1:3] = normal_t\n",
    "GT_MASK_2D[4:7, 5:7] = normal_l\n",
    "\n",
    "GT_MASK_2D_FLAT = GT_MASK_2D.flatten()\n",
    "\n",
    "\n",
    "# def create_gt_mask_interactions_1d(main_effect_ground_truth_flat, custom_interaction_pairs, d_flat):\n",
    "#     if len(main_effect_ground_truth_flat) != d_flat:\n",
    "#         raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) must match d_flat ({d_flat}).\")\n",
    "#     interaction_ground_truth = []\n",
    "#     for i, j in custom_interaction_pairs:\n",
    "#         if not (0 <= i < d_flat and 0 <= j < d_flat):\n",
    "#             interaction_ground_truth.append(0) # Invalid pair, append 0\n",
    "#             continue\n",
    "#         interaction_ground_truth.append(1 if main_effect_ground_truth_flat[i] == 1 and main_effect_ground_truth_flat[j] == 1 else 0)\n",
    "#     return np.concatenate((main_effect_ground_truth_flat, np.array(interaction_ground_truth, dtype=int)))\n",
    "\n",
    "# def create_qlr_ground_truth_mask_1d(main_effect_ground_truth_flat, d_flat):\n",
    "#     if not isinstance(main_effect_ground_truth_flat, np.ndarray):\n",
    "#         raise TypeError(\"main_effect_ground_truth_flat must be a numpy array.\")\n",
    "#     if main_effect_ground_truth_flat.ndim != 1:\n",
    "#         raise ValueError(\"main_effect_ground_truth_flat must be a 1D array.\")\n",
    "#     if len(main_effect_ground_truth_flat) != d_flat:\n",
    "#         raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) \"\n",
    "#                          f\"must match d_flat ({d_flat}).\")\n",
    "#     if not np.all(np.isin(main_effect_ground_truth_flat, [0, 1])):\n",
    "#         raise ValueError(\"main_effect_ground_truth_flat should only contain 0s and 1s.\")\n",
    "\n",
    "#     num_main_features = d_flat\n",
    "\n",
    "#     # Get indices for the upper triangle, including the diagonal (for x_i*x_j where i <= j)\n",
    "#     # These are the same indices used in the `quadratic_features` function.\n",
    "#     inds_0, inds_1 = np.triu_indices(num_main_features, 0)\n",
    "    \n",
    "#     num_quadratic_terms = len(inds_0)\n",
    "#     quadratic_part_mask = np.zeros(num_quadratic_terms, dtype=int)\n",
    "\n",
    "#     for i in range(num_quadratic_terms):\n",
    "#         idx_feature_1 = inds_0[i]\n",
    "#         idx_feature_2 = inds_1[i]\n",
    "        \n",
    "#         # The mask for the quadratic term is 1 if both corresponding main features are 1\n",
    "#         if main_effect_ground_truth_flat[idx_feature_1] == 1 and \\\n",
    "#            main_effect_ground_truth_flat[idx_feature_2] == 1:\n",
    "#             quadratic_part_mask[i] = 1\n",
    "#         else:\n",
    "#             quadratic_part_mask[i] = 0\n",
    "            \n",
    "#     # Concatenate the main effect mask with the quadratic effect mask\n",
    "#     full_mask = np.concatenate((main_effect_ground_truth_flat, quadratic_part_mask))\n",
    "    \n",
    "#     return full_mask\n",
    "\n",
    "\n",
    "# Helper: get flat-index sets for T and L shapes (row-major flatten)\n",
    "def _xor_shape_index_sets(d_edge, normal_t, normal_l):\n",
    "    T_rows = slice(1, 4)  # [1:4)\n",
    "    T_cols = slice(1, 3)  # [1:3)\n",
    "    L_rows = slice(4, 7)  # [4:7)\n",
    "    L_cols = slice(5, 7)  # [5:7)\n",
    "\n",
    "    # Bounds check like your original code\n",
    "    if d_edge < 7:\n",
    "        # Not enough room; return empty sets to avoid false positives\n",
    "        return set(), set()\n",
    "\n",
    "    mask_t = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_l = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_t[T_rows, T_cols] = normal_t\n",
    "    mask_l[L_rows, L_cols] = normal_l\n",
    "\n",
    "    # Flat indices where the mini-pattern has ones\n",
    "    idx_t = set(np.flatnonzero(mask_t.flatten()))\n",
    "    idx_l = set(np.flatnonzero(mask_l.flatten()))\n",
    "    return idx_t, idx_l\n",
    "\n",
    "\n",
    "def create_gt_mask_interactions_1d(main_effect_ground_truth_flat, custom_interaction_pairs, d_flat):\n",
    "    \"\"\"\n",
    "    XOR ground truth for methods using an explicit interaction list (FAST, etc.).\n",
    "    - Main effects: all zeros (length d_flat)\n",
    "    - Interactions: 1 iff one index in T and the other in L; else 0.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray):\n",
    "        raise TypeError(\"main_effect_ground_truth_flat must be a numpy array.\")\n",
    "    if main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) must match d_flat ({d_flat}).\")\n",
    "\n",
    "    # Build T/L index sets in the 2D grid and map to flat indices\n",
    "    idx_t, idx_l = _xor_shape_index_sets(D_2D_EDGE, normal_t, normal_l)\n",
    "\n",
    "    # Main effects are all zeros for XOR\n",
    "    main_part = np.zeros(d_flat, dtype=int)\n",
    "\n",
    "    # Interactions: only cross-shape pairs are 1\n",
    "    interaction_ground_truth = []\n",
    "    for (i, j) in custom_interaction_pairs:\n",
    "        if not (0 <= i < d_flat and 0 <= j < d_flat):\n",
    "            interaction_ground_truth.append(0)\n",
    "            continue\n",
    "        if i == j:\n",
    "            interaction_ground_truth.append(0)\n",
    "            continue\n",
    "        cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "        interaction_ground_truth.append(1 if cross else 0)\n",
    "\n",
    "    interaction_part = np.array(interaction_ground_truth, dtype=int)\n",
    "    return np.concatenate((main_part, interaction_part))\n",
    "\n",
    "\n",
    "def create_qlr_ground_truth_mask_1d(main_effect_ground_truth_flat, d_flat):\n",
    "    \"\"\"\n",
    "    XOR ground truth for QLR (upper-tri ordering i <= j).\n",
    "    - Main effects: all zeros (length d_flat)\n",
    "    - Quadratic terms: 1 iff i != j and {i,j} is a cross-shape pair (T vs L); else 0.\n",
    "      Diagonal terms i==j are set to 0.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray):\n",
    "        raise TypeError(\"main_effect_ground_truth_flat must be a numpy array.\")\n",
    "    if main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) must match d_flat ({d_flat}).\")\n",
    "\n",
    "    # Build T/L index sets\n",
    "    idx_t, idx_l = _xor_shape_index_sets(D_2D_EDGE, normal_t, normal_l)\n",
    "\n",
    "    # Main effects are all zeros for XOR importance\n",
    "    main_part = np.zeros(d_flat, dtype=int)\n",
    "\n",
    "    # Upper-tri including diagonal, same order as your QLR feature mapping\n",
    "    inds_0, inds_1 = np.triu_indices(d_flat, 0)\n",
    "    quadratic_part_mask = np.zeros(len(inds_0), dtype=int)\n",
    "\n",
    "    for k in range(len(inds_0)):\n",
    "        i = inds_0[k]; j = inds_1[k]\n",
    "        if i == j:\n",
    "            quadratic_part_mask[k] = 0  # no self-importance\n",
    "            continue\n",
    "        cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "        quadratic_part_mask[k] = 1 if cross else 0\n",
    "\n",
    "    return np.concatenate((main_part, quadratic_part_mask))\n",
    "\n",
    "\n",
    "def importance_mass_accuracy(gt_mask, attribution):\n",
    "    if not isinstance(gt_mask, np.ndarray) or not isinstance(attribution, np.ndarray):\n",
    "        return np.nan\n",
    "    if attribution.ndim != 1 or len(gt_mask) != len(attribution):\n",
    "        # print(f\"IMA shape mismatch: gt_mask {gt_mask.shape}, attribution {attribution.shape}\")\n",
    "        return np.nan\n",
    "    \n",
    "    abs_attribution = np.abs(attribution)\n",
    "    mass_in_gt = np.sum(abs_attribution[gt_mask == 1])\n",
    "    total_mass = np.sum(abs_attribution)\n",
    "    \n",
    "    if total_mass == 0:\n",
    "        return 1.0 if mass_in_gt == 0 else 0.0 # Perfect score if both are zero mass\n",
    "    return mass_in_gt / total_mass\n",
    "\n",
    "def create_cost_matrix(grid_edge_length):\n",
    "    # Creates a cost matrix for a grid of grid_edge_length * grid_edge_length features\n",
    "    if grid_edge_length == 0:\n",
    "        return np.array([]).reshape(0,0)\n",
    "    \n",
    "    total_features = grid_edge_length * grid_edge_length\n",
    "    if total_features == 1:\n",
    "        return np.array([[0.0]])\n",
    "        \n",
    "    indices_matrix = np.indices((grid_edge_length, grid_edge_length))\n",
    "    coordinates = []\n",
    "    for r in range(grid_edge_length):\n",
    "        for c in range(grid_edge_length):\n",
    "            coordinates.append((indices_matrix[0][r, c], indices_matrix[1][r, c]))\n",
    "    coordinates = np.array(coordinates)\n",
    "    return cdist(coordinates, coordinates)\n",
    "\n",
    "# Cost matrix for main effects (e.g., 8x8 grid -> 64 features)\n",
    "COST_MATRIX_MAIN_EFFECTS = create_cost_matrix(D_2D_EDGE)\n",
    "\n",
    "def calculate_emd_score_metric(gt_mask_flat, attribution_flat, grid_edge_length, base_cost_matrix, is_fni=False):\n",
    "    # Input checks\n",
    "    if not (isinstance(gt_mask_flat, np.ndarray) and gt_mask_flat.ndim == 1 and\n",
    "            isinstance(attribution_flat, np.ndarray) and attribution_flat.ndim == 1 and\n",
    "            len(gt_mask_flat) == len(attribution_flat) and\n",
    "            len(gt_mask_flat) == grid_edge_length * grid_edge_length):\n",
    "        return np.nan\n",
    "\n",
    "    current_cost_matrix = np.copy(base_cost_matrix)\n",
    "    if is_fni:\n",
    "        gt_indices = np.where(gt_mask_flat == 1)[0]\n",
    "        for r_idx in gt_indices:\n",
    "            for c_idx in gt_indices:\n",
    "                # Ensure indices are within bounds of the cost matrix\n",
    "                if r_idx < current_cost_matrix.shape[0] and c_idx < current_cost_matrix.shape[1]:\n",
    "                    current_cost_matrix[r_idx, c_idx] = 0.0\n",
    "    \n",
    "    sum_gt = np.sum(gt_mask_flat)\n",
    "    abs_attribution = np.abs(attribution_flat)\n",
    "    sum_attr = np.sum(abs_attribution)\n",
    "\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9: # Effectively both empty\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9: # One empty, other not\n",
    "        return 0.0\n",
    "        \n",
    "    dist_gt = gt_mask_flat.astype(np.float64) / sum_gt\n",
    "    dist_attr = abs_attribution.astype(np.float64) / sum_attr\n",
    "    \n",
    "    # Ensure distributions are C-contiguous and float64 for EMD\n",
    "    dist_gt_c = np.ascontiguousarray(dist_gt, dtype=np.float64)\n",
    "    dist_attr_c = np.ascontiguousarray(dist_attr, dtype=np.float64)\n",
    "    current_cost_matrix_c = np.ascontiguousarray(current_cost_matrix, dtype=np.float64)\n",
    "\n",
    "    cost_val = 0.0\n",
    "    if grid_edge_length * grid_edge_length > 1 : # EMD makes sense for >1 feature\n",
    "        try:\n",
    "            # Note: emd returns the cost value directly, not a tuple if log=False\n",
    "            _, cost_val = emd(dist_gt_c, dist_attr_c, current_cost_matrix_c, numItermax=200000, log=True)\n",
    "        except Exception:\n",
    "            return np.nan # EMD calculation failed\n",
    "    \n",
    "    # Dmax = max Euclidean distance in the grid\n",
    "    d_max = np.sqrt(2 * (grid_edge_length - 1)**2) if grid_edge_length > 1 else 0.0\n",
    "\n",
    "    if d_max == 0: # Handles grid_edge_length = 1 (single feature) or cases where d_max is ill-defined\n",
    "        return 1.0 if np.isclose(cost_val, 0) else 0.0\n",
    "    \n",
    "    return 1 - (cost_val['cost'] / d_max)\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "def process_explanations_metrics(explanations_dict, gt_mask_main_flat, d_flat_main, d_edge_main, cost_mat_main):\n",
    "    results_raw_collection = {} \n",
    "\n",
    "    for scenario_full_name, methods_data in explanations_dict.items():\n",
    "        if 'translations' in scenario_full_name:\n",
    "            continue\n",
    "        scenario_parts = scenario_full_name.split('_')\n",
    "        try:\n",
    "            # dataset_ind = int(scenario_parts[-1]) # Not used directly in aggregation key structure here\n",
    "            scenario_base_name = '_'.join(scenario_parts[:-1])\n",
    "        except ValueError:\n",
    "            scenario_base_name = scenario_full_name\n",
    "            # print(f\"Warning: Could not parse dataset index for {scenario_full_name}. Using full name as base.\")\n",
    "\n",
    "        interaction_pairs_for_scenario = []\n",
    "        if 'xor' in scenario_full_name.lower():\n",
    "            data_path = f'./data/xai_tris/{scenario_full_name}.pkl'\n",
    "            with open(data_path, \"rb\") as f:\n",
    "                data = pkl.load(f)\n",
    "                \n",
    "                X_train_tensor = data.x_train.float() \n",
    "                y_train_tensor = data.y_train\n",
    "\n",
    "            try:\n",
    "                interaction_pairs_for_scenario, _ = FAST(X_train_tensor, y_train_tensor, n_interactions=128)\n",
    "            except Exception as e:\n",
    "                # print(f\"Warning: Placeholder FAST failed for {scenario_full_name}: {e}\")\n",
    "                interaction_pairs_for_scenario = []\n",
    "        \n",
    "        if scenario_base_name not in results_raw_collection:\n",
    "            results_raw_collection[scenario_base_name] = {}\n",
    "\n",
    "        for method_name, explanation_content in methods_data.items():\n",
    "            if method_name not in results_raw_collection[scenario_base_name]:\n",
    "                results_raw_collection[scenario_base_name][method_name] = {'IMA': [], 'EMD': [], 'FNI_EMD': []}\n",
    "\n",
    "            current_explanation = explanation_content\n",
    "            if isinstance(current_explanation, list): # For \"ebm 192 <--- LIST\"\n",
    "                current_explanation = np.array(current_explanation)\n",
    "            \n",
    "            if not isinstance(current_explanation, np.ndarray):\n",
    "                # print(f\"Warning: Data for {scenario_full_name}/{method_name} is not array/list. Skipping.\")\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            # Process attribution: average local, flatten global\n",
    "            processed_attr = np.array([])\n",
    "            if current_explanation.ndim > 1 and current_explanation.shape[0] > 1 and \\\n",
    "               not (current_explanation.shape[0] == d_flat_main and current_explanation.ndim == 2 and current_explanation.shape[1] == 1 and d_flat_main > 1):\n",
    "                # processed_attr = np.mean(current_explanation, axis=0).squeeze()\n",
    "                if current_explanation[0].ndim == 3:\n",
    "                    # processed_attr = np.mean(np.vstack(current_explanation.squeeze(2)), axis=0)\n",
    "                    processed_attr = np.mean(np.mean(np.array(current_explanation), axis=0).squeeze(), axis=0)\n",
    "                else:\n",
    "                    processed_attr = np.mean(np.vstack(current_explanation), axis=0)\n",
    "            else:\n",
    "                processed_attr = current_explanation.flatten()\n",
    "            \n",
    "            # --- IMA Calculation ---\n",
    "            gt_mask_for_ima = None\n",
    "            attr_for_ima = None\n",
    "\n",
    "            if method_name in ['pattern_gam', 'ebm', 'nam'] and 'xor' in scenario_full_name.lower():\n",
    "                gt_mask_for_ima = create_gt_mask_interactions_1d(gt_mask_main_flat, interaction_pairs_for_scenario, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            elif method_name == 'pattern_qlr':\n",
    "                gt_mask_for_ima = create_qlr_ground_truth_mask_1d(gt_mask_main_flat, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            else: \n",
    "                gt_mask_for_ima = gt_mask_main_flat\n",
    "                attr_for_ima = processed_attr[:d_flat_main] \n",
    "\n",
    "            # Adjust attribution length for IMA if mismatch (truncate/pad)\n",
    "            if gt_mask_for_ima is not None and attr_for_ima is not None and len(attr_for_ima) != len(gt_mask_for_ima):\n",
    "                # print(f\"Warning IMA {scenario_full_name}/{method_name}: attr len {len(attr_for_ima)}, GT len {len(gt_mask_for_ima)}. Adjusting.\")\n",
    "                temp_attr = np.zeros(len(gt_mask_for_ima))\n",
    "                common_len = min(len(attr_for_ima), len(gt_mask_for_ima))\n",
    "                temp_attr[:common_len] = attr_for_ima[:common_len]\n",
    "                attr_for_ima = temp_attr\n",
    "            \n",
    "            ima_val = importance_mass_accuracy(gt_mask_for_ima, attr_for_ima)\n",
    "            results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "\n",
    "            # --- EMD & FNI-EMD (main effects: first d_flat_main features, d_edge_main grid) ---\n",
    "            attr_main_eff = processed_attr[:d_flat_main]\n",
    "            gt_main_eff = gt_mask_main_flat # GT for EMD/FNI is always main effects\n",
    "\n",
    "            emd_val = np.nan\n",
    "            fni_emd_val = np.nan\n",
    "            if len(attr_main_eff) == d_flat_main and d_flat_main > 0 : # Ensure correct length for main effects\n",
    "                emd_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_emd_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=True)\n",
    "            \n",
    "            results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "            results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_emd_val)\n",
    "\n",
    "    # --- Aggregation of results ---\n",
    "    final_aggregated_results = {}\n",
    "    for sc_base, meth_data in results_raw_collection.items():\n",
    "        final_aggregated_results[sc_base] = {}\n",
    "        for meth, metrics_lists in meth_data.items():\n",
    "            final_aggregated_results[sc_base][meth] = {\n",
    "                'IMA_mean': np.nanmean(metrics_lists['IMA']) if metrics_lists['IMA'] else np.nan,\n",
    "                'IMA_std': np.nanstd(metrics_lists['IMA']) if metrics_lists['IMA'] else np.nan,\n",
    "                'EMD_mean': np.nanmean(metrics_lists['EMD']) if metrics_lists['EMD'] else np.nan,\n",
    "                'EMD_std': np.nanstd(metrics_lists['EMD']) if metrics_lists['EMD'] else np.nan,\n",
    "                'FNI_EMD_mean': np.nanmean(metrics_lists['FNI_EMD']) if metrics_lists['FNI_EMD'] else np.nan,\n",
    "                'FNI_EMD_std': np.nanstd(metrics_lists['FNI_EMD']) if metrics_lists['FNI_EMD'] else np.nan,\n",
    "            }\n",
    "    return final_aggregated_results\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"D_2D_EDGE (grid edge for main effects): {D_2D_EDGE}\")\n",
    "print(f\"D_FLAT (total main effect features): {D_FLAT}\")\n",
    "print(f\"Sum of GT_MASK_2D_FLAT: {np.sum(GT_MASK_2D_FLAT)}\")\n",
    "print(f\"Cost matrix for main effects shape: {COST_MATRIX_MAIN_EFFECTS.shape}\")\n",
    "print(f\"--- Starting Metric Calculation ---\")\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)\n",
    "\n",
    "\n",
    "aggregated_metrics = process_explanations_metrics(\n",
    "    explanations,\n",
    "    GT_MASK_2D_FLAT,\n",
    "    D_FLAT,\n",
    "    D_2D_EDGE,\n",
    "    COST_MATRIX_MAIN_EFFECTS\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Aggregated Results ---\")\n",
    "for scenario_name, method_data in aggregated_metrics.items():\n",
    "    print(f\"\\nScenario Type: {scenario_name}\")\n",
    "    for method, scores in method_data.items():\n",
    "        print(f\"  Method: {method}\")\n",
    "        print(f\"    IMA    : Mean = {scores['IMA_mean']:.4f}, Std = {scores['IMA_std']:.4f}\")\n",
    "        print(f\"    EMD    : Mean = {scores['EMD_mean']:.4f}, Std = {scores['EMD_std']:.4f}\")\n",
    "        print(f\"    FNI-EMD: Mean = {scores['FNI_EMD_mean']:.4f}, Std = {scores['FNI_EMD_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "481a8c35-3933-4747-92b1-f9761fa45df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "D_2D_EDGE (grid edge for main effects): 8\n",
      "D_FLAT (total main effect features): 64\n",
      "Sum of GT_MASK_2D_FLAT (non-XOR main GT): 8\n",
      "Cost matrix for main effects shape: (64, 64)\n",
      "--- Starting Metric Calculation ---\n",
      "\n",
      "--- Aggregated Results ---\n",
      "\n",
      "Scenario Type: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated\n",
      "  Method: pattern_gam\n",
      "    IMA    : Mean = 0.5688, Std = 0.0803\n",
      "    EMD    : Mean = 0.9209, Std = 0.0108\n",
      "    FNI-EMD: Mean = 0.9319, Std = 0.0112\n",
      "  Method: pattern_qlr\n",
      "    IMA    : Mean = 0.2278, Std = 0.0385\n",
      "    EMD    : Mean = 0.8809, Std = 0.0123\n",
      "    FNI-EMD: Mean = 0.8876, Std = 0.0127\n",
      "  Method: kernel_svm\n",
      "    IMA    : Mean = 0.1231, Std = 0.0520\n",
      "    EMD    : Mean = 0.7781, Std = 0.0351\n",
      "    FNI-EMD: Mean = 0.7869, Std = 0.0377\n",
      "  Method: ebm\n",
      "    IMA    : Mean = 0.0304, Std = 0.0184\n",
      "    EMD    : Mean = 0.8376, Std = 0.0549\n",
      "    FNI-EMD: Mean = 0.8392, Std = 0.0541\n",
      "  Method: shap\n",
      "    IMA    : Mean = 0.4130, Std = 0.0354\n",
      "    EMD    : Mean = 0.8734, Std = 0.0237\n",
      "    FNI-EMD: Mean = 0.9112, Std = 0.0105\n",
      "  Method: ig\n",
      "    IMA    : Mean = 0.7278, Std = 0.0947\n",
      "    EMD    : Mean = 0.8995, Std = 0.0460\n",
      "    FNI-EMD: Mean = 0.9580, Std = 0.0128\n",
      "  Method: nam\n",
      "    IMA    : Mean = 0.3641, Std = 0.0440\n",
      "    EMD    : Mean = 0.8895, Std = 0.0196\n",
      "    FNI-EMD: Mean = 0.9070, Std = 0.0233\n",
      "  Method: pattern_net\n",
      "    IMA    : Mean = 0.6141, Std = 0.1915\n",
      "    EMD    : Mean = 0.8891, Std = 0.0687\n",
      "    FNI-EMD: Mean = 0.9235, Std = 0.0400\n",
      "  Method: pattern_attribution\n",
      "    IMA    : Mean = 0.7687, Std = 0.1277\n",
      "    EMD    : Mean = 0.9095, Std = 0.0230\n",
      "    FNI-EMD: Mean = 0.9603, Std = 0.0289\n",
      "  Method: discr\n",
      "    IMA    : Mean = 0.8485, Std = 0.0188\n",
      "    EMD    : Mean = 0.9489, Std = 0.0060\n",
      "    FNI-EMD: Mean = 0.9747, Std = 0.0058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot import emd\n",
    "from interpret.utils import measure_interactions\n",
    "import os\n",
    "\n",
    "# ----------------------\n",
    "# FAST (unchanged)\n",
    "# ----------------------\n",
    "def FAST(X_train, y_train, n_interactions, init_score=None, feature_names=None, feature_types=None):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    interactions = measure_interactions(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        interactions=n_interactions, \n",
    "        init_score=init_score,\n",
    "        feature_names=feature_names,\n",
    "        feature_types=feature_types\n",
    "    )\n",
    "    pairs = []\n",
    "    for (i, j), _ in interactions:\n",
    "        pairs.append((i, j))\n",
    "    return pairs, time.time() - t0\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Config / shapes\n",
    "# ----------------------\n",
    "D_2D_EDGE = 8 \n",
    "D_FLAT = D_2D_EDGE * D_2D_EDGE \n",
    "\n",
    "normal_t = np.array([[1,0],[1,1],[1,0]])\n",
    "normal_l = np.array([[1,0],[1,0],[1,1]])\n",
    "GT_MASK_2D = np.zeros((D_2D_EDGE, D_2D_EDGE), dtype=int)\n",
    "\n",
    "# Build the visual pattern (kept for reference/plots if you need it)\n",
    "if D_2D_EDGE >= 7: \n",
    "    GT_MASK_2D[1:4, 1:3] = normal_t\n",
    "    GT_MASK_2D[4:7, 5:7] = normal_l\n",
    "else:\n",
    "    print(f\"Warning: D_2D_EDGE ({D_2D_EDGE}) is too small for the example GT_MASK_2D pattern. GT mask will be mostly zeros.\")\n",
    "\n",
    "GT_MASK_2D_FLAT = GT_MASK_2D.flatten()  # This is the ORIGINAL main-effects mask (non-XOR meaning)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# XOR helpers\n",
    "# ----------------------\n",
    "def _xor_shape_index_sets(d_edge, normal_t, normal_l):\n",
    "    \"\"\"Return sets of flat indices for the T and L mini-shapes.\"\"\"\n",
    "    T_rows = slice(1, 4)  # [1:4)\n",
    "    T_cols = slice(1, 3)  # [1:3)\n",
    "    L_rows = slice(4, 7)  # [4:7)\n",
    "    L_cols = slice(5, 7)  # [5:7)\n",
    "\n",
    "    if d_edge < 7:\n",
    "        return set(), set()\n",
    "\n",
    "    mask_t = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_l = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_t[T_rows, T_cols] = normal_t\n",
    "    mask_l[L_rows, L_cols] = normal_l\n",
    "\n",
    "    idx_t = set(np.flatnonzero(mask_t.flatten()))\n",
    "    idx_l = set(np.flatnonzero(mask_l.flatten()))\n",
    "    return idx_t, idx_l\n",
    "\n",
    "def _is_xor_scenario(name: str) -> bool:\n",
    "    return 'xor' in str(name).lower()\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Interaction pair builders\n",
    "# ----------------------\n",
    "def qlr_pairs_upper_tri(d):\n",
    "    \"\"\"Pairs (i,j) with i <= j in np.triu_indices order.\"\"\"\n",
    "    i_idx, j_idx = np.triu_indices(d, 0)\n",
    "    return list(zip(i_idx.tolist(), j_idx.tolist()))\n",
    "\n",
    "def get_fast_pairs_for_scenario(scenario_full_name, n_interactions=128):\n",
    "    \"\"\"\n",
    "    Attempt to load the dataset for this scenario and compute FAST pairs.\n",
    "    Returns [] if unavailable.\n",
    "    \"\"\"\n",
    "    data_path = f'./data/xai_tris/{scenario_full_name}.pkl'\n",
    "    if not os.path.exists(data_path):\n",
    "        return []\n",
    "    try:\n",
    "        with open(data_path, \"rb\") as f:\n",
    "            data = pkl.load(f)\n",
    "        X_train_tensor = data.x_train.float()\n",
    "        y_train_tensor = data.y_train\n",
    "        pairs, _ = FAST(X_train_tensor, y_train_tensor, n_interactions=n_interactions)\n",
    "        return pairs\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Ground-truth constructors (64 + interactions)\n",
    "# ----------------------\n",
    "def create_gt_mask_interactions_generic(\n",
    "    main_effect_ground_truth_flat: np.ndarray,\n",
    "    custom_interaction_pairs,\n",
    "    d_flat: int,\n",
    "    d_edge: int,\n",
    "    is_xor: bool,\n",
    "    idx_t=None,\n",
    "    idx_l=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For methods with explicit interaction list (NAM/EBM/PatternGAM).\n",
    "    XOR:\n",
    "        - mains = 0\n",
    "        - interactions = 1 iff one endpoint in T and the other in L; diag ignored (pairs should be i != j).\n",
    "    non-XOR:\n",
    "        - mains = main_effect_ground_truth_flat\n",
    "        - interactions = 1 iff both endpoints are 1 in main_effect_ground_truth_flat.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray) or main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D numpy array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat length must equal d_flat.\")\n",
    "\n",
    "    m = len(custom_interaction_pairs)\n",
    "    if is_xor:\n",
    "        if idx_t is None or idx_l is None:\n",
    "            idx_t, idx_l = _xor_shape_index_sets(d_edge, normal_t, normal_l)\n",
    "        main_part = np.zeros(d_flat, dtype=int)\n",
    "        inter = []\n",
    "        for (i, j) in custom_interaction_pairs:\n",
    "            if not (0 <= i < d_flat and 0 <= j < d_flat) or i == j:\n",
    "                inter.append(0); continue\n",
    "            cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "            inter.append(1 if cross else 0)\n",
    "        inter_part = np.array(inter, dtype=int)\n",
    "        return np.concatenate([main_part, inter_part])\n",
    "    else:\n",
    "        main_part = main_effect_ground_truth_flat.astype(int)\n",
    "        inter = []\n",
    "        for (i, j) in custom_interaction_pairs:\n",
    "            good = (0 <= i < d_flat) and (0 <= j < d_flat)\n",
    "            inter.append(1 if (good and main_part[i] == 1 and main_part[j] == 1) else 0)\n",
    "        inter_part = np.array(inter, dtype=int)\n",
    "        return np.concatenate([main_part, inter_part])\n",
    "\n",
    "\n",
    "def create_qlr_ground_truth_mask_generic(\n",
    "    main_effect_ground_truth_flat: np.ndarray,\n",
    "    d_flat: int,\n",
    "    d_edge: int,\n",
    "    is_xor: bool,\n",
    "    idx_t=None,\n",
    "    idx_l=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For PatternQLR (mains + all degree-2 terms in np.triu order, incl. diagonal).\n",
    "    XOR:\n",
    "        - mains = 0\n",
    "        - quadratic terms: 1 iff i != j and {i,j} is a cross-shape pair (T vs L); diag = 0.\n",
    "    non-XOR:\n",
    "        - mains = main_effect_ground_truth_flat\n",
    "        - quadratic terms: \n",
    "              diag(i,i) = 1 iff main_effect_ground_truth_flat[i] == 1\n",
    "              off-diag(i<j) = 1 iff both endpoints are 1 in main GT.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray) or main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D numpy array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat length must equal d_flat.\")\n",
    "\n",
    "    inds_0, inds_1 = np.triu_indices(d_flat, 0)\n",
    "    quad = np.zeros(len(inds_0), dtype=int)\n",
    "\n",
    "    if is_xor:\n",
    "        if idx_t is None or idx_l is None:\n",
    "            idx_t, idx_l = _xor_shape_index_sets(d_edge, normal_t, normal_l)\n",
    "        main_part = np.zeros(d_flat, dtype=int)\n",
    "        for k in range(len(inds_0)):\n",
    "            i, j = int(inds_0[k]), int(inds_1[k])\n",
    "            if i == j:\n",
    "                quad[k] = 0\n",
    "            else:\n",
    "                cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "                quad[k] = 1 if cross else 0\n",
    "        return np.concatenate([main_part, quad])\n",
    "    else:\n",
    "        main_part = main_effect_ground_truth_flat.astype(int)\n",
    "        for k in range(len(inds_0)):\n",
    "            i, j = int(inds_0[k]), int(inds_1[k])\n",
    "            if i == j:\n",
    "                quad[k] = 1 if main_part[i] == 1 else 0\n",
    "            else:\n",
    "                quad[k] = 1 if (main_part[i] == 1 and main_part[j] == 1) else 0\n",
    "        return np.concatenate([main_part, quad])\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# EMD / FNI-EMD\n",
    "# ----------------------\n",
    "def calculate_emd_score_metric(gt_mask_flat, attribution_flat, grid_edge_length, base_cost_matrix, is_fni=False):\n",
    "    \"\"\"\n",
    "    64-D EMD/FNI-EMD (main effects grid). Kept for non-interaction methods.\n",
    "    \"\"\"\n",
    "    if not (isinstance(gt_mask_flat, np.ndarray) and gt_mask_flat.ndim == 1 and\n",
    "            isinstance(attribution_flat, np.ndarray) and attribution_flat.ndim == 1 and\n",
    "            len(gt_mask_flat) == len(attribution_flat) and\n",
    "            len(gt_mask_flat) == grid_edge_length * grid_edge_length):\n",
    "        return np.nan\n",
    "\n",
    "    current_cost_matrix = np.copy(base_cost_matrix)\n",
    "    if is_fni:\n",
    "        gt_indices = np.where(gt_mask_flat == 1)[0]\n",
    "        for r_idx in gt_indices:\n",
    "            for c_idx in gt_indices:\n",
    "                if r_idx < current_cost_matrix.shape[0] and c_idx < current_cost_matrix.shape[1]:\n",
    "                    current_cost_matrix[r_idx, c_idx] = 0.0\n",
    "    \n",
    "    sum_gt = np.sum(gt_mask_flat)\n",
    "    abs_attribution = np.abs(attribution_flat)\n",
    "    sum_attr = np.sum(abs_attribution)\n",
    "\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9:\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9:\n",
    "        return 0.0\n",
    "        \n",
    "    dist_gt = gt_mask_flat.astype(np.float64) / sum_gt\n",
    "    dist_attr = abs_attribution.astype(np.float64) / sum_attr\n",
    "\n",
    "    dist_gt_c = np.ascontiguousarray(dist_gt, dtype=np.float64)\n",
    "    dist_attr_c = np.ascontiguousarray(dist_attr, dtype=np.float64)\n",
    "    current_cost_matrix_c = np.ascontiguousarray(current_cost_matrix, dtype=np.float64)\n",
    "\n",
    "    _, log = emd(dist_gt_c, dist_attr_c, current_cost_matrix_c, numItermax=200000, log=True)\n",
    "    d_max = np.sqrt(2 * (grid_edge_length - 1)**2) if grid_edge_length > 1 else 0.0\n",
    "    if d_max == 0:\n",
    "        return 1.0 if np.isclose(log['cost'], 0) else 0.0\n",
    "    return 1 - (log['cost'] / d_max)\n",
    "\n",
    "def _grid_coords_for_main(d_edge):\n",
    "    coords = []\n",
    "    for r in range(d_edge):\n",
    "        for c in range(d_edge):\n",
    "            coords.append((float(r), float(c)))\n",
    "    return np.array(coords, dtype=float)\n",
    "\n",
    "def _coords_for_interactions_from_pairs(d_edge, pairs):\n",
    "    main_coords = _grid_coords_for_main(d_edge)\n",
    "    coords = []\n",
    "    for (i, j) in pairs:\n",
    "        ri, ci = main_coords[i]\n",
    "        rj, cj = main_coords[j]\n",
    "        coords.append(((ri + rj) / 2.0, (ci + cj) / 2.0))\n",
    "    return np.array(coords, dtype=float)\n",
    "\n",
    "def _emd_with_arbitrary_cost(gt_vec, attr_vec, cost_matrix, d_edge, is_fni=False):\n",
    "    \"\"\"EMD/FNI-EMD for arbitrary square cost matrix; normalization keeps main-grid Dmax.\"\"\"\n",
    "    if gt_vec.shape != attr_vec.shape:\n",
    "        return np.nan\n",
    "    if cost_matrix.shape[0] != cost_matrix.shape[1] or cost_matrix.shape[0] != gt_vec.shape[0]:\n",
    "        return np.nan\n",
    "\n",
    "    C = np.array(cost_matrix, dtype=float)\n",
    "    if is_fni:\n",
    "        gt_idx = np.flatnonzero(gt_vec > 0)\n",
    "        if gt_idx.size > 0:\n",
    "            C = C.copy()\n",
    "            C[np.ix_(gt_idx, gt_idx)] = 0.0\n",
    "\n",
    "    sum_gt = float(np.sum(gt_vec))\n",
    "    sum_attr = float(np.sum(attr_vec))\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9:\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9:\n",
    "        return 0.0\n",
    "\n",
    "    p = (gt_vec / sum_gt).astype(np.float64)\n",
    "    q = (attr_vec / sum_attr).astype(np.float64)\n",
    "    _, log = emd(p, q, C, numItermax=200000, log=True)\n",
    "\n",
    "    d_max = np.sqrt(2 * (d_edge - 1)**2) if d_edge > 1 else 0.0\n",
    "    if d_max == 0:\n",
    "        return 1.0 if np.isclose(log['cost'], 0) else 0.0\n",
    "    return 1.0 - (log['cost'] / d_max)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# IMA\n",
    "# ----------------------\n",
    "def importance_mass_accuracy(gt_mask, attribution):\n",
    "    if not isinstance(gt_mask, np.ndarray) or not isinstance(attribution, np.ndarray):\n",
    "        return np.nan\n",
    "    if attribution.ndim != 1 or len(gt_mask) != len(attribution):\n",
    "        return np.nan\n",
    "    \n",
    "    abs_attribution = np.abs(attribution)\n",
    "    mass_in_gt = np.sum(abs_attribution[gt_mask == 1])\n",
    "    total_mass = np.sum(abs_attribution)\n",
    "    \n",
    "    if total_mass == 0:\n",
    "        return 1.0 if mass_in_gt == 0 else 0.0\n",
    "    return mass_in_gt / total_mass\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Cost matrix (64-D main grid)\n",
    "# ----------------------\n",
    "def create_cost_matrix(grid_edge_length):\n",
    "    if grid_edge_length == 0:\n",
    "        return np.array([]).reshape(0, 0)\n",
    "    total = grid_edge_length * grid_edge_length\n",
    "    if total == 1:\n",
    "        return np.array([[0.0]])\n",
    "    indices_matrix = np.indices((grid_edge_length, grid_edge_length))\n",
    "    coordinates = [(indices_matrix[0][r, c], indices_matrix[1][r, c])\n",
    "                   for r in range(grid_edge_length) for c in range(grid_edge_length)]\n",
    "    coordinates = np.array(coordinates)\n",
    "    return cdist(coordinates, coordinates)\n",
    "\n",
    "COST_MATRIX_MAIN_EFFECTS = create_cost_matrix(D_2D_EDGE)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Main processing (original metrics now full-dim when applicable)\n",
    "# ----------------------\n",
    "INTERACTION_METHODS = {'pattern_gam', 'ebm', 'nam', 'discr', 'pattern_qlr'}\n",
    "\n",
    "def process_explanations_metrics(explanations_dict, main_effect_gt_flat, d_flat_main, d_edge_main, cost_mat_main):\n",
    "    \"\"\"\n",
    "    For interaction methods, compute ORIGINAL metrics using the full feature space:\n",
    "      - NAM/EBM/PatternGAM: length = 64 + len(FAST pairs)\n",
    "      - PatternQLR: length = 64 + D*(D+1)/2 (mains + all degree-2 terms in triu order)\n",
    "    For other methods, keep the 64-D main-effects evaluation.\n",
    "    \"\"\"\n",
    "    results_raw_collection = {} \n",
    "\n",
    "    for scenario_full_name, methods_data in explanations_dict.items():\n",
    "        if 'translations' in scenario_full_name:\n",
    "            continue\n",
    "\n",
    "        scenario_parts = scenario_full_name.split('_')\n",
    "        try:\n",
    "            scenario_base_name = '_'.join(scenario_parts[:-1])\n",
    "        except ValueError:\n",
    "            scenario_base_name = scenario_full_name\n",
    "\n",
    "        is_xor = _is_xor_scenario(scenario_full_name)\n",
    "        idx_t, idx_l = _xor_shape_index_sets(d_edge_main, normal_t, normal_l) if is_xor else (None, None)\n",
    "\n",
    "        # Try to get FAST pairs (order must match models' interaction ordering)\n",
    "        pairs_for_scenario = get_fast_pairs_for_scenario(scenario_full_name, n_interactions=128)\n",
    "\n",
    "        if scenario_base_name not in results_raw_collection:\n",
    "            results_raw_collection[scenario_base_name] = {}\n",
    "\n",
    "        for method_name, explanation_content in methods_data.items():\n",
    "            if method_name not in results_raw_collection[scenario_base_name]:\n",
    "                results_raw_collection[scenario_base_name][method_name] = {'IMA': [], 'EMD': [], 'FNI_EMD': []}\n",
    "\n",
    "            # normalize explanation to a single 1D vector\n",
    "            current_explanation = explanation_content\n",
    "            if isinstance(current_explanation, list):\n",
    "                current_explanation = np.array(current_explanation)\n",
    "\n",
    "            if not isinstance(current_explanation, np.ndarray):\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            if current_explanation.ndim > 1 and current_explanation.shape[0] > 1 and \\\n",
    "               not (current_explanation.shape[0] == d_flat_main and current_explanation.ndim == 2 and current_explanation.shape[1] == 1 and d_flat_main > 1):\n",
    "                if np.ndim(current_explanation[0]) == 3:\n",
    "                    processed_attr = np.mean(np.mean(np.array(current_explanation), axis=0).squeeze(), axis=0)\n",
    "                else:\n",
    "                    processed_attr = np.mean(np.vstack(current_explanation), axis=0)\n",
    "            else:\n",
    "                processed_attr = current_explanation.flatten()\n",
    "\n",
    "            # -----------------------\n",
    "            # Build ground truth & geometry matching the method's mapping\n",
    "            # -----------------------\n",
    "            use_full = (method_name in INTERACTION_METHODS) and (processed_attr.size > d_flat_main)\n",
    "\n",
    "            if method_name in {'nam', 'ebm', 'pattern_gam', 'discr'} and use_full:\n",
    "                # NAM/EBM/PatternGAM: mains + FAST pairs\n",
    "                if len(pairs_for_scenario) == 0:\n",
    "                    # Fall back (cannot fabricate interaction order)\n",
    "                    gt_for_ima = main_effect_gt_flat\n",
    "                    attr_for_ima = processed_attr[:d_flat_main]\n",
    "                    # 64-D EMD/FNI only\n",
    "                    emd_val = calculate_emd_score_metric(main_effect_gt_flat, attr_for_ima, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                    fni_val = calculate_emd_score_metric(main_effect_gt_flat, attr_for_ima, d_edge_main, cost_mat_main, is_fni=True)\n",
    "                    ima_val = importance_mass_accuracy(gt_for_ima, attr_for_ima)\n",
    "                    results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                    results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                    results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "                    continue\n",
    "\n",
    "                # GT (64 + m)\n",
    "                gt_full = create_gt_mask_interactions_generic(\n",
    "                    main_effect_gt_flat, pairs_for_scenario, d_flat_main, d_edge_main, is_xor, idx_t, idx_l\n",
    "                )\n",
    "                m = len(pairs_for_scenario)\n",
    "                # Align attribution length to 64+m\n",
    "                full_len = d_flat_main + m\n",
    "                attr_full = processed_attr[:full_len]\n",
    "                if attr_full.shape[0] != full_len:\n",
    "                    tmp = np.zeros(full_len, dtype=float)\n",
    "                    n = min(len(processed_attr), full_len)\n",
    "                    tmp[:n] = processed_attr[:n]\n",
    "                    attr_full = tmp\n",
    "\n",
    "                # Geometry: mains at grid, interactions at midpoints of FAST pairs\n",
    "                main_coords = _grid_coords_for_main(d_edge_main)         # (64,2)\n",
    "                inter_coords = _coords_for_interactions_from_pairs(d_edge_main, pairs_for_scenario)  # (m,2)\n",
    "                coords = np.vstack([main_coords, inter_coords])          # (64+m,2)\n",
    "                C = cdist(coords, coords)\n",
    "\n",
    "                # IMA / EMD / FNI-EMD in full space\n",
    "                ima_val = importance_mass_accuracy(gt_full, attr_full)\n",
    "                emd_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=False)\n",
    "                fni_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=True)\n",
    "\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "\n",
    "            elif method_name == 'pattern_qlr' and use_full:\n",
    "                # QLR: mains + all quadratic terms in upper-tri order (incl diag)\n",
    "                pairs_triu = qlr_pairs_upper_tri(d_flat_main)\n",
    "                gt_full = create_qlr_ground_truth_mask_generic(\n",
    "                    main_effect_gt_flat, d_flat_main, d_edge_main, is_xor, idx_t, idx_l\n",
    "                )\n",
    "                # Align attribution to (64 + len(triu))\n",
    "                full_len = d_flat_main + len(pairs_triu)\n",
    "                attr_full = processed_attr[:full_len]\n",
    "                if attr_full.shape[0] != full_len:\n",
    "                    tmp = np.zeros(full_len, dtype=float)\n",
    "                    n = min(len(processed_attr), full_len)\n",
    "                    tmp[:n] = processed_attr[:n]\n",
    "                    attr_full = tmp\n",
    "\n",
    "                # Geometry: mains on grid; interactions at midpoints for triu pairs\n",
    "                main_coords = _grid_coords_for_main(d_edge_main)\n",
    "                inter_coords = _coords_for_interactions_from_pairs(d_edge_main, pairs_triu)\n",
    "                coords = np.vstack([main_coords, inter_coords])\n",
    "                C = cdist(coords, coords)\n",
    "\n",
    "                ima_val = importance_mass_accuracy(gt_full, attr_full)\n",
    "                emd_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=False)\n",
    "                fni_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=True)\n",
    "\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "\n",
    "            else:\n",
    "                # Non-interaction methods or methods without interaction tail -> 64-D original behavior\n",
    "                attr_main_eff = processed_attr[:d_flat_main]\n",
    "                gt_main_eff = main_effect_gt_flat\n",
    "\n",
    "                # IMA: 64-D\n",
    "                ima_val = importance_mass_accuracy(gt_main_eff, attr_main_eff)\n",
    "\n",
    "                # EMD & FNI-EMD: 64-D\n",
    "                emd_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=True)\n",
    "\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "\n",
    "    # --- Aggregation ---\n",
    "    final_aggregated_results = {}\n",
    "    for sc_base, meth_data in results_raw_collection.items():\n",
    "        final_aggregated_results[sc_base] = {}\n",
    "        for meth, metrics_lists in meth_data.items():\n",
    "            final_aggregated_results[sc_base][meth] = {\n",
    "                'IMA_mean': np.nanmean(metrics_lists['IMA']) if metrics_lists['IMA'] else np.nan,\n",
    "                'IMA_std':  np.nanstd(metrics_lists['IMA'])  if metrics_lists['IMA'] else np.nan,\n",
    "                'EMD_mean': np.nanmean(metrics_lists['EMD']) if metrics_lists['EMD'] else np.nan,\n",
    "                'EMD_std':  np.nanstd(metrics_lists['EMD'])  if metrics_lists['EMD'] else np.nan,\n",
    "                'FNI_EMD_mean': np.nanmean(metrics_lists['FNI_EMD']) if metrics_lists['FNI_EMD'] else np.nan,\n",
    "                'FNI_EMD_std':  np.nanstd(metrics_lists['FNI_EMD'])  if metrics_lists['FNI_EMD'] else np.nan,\n",
    "            }\n",
    "    return final_aggregated_results\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Run\n",
    "# ----------------------\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"D_2D_EDGE (grid edge for main effects): {D_2D_EDGE}\")\n",
    "print(f\"D_FLAT (total main effect features): {D_FLAT}\")\n",
    "print(f\"Sum of GT_MASK_2D_FLAT (non-XOR main GT): {np.sum(GT_MASK_2D_FLAT)}\")\n",
    "print(f\"Cost matrix for main effects shape: {COST_MATRIX_MAIN_EFFECTS.shape}\")\n",
    "print(f\"--- Starting Metric Calculation ---\")\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)\n",
    "\n",
    "aggregated_metrics = process_explanations_metrics(\n",
    "    explanations,\n",
    "    GT_MASK_2D_FLAT,   # For XOR runs, mains are overridden to 0 inside the GT builders for interaction methods\n",
    "    D_FLAT,\n",
    "    D_2D_EDGE,\n",
    "    COST_MATRIX_MAIN_EFFECTS\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Aggregated Results ---\")\n",
    "for scenario_name, method_data in aggregated_metrics.items():\n",
    "    print(f\"\\nScenario Type: {scenario_name}\")\n",
    "    for method, scores in method_data.items():\n",
    "        print(f\"  Method: {method}\")\n",
    "        print(f\"    IMA    : Mean = {scores['IMA_mean']:.4f}, Std = {scores['IMA_std']:.4f}\")\n",
    "        print(f\"    EMD    : Mean = {scores['EMD_mean']:.4f}, Std = {scores['EMD_std']:.4f}\")\n",
    "        print(f\"    FNI-EMD: Mean = {scores['FNI_EMD_mean']:.4f}, Std = {scores['FNI_EMD_std']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efe0afc-e6d5-4fe6-807b-37e6163e6aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating LaTeX Tables with Final Custom Row and Column Layout ---\n",
      "\n",
      "% --- LaTeX Table for IMA (final layout, bolded best) ---\n",
      "% LaTeX Table for IMA with custom layout and best result emboldened\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Importance Mass Accuracy (IMA). Values are mean $\\pm$ standard deviation. Best result per row is emboldened.}\n",
      "\\label{tab:ima_results_final_layout}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{l|cccccccccc}\n",
      "\\hline\n",
      "Scenario & pattern\\_gam & pattern\\_qlr & nam & ebm & kernel\\_svm & pattern\\_net & pattern\\_attribution & shap & ig & discr \\\\ \\hline\\hline\n",
      "XOR DIST CORR & $0.57 \\pm 0.08$ & $0.23 \\pm 0.04$ & $0.36 \\pm 0.04$ & $0.03 \\pm 0.02$ & $0.12 \\pm 0.05$ & $0.61 \\pm 0.19$ & $\\mathbf{0.77 \\pm 0.13}$ & $0.41 \\pm 0.04$ & $0.73 \\pm 0.09$ & $0.12 \\pm 0.03$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "% --- End of LaTeX Table ---\n",
      "\n",
      "% --- LaTeX Table for EMD (final layout, bolded best) ---\n",
      "% LaTeX Table for EMD with custom layout and best result emboldened\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Earth Mover's Distance (EMD). Values are mean $\\pm$ standard deviation. Best result per row is emboldened.}\n",
      "\\label{tab:emd_results_final_layout}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{l|cccccccccc}\n",
      "\\hline\n",
      "Scenario & pattern\\_gam & pattern\\_qlr & nam & ebm & kernel\\_svm & pattern\\_net & pattern\\_attribution & shap & ig & discr \\\\ \\hline\\hline\n",
      "XOR DIST CORR & $0.81 \\pm 0.02$ & $0.78 \\pm 0.02$ & $0.83 \\pm 0.03$ & $0.82 \\pm 0.00$ & $0.78 \\pm 0.04$ & $0.89 \\pm 0.07$ & $\\mathbf{0.91 \\pm 0.02}$ & $0.87 \\pm 0.02$ & $0.90 \\pm 0.05$ & $0.80 \\pm 0.02$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "% --- End of LaTeX Table ---\n",
      "\n",
      "% --- LaTeX Table for FNI-EMD (final layout, bolded best) ---\n",
      "% LaTeX Table for FNI-EMD with custom layout and best result emboldened\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Feature Preservation Index EMD (FNI-EMD). Values are mean $\\pm$ standard deviation. Best result per row is emboldened.}\n",
      "\\label{tab:fniemd_results_final_layout}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{l|cccccccccc}\n",
      "\\hline\n",
      "Scenario & pattern\\_gam & pattern\\_qlr & nam & ebm & kernel\\_svm & pattern\\_net & pattern\\_attribution & shap & ig & discr \\\\ \\hline\\hline\n",
      "XOR DIST CORR & $0.82 \\pm 0.02$ & $0.79 \\pm 0.02$ & $0.84 \\pm 0.03$ & $0.82 \\pm 0.00$ & $0.79 \\pm 0.04$ & $0.92 \\pm 0.04$ & $\\mathbf{0.96 \\pm 0.03}$ & $0.91 \\pm 0.01$ & $0.96 \\pm 0.01$ & $0.81 \\pm 0.02$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "% --- End of LaTeX Table ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_scenario_name_for_table(scenario_base_name):\n",
    "    \"\"\"\n",
    "    Parses a scenario base name into a formatted string for table rows.\n",
    "    \"\"\"\n",
    "    name_lower = scenario_base_name.lower()\n",
    "    \n",
    "    base_type_str = \"OTHER\" \n",
    "    if \"xor\" in name_lower:\n",
    "        base_type_str = \"XOR\"\n",
    "    elif \"multiplicative\" in name_lower:\n",
    "        base_type_str = \"MULT\"\n",
    "    elif \"linear\" in name_lower: \n",
    "        base_type_str = \"LIN\"\n",
    "    elif \"additive\" in name_lower: \n",
    "        base_type_str = \"LIN\" \n",
    "\n",
    "    dist_str = \"\"\n",
    "    if \"_distractor\" in name_lower or \"distractor_\" in name_lower:\n",
    "        dist_str = \"DIST\"\n",
    "        \n",
    "    bg_str = \"UNK_BG\" \n",
    "    if \"white\" in name_lower:\n",
    "        bg_str = \"WHITE\"\n",
    "    elif \"correlated\" in name_lower:\n",
    "        bg_str = \"CORR\"\n",
    "        \n",
    "    return f\"{base_type_str} {dist_str} {bg_str}\".replace(\"  \", \" \").strip()\n",
    "\n",
    "def get_scenario_sort_key_v2(parsed_scenario_name):\n",
    "    \"\"\"\n",
    "    Generates a sort key tuple for a parsed scenario name to achieve the desired row order:\n",
    "    Primary group: Base Type (LIN, MULT, XOR, OTHER)\n",
    "    Secondary group (within Base Type): Non-DIST vs DIST\n",
    "    Tertiary group (within above): WHITE, CORR, UNK_BG\n",
    "    \"\"\"\n",
    "    parts = parsed_scenario_name.split(' ') \n",
    "\n",
    "    base_type = parts[0] \n",
    "    base_type_key = 3 \n",
    "    if base_type == \"LIN\": base_type_key = 0\n",
    "    elif base_type == \"MULT\": base_type_key = 1\n",
    "    elif base_type == \"XOR\": base_type_key = 2\n",
    "    \n",
    "    is_dist_key = 1 if \"DIST\" in parts else 0\n",
    "\n",
    "    bg_key = 2 \n",
    "    if \"WHITE\" in parts: bg_key = 0\n",
    "    elif \"CORR\" in parts: bg_key = 1\n",
    "        \n",
    "    return (base_type_key, is_dist_key, bg_key)\n",
    "\n",
    "\n",
    "def format_latex_value(mean_val, std_val, precision=2, is_bold=False):\n",
    "    \"\"\"Formats mean and std into LaTeX string, handling NaN and bolding.\"\"\"\n",
    "    if mean_val is None or std_val is None or np.isnan(mean_val) or np.isnan(std_val):\n",
    "        return \"-\"\n",
    "    \n",
    "    mean_str = f\"{mean_val:.{precision}f}\"\n",
    "    std_str = f\"{std_val:.{precision}f}\"\n",
    "    core_expression = f\"{mean_str} \\\\pm {std_str}\"\n",
    "    \n",
    "    if is_bold:\n",
    "        return f\"$\\\\mathbf{{{core_expression}}}$\"\n",
    "    else:\n",
    "        return f\"${core_expression}$\"\n",
    "\n",
    "def generate_latex_tables_final_layout(aggregated_metrics): # Renamed main function\n",
    "    \"\"\"\n",
    "    Generates three LaTeX tables (IMA, EMD, FNI-EMD) from aggregated metrics,\n",
    "    with specified row and column sorting, and emboldening the best result per row.\n",
    "    \"\"\"\n",
    "    data_for_tables = {}\n",
    "    all_method_names_in_data = set()\n",
    "\n",
    "    for scenario_base_name, methods_data in aggregated_metrics.items():\n",
    "        parsed_name = parse_scenario_name_for_table(scenario_base_name)\n",
    "        if parsed_name not in data_for_tables:\n",
    "            data_for_tables[parsed_name] = {}\n",
    "        \n",
    "        for method_name, metrics_values in methods_data.items():\n",
    "            all_method_names_in_data.add(method_name)\n",
    "            data_for_tables[parsed_name][method_name] = metrics_values\n",
    "\n",
    "    # Sort row labels using the custom key\n",
    "    sorted_row_labels = sorted(list(data_for_tables.keys()), key=get_scenario_sort_key_v2)\n",
    "    \n",
    "    # Define custom column order\n",
    "    custom_column_order = [\n",
    "        'pattern_gam', 'pattern_qlr', 'nam', 'ebm', 'kernel_svm', \n",
    "        'pattern_net', 'pattern_attribution', 'shap', 'ig'\n",
    "    ]\n",
    "\n",
    "    # Create the final ordered list of method names for columns\n",
    "    ordered_method_columns = [method for method in custom_column_order if method in all_method_names_in_data]\n",
    "    \n",
    "    remaining_methods_in_data = sorted(\n",
    "        [method for method in all_method_names_in_data if method not in ordered_method_columns]\n",
    "    )\n",
    "    ordered_method_columns.extend(remaining_methods_in_data)\n",
    "\n",
    "\n",
    "    latex_output_tables = {}\n",
    "    metrics_config = [\n",
    "        (\"IMA\", \"IMA_mean\", \"IMA_std\", \"Importance Mass Accuracy (IMA)\"),\n",
    "        (\"EMD\", \"EMD_mean\", \"EMD_std\", \"Earth Mover's Distance (EMD)\"),\n",
    "        (\"FNI-EMD\", \"FNI_EMD_mean\", \"FNI_EMD_std\", \"Feature Preservation Index EMD (FNI-EMD)\")\n",
    "    ]\n",
    "\n",
    "    for metric_key, mean_key, std_key, caption_title in metrics_config:\n",
    "        num_columns = len(ordered_method_columns)\n",
    "        table_cols_format = \"l|\" + \"c\" * num_columns \n",
    "        \n",
    "        latex_str = f\"% LaTeX Table for {metric_key} with custom layout and best result emboldened\\n\"\n",
    "        latex_str += \"\\\\begin{table}[htbp]\\n\"\n",
    "        latex_str += \"\\\\centering\\n\"\n",
    "        latex_str += f\"\\\\caption{{{caption_title}. Values are mean $\\\\pm$ standard deviation. Best result per row is emboldened.}}\\n\"\n",
    "        latex_str += f\"\\\\label{{tab:{metric_key.lower().replace('-', '')}_results_final_layout}}\\n\"\n",
    "        latex_str += f\"\\\\resizebox{{\\\\textwidth}}{{!}}{{\\n\" \n",
    "        latex_str += f\"\\\\begin{{tabular}}{{{table_cols_format}}}\\n\"\n",
    "        latex_str += \"\\\\hline\\n\"\n",
    "        \n",
    "        header_methods = [name.replace(\"_\", \"\\\\_\") for name in ordered_method_columns]\n",
    "        latex_str += \"Scenario & \" + \" & \".join(header_methods) + \" \\\\\\\\ \\\\hline\\\\hline\\n\"\n",
    "        \n",
    "        for row_label in sorted_row_labels:\n",
    "            means_for_current_row = []\n",
    "            for method_name_iter in ordered_method_columns: # Use the new column order here\n",
    "                val = data_for_tables.get(row_label, {}).get(method_name_iter, {}).get(mean_key)\n",
    "                if val is not None and not np.isnan(val):\n",
    "                    means_for_current_row.append(val)\n",
    "                else:\n",
    "                    means_for_current_row.append(-np.inf) \n",
    "\n",
    "            max_mean_in_row = -np.inf \n",
    "            if any(m != -np.inf for m in means_for_current_row):\n",
    "                max_mean_in_row = np.nanmax([m if m != -np.inf else np.nan for m in means_for_current_row])\n",
    "\n",
    "            row_values_formatted = [row_label] \n",
    "            for method_name in ordered_method_columns: # And here for data fetching\n",
    "                method_metrics = data_for_tables.get(row_label, {}).get(method_name, {})\n",
    "                mean_val = method_metrics.get(mean_key)\n",
    "                std_val = method_metrics.get(std_key)\n",
    "                \n",
    "                is_best_in_row = False\n",
    "                if mean_val is not None and not np.isnan(mean_val) and \\\n",
    "                   max_mean_in_row != -np.inf and not np.isnan(max_mean_in_row):\n",
    "                    if np.isclose(mean_val, max_mean_in_row):\n",
    "                        is_best_in_row = True\n",
    "                \n",
    "                row_values_formatted.append(format_latex_value(mean_val, std_val, is_bold=is_best_in_row))\n",
    "            \n",
    "            latex_str += \" & \".join(row_values_formatted) + \" \\\\\\\\\\n\"\n",
    "            \n",
    "        latex_str += \"\\\\hline\\n\"\n",
    "        latex_str += \"\\\\end{tabular}\\n\"\n",
    "        latex_str += \"}\\n\" \n",
    "        latex_str += \"\\\\end{table}\\n\"\n",
    "        \n",
    "        latex_output_tables[metric_key] = latex_str\n",
    "        \n",
    "    return latex_output_tables\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Sample aggregated_metrics dictionary to test sorting and column order\n",
    "\n",
    "\n",
    "    print(\"--- Generating LaTeX Tables with Final Custom Row and Column Layout ---\")\n",
    "    latex_tables_final_layout = generate_latex_tables_final_layout(aggregated_metrics)\n",
    "\n",
    "    for metric_name, table_code in latex_tables_final_layout.items():\n",
    "        print(f\"\\n% --- LaTeX Table for {metric_name} (final layout, bolded best) ---\")\n",
    "        print(table_code)\n",
    "        print(\"% --- End of LaTeX Table ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc9c1b4-2ae3-400f-bcb5-fb39d9fb5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "D_2D_EDGE (grid edge for main effects): 8\n",
      "D_FLAT (total main effect features): 64\n",
      "Sum of GT_MASK_2D_FLAT: 8\n",
      "Cost matrix for main effects shape: (64, 64)\n",
      "--- Starting Metric Calculation (with redistribution) ---\n",
      "\n",
      "--- Aggregated Results (Original, Sum, Weighted, Max) ---\n",
      "\n",
      "=== Scenario: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated ===\n",
      "\n",
      "IMA (Importance Mass Accuracy):\n",
      "                            original              sum         weighted              max\n",
      "discr                0.1178 ± 0.0273  0.8692 ± 0.0238  0.7617 ± 0.0510  0.8956 ± 0.0193\n",
      "ebm                  0.0304 ± 0.0184  0.1441 ± 0.0599  0.0784 ± 0.0310  0.1187 ± 0.0659\n",
      "ig                   0.7278 ± 0.0947  0.7278 ± 0.0947  0.7278 ± 0.0947  0.7278 ± 0.0947\n",
      "kernel_svm           0.1231 ± 0.0520  0.1231 ± 0.0520  0.1231 ± 0.0520  0.1231 ± 0.0520\n",
      "nam                  0.3641 ± 0.0440  0.5350 ± 0.0364  0.3663 ± 0.0808  0.4708 ± 0.0606\n",
      "pattern_attribution  0.7687 ± 0.1277  0.7687 ± 0.1277  0.7687 ± 0.1277  0.7687 ± 0.1277\n",
      "pattern_gam          0.5688 ± 0.0803  0.6537 ± 0.0521  0.4889 ± 0.1072  0.6180 ± 0.0679\n",
      "pattern_net          0.6141 ± 0.1915  0.6141 ± 0.1915  0.6141 ± 0.1915  0.6141 ± 0.1915\n",
      "pattern_qlr          0.2278 ± 0.0385  0.4286 ± 0.0132  0.3414 ± 0.0063  0.5864 ± 0.0835\n",
      "shap                 0.4130 ± 0.0354  0.4130 ± 0.0354  0.4130 ± 0.0354  0.4130 ± 0.0354\n",
      "\n",
      "EMD:\n",
      "                            original              sum         weighted              max\n",
      "discr                0.7986 ± 0.0207  0.9457 ± 0.0056  0.9176 ± 0.0182  0.9430 ± 0.0052\n",
      "ebm                  0.8151 ± 0.0017  0.7888 ± 0.0304  0.7700 ± 0.0186  0.7796 ± 0.0325\n",
      "ig                   0.8995 ± 0.0460  0.8995 ± 0.0460  0.8995 ± 0.0460  0.8995 ± 0.0460\n",
      "kernel_svm           0.7781 ± 0.0351  0.7781 ± 0.0351  0.7781 ± 0.0351  0.7781 ± 0.0351\n",
      "nam                  0.8256 ± 0.0312  0.8918 ± 0.0115  0.8687 ± 0.0137  0.8779 ± 0.0144\n",
      "pattern_attribution  0.9095 ± 0.0230  0.9095 ± 0.0230  0.9095 ± 0.0230  0.9095 ± 0.0230\n",
      "pattern_gam          0.8095 ± 0.0182  0.9203 ± 0.0112  0.8816 ± 0.0176  0.9144 ± 0.0123\n",
      "pattern_net          0.8891 ± 0.0687  0.8891 ± 0.0687  0.8891 ± 0.0687  0.8891 ± 0.0687\n",
      "pattern_qlr          0.7832 ± 0.0221  0.8818 ± 0.0092  0.8564 ± 0.0100  0.9194 ± 0.0219\n",
      "shap                 0.8734 ± 0.0237  0.8734 ± 0.0237  0.8734 ± 0.0237  0.8734 ± 0.0237\n",
      "\n",
      "FNI-EMD:\n",
      "                            original              sum         weighted              max\n",
      "discr                0.8052 ± 0.0216  0.9729 ± 0.0065  0.9516 ± 0.0112  0.9790 ± 0.0046\n",
      "ebm                  0.8213 ± 0.0017  0.8129 ± 0.0270  0.7850 ± 0.0229  0.8009 ± 0.0317\n",
      "ig                   0.9580 ± 0.0128  0.9580 ± 0.0128  0.9580 ± 0.0128  0.9580 ± 0.0128\n",
      "kernel_svm           0.7869 ± 0.0377  0.7869 ± 0.0377  0.7869 ± 0.0377  0.7869 ± 0.0377\n",
      "nam                  0.8414 ± 0.0304  0.9150 ± 0.0127  0.8853 ± 0.0125  0.9058 ± 0.0167\n",
      "pattern_attribution  0.9603 ± 0.0289  0.9603 ± 0.0289  0.9603 ± 0.0289  0.9603 ± 0.0289\n",
      "pattern_gam          0.8196 ± 0.0202  0.9308 ± 0.0096  0.8970 ± 0.0196  0.9250 ± 0.0133\n",
      "pattern_net          0.9235 ± 0.0400  0.9235 ± 0.0400  0.9235 ± 0.0400  0.9235 ± 0.0400\n",
      "pattern_qlr          0.7941 ± 0.0250  0.8908 ± 0.0052  0.8679 ± 0.0087  0.9260 ± 0.0210\n",
      "shap                 0.9112 ± 0.0105  0.9112 ± 0.0105  0.9112 ± 0.0105  0.9112 ± 0.0105\n"
     ]
    }
   ],
   "source": [
    "# ==== ADDITIONS / REPLACEMENTS START HERE ====\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot import emd\n",
    "\n",
    "# -----------------------------\n",
    "# (1) Redistribution functions\n",
    "# -----------------------------\n",
    "\n",
    "# --- original sum version (absolute attributions; each pair split 0.5/0.5) ---\n",
    "def transform_interaction_sum(pattern, interaction_pairs=(), d=64):\n",
    "    pattern = np.asarray(pattern)\n",
    "    feat_imp = np.zeros(d, dtype=float)\n",
    "    feat_imp += np.abs(pattern[:d])\n",
    "    inter_vals = np.abs(pattern[d:])\n",
    "    for k, (i, j) in enumerate(interaction_pairs):\n",
    "        v = inter_vals[k]\n",
    "        feat_imp[i] += 0.5 * v\n",
    "        feat_imp[j] += 0.5 * v\n",
    "    return feat_imp\n",
    "\n",
    "# --- weighted sum version (divide pairwise mass by node degree) ---\n",
    "def transform_interaction_weighted_sum(pattern, interaction_pairs=(), d=64):\n",
    "    pattern = np.asarray(pattern)\n",
    "    main_abs = np.abs(pattern[:d])\n",
    "    inter_vals = np.abs(pattern[d:])\n",
    "\n",
    "    inter_sum = np.zeros(d, dtype=float)\n",
    "    degree = np.zeros(d, dtype=float)\n",
    "\n",
    "    for k, (i, j) in enumerate(interaction_pairs):\n",
    "        v = inter_vals[k]\n",
    "        inter_sum[i] += v\n",
    "        inter_sum[j] += v\n",
    "        degree[i] += 1.0\n",
    "        degree[j] += 1.0\n",
    "\n",
    "    # divide per-feature interaction mass by its incident count when > 0\n",
    "    out = main_abs.copy()\n",
    "    nonzero = degree > 0\n",
    "    out[nonzero] += inter_sum[nonzero] / degree[nonzero]\n",
    "    out[~nonzero] += 0.0\n",
    "    return out\n",
    "\n",
    "# --- max redistribution, signed (metrics later take abs anyway) ---\n",
    "def transform_interaction_max_signed(pattern, interaction_pairs=(), d=None):\n",
    "    pattern = np.asarray(pattern)\n",
    "    m = len(interaction_pairs)\n",
    "    if d is None:\n",
    "        d = pattern.size - m\n",
    "    if d + m != pattern.size or d <= 0:\n",
    "        raise ValueError(\"Length mismatch: expected len(pattern) == d + len(interaction_pairs).\")\n",
    "    main = pattern[:d]\n",
    "    inter = pattern[d:] if m > 0 else np.empty(0, dtype=pattern.dtype)\n",
    "    adj = [[] for _ in range(d)]\n",
    "    for k, (i, j) in enumerate(interaction_pairs):\n",
    "        if not (0 <= i < d and 0 <= j < d):\n",
    "            raise ValueError(f\"interaction_pairs[{k}] = ({i},{j}) out of range [0,{d-1}]\")\n",
    "        adj[i].append(k); adj[j].append(k)\n",
    "    out = np.empty(d, dtype=float)\n",
    "    for i in range(d):\n",
    "        best_val = float(main[i]); best_abs = abs(best_val)\n",
    "        for k in adj[i]:\n",
    "            v = float(inter[k]); av = abs(v)\n",
    "            if av > best_abs:\n",
    "                best_val = v; best_abs = av\n",
    "        out[i] = best_val\n",
    "    return out\n",
    "\n",
    "# helper: unsigned version of max (for symmetry with the other two)\n",
    "def transform_interaction_max_abs(pattern, interaction_pairs=(), d=64):\n",
    "    return np.abs(transform_interaction_max_signed(pattern, interaction_pairs, d=d))\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# (2) QLR interaction-pair construction\n",
    "# ---------------------------------------\n",
    "def qlr_pairs_upper_tri(d):\n",
    "    \"\"\"Pairs (i,j) with i <= j, in the same order as np.triu_indices(d, 0).\"\"\"\n",
    "    i_idx, j_idx = np.triu_indices(d, 0)\n",
    "    return list(zip(i_idx.tolist(), j_idx.tolist()))\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (3) Metric functions (FNI -> FNI rename applied)\n",
    "# -------------------------------------------------\n",
    "def importance_mass_accuracy(gt_mask, attribution):\n",
    "    if not isinstance(gt_mask, np.ndarray) or not isinstance(attribution, np.ndarray):\n",
    "        return np.nan\n",
    "    if attribution.ndim != 1 or len(gt_mask) != len(attribution):\n",
    "        return np.nan\n",
    "    abs_attr = np.abs(attribution)\n",
    "    mass_in_gt = np.sum(abs_attr[gt_mask == 1])\n",
    "    total_mass = np.sum(abs_attr)\n",
    "    if total_mass == 0:\n",
    "        return 1.0 if mass_in_gt == 0 else 0.0\n",
    "    return mass_in_gt / total_mass\n",
    "\n",
    "def create_cost_matrix(grid_edge_length):\n",
    "    if grid_edge_length == 0:\n",
    "        return np.array([]).reshape(0,0)\n",
    "    total = grid_edge_length * grid_edge_length\n",
    "    if total == 1:\n",
    "        return np.array([[0.0]])\n",
    "    indices_matrix = np.indices((grid_edge_length, grid_edge_length))\n",
    "    coordinates = [(indices_matrix[0][r, c], indices_matrix[1][r, c])\n",
    "                   for r in range(grid_edge_length) for c in range(grid_edge_length)]\n",
    "    coordinates = np.array(coordinates)\n",
    "    return cdist(coordinates, coordinates)\n",
    "\n",
    "def calculate_emd_score_metric(gt_mask_flat, attribution_flat, grid_edge_length, base_cost_matrix, is_fni=False):\n",
    "    # Same implementation as your original, only the flag/name changed to is_fni.\n",
    "    if not (isinstance(gt_mask_flat, np.ndarray) and gt_mask_flat.ndim == 1 and\n",
    "            isinstance(attribution_flat, np.ndarray) and attribution_flat.ndim == 1 and\n",
    "            len(gt_mask_flat) == len(attribution_flat) and\n",
    "            len(gt_mask_flat) == grid_edge_length * grid_edge_length):\n",
    "        return np.nan\n",
    "\n",
    "    current_cost_matrix = np.copy(base_cost_matrix)\n",
    "    if is_fni:\n",
    "        gt_indices = np.where(gt_mask_flat == 1)[0]\n",
    "        for r_idx in gt_indices:\n",
    "            for c_idx in gt_indices:\n",
    "                if r_idx < current_cost_matrix.shape[0] and c_idx < current_cost_matrix.shape[1]:\n",
    "                    current_cost_matrix[r_idx, c_idx] = 0.0\n",
    "\n",
    "    sum_gt = np.sum(gt_mask_flat)\n",
    "    abs_attribution = np.abs(attribution_flat)\n",
    "    sum_attr = np.sum(abs_attribution)\n",
    "\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9:\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9:\n",
    "        return 0.0\n",
    "\n",
    "    dist_gt = gt_mask_flat.astype(np.float64) / sum_gt\n",
    "    dist_attr = abs_attribution.astype(np.float64) / sum_attr\n",
    "\n",
    "    dist_gt_c = np.ascontiguousarray(dist_gt, dtype=np.float64)\n",
    "    dist_attr_c = np.ascontiguousarray(dist_attr, dtype=np.float64)\n",
    "    current_cost_matrix_c = np.ascontiguousarray(current_cost_matrix, dtype=np.float64)\n",
    "\n",
    "    cost_val = 0.0\n",
    "    if grid_edge_length * grid_edge_length > 1:\n",
    "        try:\n",
    "            _, cost_val = emd(dist_gt_c, dist_attr_c, current_cost_matrix_c, numItermax=200000, log=True)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    d_max = np.sqrt(2 * (grid_edge_length - 1)**2) if grid_edge_length > 1 else 0.0\n",
    "    if d_max == 0:\n",
    "        return 1.0 if np.isclose(cost_val, 0) else 0.0\n",
    "\n",
    "    return 1 - (cost_val['cost'] / d_max)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# (4) Main processing extended with redistribution + FNI terminology\n",
    "# --------------------------------------------------------------------\n",
    "def process_explanations_metrics_with_redistribution(\n",
    "    explanations_dict, gt_mask_main_flat, d_flat_main, d_edge_main, cost_mat_main,\n",
    "    fast_func_for_pairs  # function FAST to recover interaction pairs when needed\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes metrics in four variants:\n",
    "      - original (your current behavior)\n",
    "      - sum redistribution (64-D)\n",
    "      - weighted sum redistribution (64-D)\n",
    "      - max redistribution (64-D)\n",
    "\n",
    "    Returns nested dict: results[scenario_base][method][metric_variant]['IMA'|'EMD'|'FNI-EMD'] -> list of values,\n",
    "    and aggregated means/stds.\n",
    "    \"\"\"\n",
    "    # raw collections\n",
    "    results_raw = {}  # results_raw[scenario_base][method][variant]['IMA'|'EMD'|'FNI-EMD'] -> list\n",
    "\n",
    "    for scenario_full_name, methods_data in explanations_dict.items():\n",
    "        if 'translations' in scenario_full_name:\n",
    "            continue\n",
    "\n",
    "        parts = scenario_full_name.split('_')\n",
    "        try:\n",
    "            scenario_base_name = '_'.join(parts[:-1])\n",
    "        except ValueError:\n",
    "            scenario_base_name = scenario_full_name\n",
    "\n",
    "        # default: no interaction pairs\n",
    "        interaction_pairs_for_scenario = []\n",
    "        if 'xor' in scenario_full_name.lower():\n",
    "            # load training data to re-run FAST as you do\n",
    "            data_path = f'./data/xai_tris/{scenario_full_name}.pkl'\n",
    "            try:\n",
    "                with open(data_path, \"rb\") as f:\n",
    "                    data = pkl.load(f)\n",
    "                X_train_tensor = data.x_train.float()\n",
    "                y_train_tensor = data.y_train\n",
    "                interaction_pairs_for_scenario, _ = fast_func_for_pairs(\n",
    "                    X_train_tensor, y_train_tensor, n_interactions=128\n",
    "                )\n",
    "            except Exception:\n",
    "                interaction_pairs_for_scenario = []\n",
    "\n",
    "        if scenario_base_name not in results_raw:\n",
    "            results_raw[scenario_base_name] = {}\n",
    "\n",
    "        for method_name, explanation_content in methods_data.items():\n",
    "            if method_name not in results_raw[scenario_base_name]:\n",
    "                results_raw[scenario_base_name][method_name] = {\n",
    "                    'original': {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                    'sum':      {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                    'weighted': {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                    'max':      {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                }\n",
    "\n",
    "            # normalize explanation to 1D vector (global) or mean over samples\n",
    "            current_explanation = explanation_content\n",
    "            if isinstance(current_explanation, list):\n",
    "                current_explanation = np.array(current_explanation)\n",
    "\n",
    "            if not isinstance(current_explanation, np.ndarray):\n",
    "                # store NaNs for all four variants\n",
    "                for v in ['original','sum','weighted','max']:\n",
    "                    for m in ['IMA','EMD','FNI-EMD']:\n",
    "                        results_raw[scenario_base_name][method_name][v][m].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            if current_explanation.ndim > 1 and current_explanation.shape[0] > 1 and \\\n",
    "               not (current_explanation.shape[0] == d_flat_main and current_explanation.ndim == 2 and current_explanation.shape[1] == 1 and d_flat_main > 1):\n",
    "                if np.ndim(current_explanation[0]) == 3:\n",
    "                    processed_attr = np.mean(np.mean(np.array(current_explanation), axis=0).squeeze(), axis=0)\n",
    "                else:\n",
    "                    processed_attr = np.mean(np.vstack(current_explanation), axis=0)\n",
    "            else:\n",
    "                processed_attr = current_explanation.flatten()\n",
    "\n",
    "            # -----------------------\n",
    "            # (4a) ORIGINAL metrics\n",
    "            # -----------------------\n",
    "            # IMA: replicate your prior logic for GT construction per method\n",
    "            XOR_GT_MASK_MAIN_FLAT = np.zeros(D_FLAT, dtype=int)\n",
    "            \n",
    "            if method_name in ['pattern_gam', 'ebm', 'nam'] and 'xor' in scenario_full_name.lower():\n",
    "                gt_mask_for_ima = create_gt_mask_interactions_1d(XOR_GT_MASK_MAIN_FLAT, interaction_pairs_for_scenario, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            elif method_name == 'pattern_qlr':\n",
    "                gt_mask_for_ima = create_qlr_ground_truth_mask_1d(XOR_GT_MASK_MAIN_FLAT, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            else:\n",
    "                gt_mask_for_ima = gt_mask_main_flat\n",
    "                attr_for_ima = processed_attr[:d_flat_main]\n",
    "\n",
    "            if len(attr_for_ima) != len(gt_mask_for_ima):\n",
    "                tmp = np.zeros(len(gt_mask_for_ima))\n",
    "                n = min(len(attr_for_ima), len(gt_mask_for_ima))\n",
    "                tmp[:n] = attr_for_ima[:n]\n",
    "                attr_for_ima = tmp\n",
    "\n",
    "            ima_val = importance_mass_accuracy(gt_mask_for_ima, attr_for_ima)\n",
    "\n",
    "            # EMD/FNI-EMD on main effects only\n",
    "            attr_main_eff = processed_attr[:d_flat_main]\n",
    "            emd_val = np.nan\n",
    "            fni_emd_val = np.nan\n",
    "            if len(attr_main_eff) == d_flat_main and d_flat_main > 0:\n",
    "                emd_val = calculate_emd_score_metric(gt_mask_main_flat, attr_main_eff, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_emd_val = calculate_emd_score_metric(gt_mask_main_flat, attr_main_eff, d_edge_main, cost_mat_main, is_fni=True)\n",
    "\n",
    "            results_raw[scenario_base_name][method_name]['original']['IMA'].append(ima_val)\n",
    "            results_raw[scenario_base_name][method_name]['original']['EMD'].append(emd_val)\n",
    "            results_raw[scenario_base_name][method_name]['original']['FNI-EMD'].append(fni_emd_val)\n",
    "\n",
    "            # ---------------------------------------------------\n",
    "            # (4b) REDISTRIBUTIONS back to 64-D and 64-D metrics\n",
    "            # ---------------------------------------------------\n",
    "            # Decide interaction pairs for redistribution\n",
    "            # For QLR: pairs are upper-tri on 64-D (in the same order used to build z^QLR)\n",
    "            # For others: use FAST pairs when available.\n",
    "            pairs = []\n",
    "            d_expected = d_flat_main\n",
    "\n",
    "            if method_name == 'pattern_qlr':\n",
    "                pairs = qlr_pairs_upper_tri(d_expected)\n",
    "            else:\n",
    "                pairs = interaction_pairs_for_scenario\n",
    "\n",
    "            # make the pair list fit the tail length if mismatch\n",
    "            m_expected = len(pairs)\n",
    "            m_from_vec = max(0, len(processed_attr) - d_expected)\n",
    "            if m_from_vec <= 0:\n",
    "                # nothing to redistribute; fall back to plain 64-D main effects\n",
    "                red_sum = np.abs(processed_attr[:d_expected])\n",
    "                red_weighted = red_sum.copy()\n",
    "                red_max = red_sum.copy()\n",
    "            else:\n",
    "                if m_expected != m_from_vec:\n",
    "                    # trim or pad pairs (padding cannot invent structure -> trim to fit)\n",
    "                    pairs = pairs[:m_from_vec]\n",
    "                    m_expected = len(pairs)\n",
    "                    if d_expected + m_expected != len(processed_attr):\n",
    "                        # as a last resort, skip redistribution (use main effects only)\n",
    "                        red_sum = np.abs(processed_attr[:d_expected])\n",
    "                        red_weighted = red_sum.copy()\n",
    "                        red_max = red_sum.copy()\n",
    "                    else:\n",
    "                        red_sum = transform_interaction_sum(processed_attr, pairs, d=d_expected)\n",
    "                        red_weighted = transform_interaction_weighted_sum(processed_attr, pairs, d=d_expected)\n",
    "                        # max uses signed; convert to abs for metric parity\n",
    "                        red_max = transform_interaction_max_abs(processed_attr, pairs, d=d_expected)\n",
    "                else:\n",
    "                    red_sum = transform_interaction_sum(processed_attr, pairs, d=d_expected)\n",
    "                    red_weighted = transform_interaction_weighted_sum(processed_attr, pairs, d=d_expected)\n",
    "                    red_max = transform_interaction_max_abs(processed_attr, pairs, d=d_expected)\n",
    "\n",
    "            # Metrics on redistributed 64-D vectors\n",
    "            for variant_name, vattr in [('sum', red_sum), ('weighted', red_weighted), ('max', red_max)]:\n",
    "                ima_r = importance_mass_accuracy(gt_mask_main_flat, vattr)\n",
    "                emd_r = calculate_emd_score_metric(gt_mask_main_flat, vattr, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_r = calculate_emd_score_metric(gt_mask_main_flat, vattr, d_edge_main, cost_mat_main, is_fni=True)\n",
    "                results_raw[scenario_base_name][method_name][variant_name]['IMA'].append(ima_r)\n",
    "                results_raw[scenario_base_name][method_name][variant_name]['EMD'].append(emd_r)\n",
    "                results_raw[scenario_base_name][method_name][variant_name]['FNI-EMD'].append(fni_r)\n",
    "\n",
    "    # ----------------------\n",
    "    # aggregate mean / std\n",
    "    # ----------------------\n",
    "    aggregated = {}\n",
    "    for sc_base, meth_data in results_raw.items():\n",
    "        aggregated[sc_base] = {}\n",
    "        for meth, variants in meth_data.items():\n",
    "            aggregated[sc_base][meth] = {}\n",
    "            for variant, metric_lists in variants.items():\n",
    "                aggregated[sc_base][meth][variant] = {\n",
    "                    'IMA_mean': np.nanmean(metric_lists['IMA']) if metric_lists['IMA'] else np.nan,\n",
    "                    'IMA_std':  np.nanstd(metric_lists['IMA'])  if metric_lists['IMA'] else np.nan,\n",
    "                    'EMD_mean': np.nanmean(metric_lists['EMD']) if metric_lists['EMD'] else np.nan,\n",
    "                    'EMD_std':  np.nanstd(metric_lists['EMD'])  if metric_lists['EMD'] else np.nan,\n",
    "                    'FNI-EMD_mean': np.nanmean(metric_lists['FNI-EMD']) if metric_lists['FNI-EMD'] else np.nan,\n",
    "                    'FNI-EMD_std':  np.nanstd(metric_lists['FNI-EMD'])  if metric_lists['FNI-EMD'] else np.nan,\n",
    "                }\n",
    "    return results_raw, aggregated\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# (5) Pretty printing: compact tables per metric\n",
    "# --------------------------------------------------------\n",
    "def print_metric_tables(aggregated_results):\n",
    "    \"\"\"\n",
    "    For each scenario, prints three tables (IMA / EMD / FNI-EMD).\n",
    "    Rows: methods; Columns: original / sum / weighted / max as Mean ± Std (4 decimals).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    for scenario_name, method_data in aggregated_results.items():\n",
    "        methods = sorted(method_data.keys())\n",
    "\n",
    "        # build per-metric dataframes\n",
    "        cols = ['original','sum','weighted','max']\n",
    "        def fmt(m, s):\n",
    "            if np.isnan(m) or np.isnan(s):\n",
    "                return \"nan\"\n",
    "            return f\"{m:.4f} ± {s:.4f}\"\n",
    "\n",
    "        tables = {'IMA': [], 'EMD': [], 'FNI-EMD': []}\n",
    "        for meth in methods:\n",
    "            row_ima, row_emd, row_fni = [], [], []\n",
    "            for v in cols:\n",
    "                stats = method_data[meth][v]\n",
    "                row_ima.append(fmt(stats['IMA_mean'], stats['IMA_std']))\n",
    "                row_emd.append(fmt(stats['EMD_mean'], stats['EMD_std']))\n",
    "                row_fni.append(fmt(stats['FNI-EMD_mean'], stats['FNI-EMD_std']))\n",
    "            tables['IMA'].append(row_ima)\n",
    "            tables['EMD'].append(row_emd)\n",
    "            tables['FNI-EMD'].append(row_fni)\n",
    "\n",
    "        print(f\"\\n=== Scenario: {scenario_name} ===\")\n",
    "        df_ima = pd.DataFrame(tables['IMA'], index=methods, columns=cols)\n",
    "        df_emd = pd.DataFrame(tables['EMD'], index=methods, columns=cols)\n",
    "        df_fni = pd.DataFrame(tables['FNI-EMD'], index=methods, columns=cols)\n",
    "\n",
    "        print(\"\\nIMA (Importance Mass Accuracy):\")\n",
    "        print(df_ima.to_string())\n",
    "\n",
    "        print(\"\\nEMD:\")\n",
    "        print(df_emd.to_string())\n",
    "\n",
    "        print(\"\\nFNI-EMD:\")\n",
    "        print(df_fni.to_string())\n",
    "\n",
    "\n",
    "# ======================\n",
    "# ===== USAGE EXAMPLE ==\n",
    "# ======================\n",
    "# (Keep your existing configuration / GT / COST matrix creation as-is.)\n",
    "# Ensure the following are already defined in your script before this section:\n",
    "# - D_2D_EDGE, D_FLAT, GT_MASK_2D_FLAT, COST_MATRIX_MAIN_EFFECTS\n",
    "# - FAST (as provided), create_gt_mask_interactions_1d, create_qlr_ground_truth_mask_1d\n",
    "# - calculate_emd_score_metric (replaced above to use is_fni and 'FNI-EMD' naming)\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"D_2D_EDGE (grid edge for main effects): {D_2D_EDGE}\")\n",
    "print(f\"D_FLAT (total main effect features): {D_FLAT}\")\n",
    "print(f\"Sum of GT_MASK_2D_FLAT: {np.sum(GT_MASK_2D_FLAT)}\")\n",
    "print(f\"Cost matrix for main effects shape: {COST_MATRIX_MAIN_EFFECTS.shape}\")\n",
    "print(f\"--- Starting Metric Calculation (with redistribution) ---\")\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)\n",
    "\n",
    "# Compute\n",
    "results_raw_all, aggregated_all = process_explanations_metrics_with_redistribution(\n",
    "    explanations,\n",
    "    GT_MASK_2D_FLAT,\n",
    "    D_FLAT,\n",
    "    D_2D_EDGE,\n",
    "    COST_MATRIX_MAIN_EFFECTS,\n",
    "    FAST  # pass your FAST function for pair discovery\n",
    ")\n",
    "\n",
    "# Print compact tables per scenario\n",
    "print(\"\\n--- Aggregated Results (Original, Sum, Weighted, Max) ---\")\n",
    "print_metric_tables(aggregated_all)\n",
    "\n",
    "# ==== END ADDITIONS / REPLACEMENTS ====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6374998d-12a8-4d7e-a407-4e5377ba7c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated ===\n",
      "\n",
      "IMA:\n",
      "|               | Original (feature space)   | Sum (redistributed)   | Weighted sum (redistributed)   | Max (redistributed)   |\n",
      "|---------------|----------------------------|-----------------------|--------------------------------|-----------------------|\n",
      "| DISCR         | 0.1178 ± 0.0273            | **0.8692 ± 0.0238**   | 0.7617 ± 0.0510                | **0.8956 ± 0.0193**   |\n",
      "| PatternGAM    | 0.5688 ± 0.0803            | 0.6537 ± 0.0521       | 0.4889 ± 0.1072                | 0.6180 ± 0.0679       |\n",
      "| PatternQLR    | 0.2278 ± 0.0385            | 0.4286 ± 0.0132       | 0.3414 ± 0.0063                | 0.5864 ± 0.0835       |\n",
      "| KernelPattern | 0.1231 ± 0.0520            | 0.1231 ± 0.0520       | 0.1231 ± 0.0520                | 0.1231 ± 0.0520       |\n",
      "| PatternAttr   | **0.7687 ± 0.1277**        | 0.7687 ± 0.1277       | **0.7687 ± 0.1277**            | 0.7687 ± 0.1277       |\n",
      "| PatternNet    | 0.6141 ± 0.1915            | 0.6141 ± 0.1915       | 0.6141 ± 0.1915                | 0.6141 ± 0.1915       |\n",
      "| NAM           | 0.3641 ± 0.0440            | 0.5350 ± 0.0364       | 0.3663 ± 0.0808                | 0.4708 ± 0.0606       |\n",
      "| EBM           | 0.0304 ± 0.0184            | 0.1441 ± 0.0599       | 0.0784 ± 0.0310                | 0.1187 ± 0.0659       |\n",
      "| SHAP          | 0.4130 ± 0.0354            | 0.4130 ± 0.0354       | 0.4130 ± 0.0354                | 0.4130 ± 0.0354       |\n",
      "| IG            | 0.7278 ± 0.0947            | 0.7278 ± 0.0947       | 0.7278 ± 0.0947                | 0.7278 ± 0.0947       |\n",
      "\n",
      "EMD:\n",
      "|               | Original (feature space)   | Sum (redistributed)   | Weighted sum (redistributed)   | Max (redistributed)   |\n",
      "|---------------|----------------------------|-----------------------|--------------------------------|-----------------------|\n",
      "| DISCR         | 0.7986 ± 0.0207            | **0.9457 ± 0.0056**   | **0.9176 ± 0.0182**            | **0.9430 ± 0.0052**   |\n",
      "| PatternGAM    | 0.8095 ± 0.0182            | 0.9203 ± 0.0112       | 0.8816 ± 0.0176                | 0.9144 ± 0.0123       |\n",
      "| PatternQLR    | 0.7832 ± 0.0221            | 0.8818 ± 0.0092       | 0.8564 ± 0.0100                | 0.9194 ± 0.0219       |\n",
      "| KernelPattern | 0.7781 ± 0.0351            | 0.7781 ± 0.0351       | 0.7781 ± 0.0351                | 0.7781 ± 0.0351       |\n",
      "| PatternAttr   | **0.9095 ± 0.0230**        | 0.9095 ± 0.0230       | 0.9095 ± 0.0230                | 0.9095 ± 0.0230       |\n",
      "| PatternNet    | 0.8891 ± 0.0687            | 0.8891 ± 0.0687       | 0.8891 ± 0.0687                | 0.8891 ± 0.0687       |\n",
      "| NAM           | 0.8256 ± 0.0312            | 0.8918 ± 0.0115       | 0.8687 ± 0.0137                | 0.8779 ± 0.0144       |\n",
      "| EBM           | 0.8151 ± 0.0017            | 0.7888 ± 0.0304       | 0.7700 ± 0.0186                | 0.7796 ± 0.0325       |\n",
      "| SHAP          | 0.8734 ± 0.0237            | 0.8734 ± 0.0237       | 0.8734 ± 0.0237                | 0.8734 ± 0.0237       |\n",
      "| IG            | 0.8995 ± 0.0460            | 0.8995 ± 0.0460       | 0.8995 ± 0.0460                | 0.8995 ± 0.0460       |\n",
      "\n",
      "FNI-EMD:\n",
      "|               | Original (feature space)   | Sum (redistributed)   | Weighted sum (redistributed)   | Max (redistributed)   |\n",
      "|---------------|----------------------------|-----------------------|--------------------------------|-----------------------|\n",
      "| DISCR         | 0.8052 ± 0.0216            | **0.9729 ± 0.0065**   | 0.9516 ± 0.0112                | **0.9790 ± 0.0046**   |\n",
      "| PatternGAM    | 0.8196 ± 0.0202            | 0.9308 ± 0.0096       | 0.8970 ± 0.0196                | 0.9250 ± 0.0133       |\n",
      "| PatternQLR    | 0.7941 ± 0.0250            | 0.8908 ± 0.0052       | 0.8679 ± 0.0087                | 0.9260 ± 0.0210       |\n",
      "| KernelPattern | 0.7869 ± 0.0377            | 0.7869 ± 0.0377       | 0.7869 ± 0.0377                | 0.7869 ± 0.0377       |\n",
      "| PatternAttr   | **0.9603 ± 0.0289**        | 0.9603 ± 0.0289       | **0.9603 ± 0.0289**            | 0.9603 ± 0.0289       |\n",
      "| PatternNet    | 0.9235 ± 0.0400            | 0.9235 ± 0.0400       | 0.9235 ± 0.0400                | 0.9235 ± 0.0400       |\n",
      "| NAM           | 0.8414 ± 0.0304            | 0.9150 ± 0.0127       | 0.8853 ± 0.0125                | 0.9058 ± 0.0167       |\n",
      "| EBM           | 0.8213 ± 0.0017            | 0.8129 ± 0.0270       | 0.7850 ± 0.0229                | 0.8009 ± 0.0317       |\n",
      "| SHAP          | 0.9112 ± 0.0105            | 0.9112 ± 0.0105       | 0.9112 ± 0.0105                | 0.9112 ± 0.0105       |\n",
      "| IG            | 0.9580 ± 0.0128            | 0.9580 ± 0.0128       | 0.9580 ± 0.0128                | 0.9580 ± 0.0128       |\n",
      "Saved: {'IMA': {'html': './table_exports/xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_IMA.html'}, 'EMD': {'html': './table_exports/xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_EMD.html'}, 'FNI-EMD': {'html': './table_exports/xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_FNI-EMD.html'}}\n"
     ]
    }
   ],
   "source": [
    "# ======= Pretty tables with ordering, renaming, bolding, and exports =======\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Methods: order + pretty names \n",
    "METHOD_ORDER = [\n",
    "    \"discr\", \"pattern_gam\", \"pattern_qlr\", \"kernel_svm\", \n",
    "    \"pattern_attribution\", \"pattern_net\", \"nam\", \"ebm\", \"shap\", \"ig\"\n",
    "]\n",
    "\n",
    "PRETTY_NAME = {\n",
    "    \"discr\": \"DISCR\",\n",
    "    \"kernel_svm\": \"KernelPattern\",\n",
    "    \"shap\": \"SHAP\",\n",
    "    \"ig\": \"IG\",\n",
    "    \"pattern_attribution\": \"PatternAttr\",\n",
    "    \"pattern_net\": \"PatternNet\",\n",
    "    \"nam\": \"NAM\",\n",
    "    \"ebm\": \"EBM\",\n",
    "    \"pattern_gam\": \"PatternGAM\",\n",
    "    \"pattern_qlr\": \"PatternQLR\",\n",
    "}\n",
    "\n",
    "COL_SPECS = [\n",
    "    (\"original\", \"Original (feature space)\"),\n",
    "    (\"sum\",      \"Sum (redistributed)\"),\n",
    "    (\"weighted\", \"Weighted sum (redistributed)\"),\n",
    "    (\"max\",      \"Max (redistributed)\"),\n",
    "]\n",
    "# If you want a different order or subset, just reorder/remove tuples above.\n",
    "# Example:\n",
    "# COL_SPECS = [(\"sum\",\"Sum\"), (\"weighted\",\"Weighted\"), (\"max\",\"Max\"), (\"original\",\"Original\")]\n",
    "\n",
    "COL_ORDER = [\"original\", \"sum\", \"weighted\", \"max\"] \n",
    "\n",
    "\n",
    "METRICS = [\"IMA\", \"EMD\", \"FNI-EMD\"]    \n",
    "\n",
    "def _fmt_cell(mean, std):\n",
    "    if np.isnan(mean) or np.isnan(std):\n",
    "        return \"nan\"\n",
    "    return f\"{mean:.4f} ± {std:.4f}\"\n",
    "\n",
    "def _bold_winners_as_markdown(df_means, df_strings):\n",
    "    \"\"\"\n",
    "    Bold the max value per column in df_strings (string cells), using df_means (numeric) to decide winners.\n",
    "    Ties: bold all tied maxima.\n",
    "    \"\"\"\n",
    "    out = df_strings.copy()\n",
    "    for col in df_means.columns:\n",
    "        col_vals = df_means[col]\n",
    "        if col_vals.isna().all():\n",
    "            continue\n",
    "        max_val = np.nanmax(col_vals.values.astype(float))\n",
    "        winners = (np.abs(col_vals - max_val) < 1e-12)  # tie-safe\n",
    "        for idx in df_means.index[winners]:\n",
    "            out.loc[idx, col] = f\"**{out.loc[idx, col]}**\"\n",
    "    return out\n",
    "\n",
    "def _styler_from_strings_and_means(df_strings, df_means, caption=None):\n",
    "    \"\"\"\n",
    "    Create a pandas Styler that shows df_strings but bolds the winners from df_means.\n",
    "    \"\"\"\n",
    "    # build boolean mask for winners\n",
    "    mask = pd.DataFrame(False, index=df_means.index, columns=df_means.columns)\n",
    "    for col in df_means.columns:\n",
    "        col_vals = df_means[col]\n",
    "        if col_vals.isna().all():\n",
    "            continue\n",
    "        m = np.nanmax(col_vals.values.astype(float))\n",
    "        mask[col] = (np.abs(col_vals - m) < 1e-12)\n",
    "\n",
    "    def bold_mask(s):\n",
    "        return ['font-weight: bold' if m else '' for m in mask[s.name]]\n",
    "\n",
    "    sty = (df_strings.style\n",
    "           .apply(bold_mask, axis=0)\n",
    "           .set_properties(**{\"white-space\": \"nowrap\"})\n",
    "           .set_table_styles([\n",
    "               {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "               {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\"), (\"padding\", \"6px 10px\")]},\n",
    "               {\"selector\": \"caption\", \"props\": [(\"caption-side\", \"top\"), (\"font-weight\", \"bold\"), (\"margin-bottom\", \"8px\")]}\n",
    "           ])\n",
    "          )\n",
    "    if caption:\n",
    "        sty = sty.set_caption(caption)\n",
    "    return sty\n",
    "\n",
    "def build_tables_for_scenario(method_data, method_order, pretty_map, col_specs):\n",
    "    \"\"\"\n",
    "    col_specs: list of (internal_key, pretty_label)\n",
    "    \"\"\"\n",
    "    methods_present = [m for m in method_order if m in method_data]\n",
    "    pretty_index = [pretty_map.get(m, m) for m in methods_present]\n",
    "\n",
    "    # Split specs into internal keys (used to fetch stats) and labels (shown in table)\n",
    "    col_keys   = [k for k, _ in col_specs]\n",
    "    col_labels = [l for _, l in col_specs]\n",
    "\n",
    "    per_metric = {}\n",
    "    for metric in METRICS:\n",
    "        means = []\n",
    "        stds  = []\n",
    "        for m in methods_present:\n",
    "            row_means, row_stds = [], []\n",
    "            for ckey in col_keys:\n",
    "                stats = method_data[m][ckey]\n",
    "                mean_key = f\"{metric}_mean\" if metric != \"FNI-EMD\" else \"FNI-EMD_mean\"\n",
    "                std_key  = f\"{metric}_std\"  if metric != \"FNI-EMD\" else \"FNI-EMD_std\"\n",
    "                row_means.append(stats.get(mean_key, np.nan))\n",
    "                row_stds.append(stats.get(std_key, np.nan))\n",
    "            means.append(row_means)\n",
    "            stds.append(row_stds)\n",
    "\n",
    "        # Use pretty labels as the displayed column headers\n",
    "        df_means = pd.DataFrame(means, index=pretty_index, columns=col_labels, dtype=float)\n",
    "        df_stds  = pd.DataFrame(stds,  index=pretty_index, columns=col_labels, dtype=float)\n",
    "\n",
    "        # Format\n",
    "        df_fmt = pd.DataFrame(index=pretty_index, columns=col_labels, dtype=object)\n",
    "        for i in df_fmt.index:\n",
    "            for j in df_fmt.columns:\n",
    "                df_fmt.loc[i, j] = _fmt_cell(df_means.loc[i, j], df_stds.loc[i, j])\n",
    "\n",
    "        # Bold winners by comparing numeric df_means; labels are fine here\n",
    "        df_fmt_bold_md = _bold_winners_as_markdown(df_means, df_fmt)\n",
    "        styler = _styler_from_strings_and_means(df_fmt, df_means, caption=f\"{metric}\")\n",
    "\n",
    "        per_metric[metric] = {\n",
    "            \"df_means\": df_means, \"df_stds\": df_stds,\n",
    "            \"df_fmt\": df_fmt, \"df_fmt_bold_md\": df_fmt_bold_md,\n",
    "            \"styler\": styler\n",
    "        }\n",
    "    return per_metric\n",
    "\n",
    "\n",
    "def export_tables(per_metric, out_dir=None, fname_prefix=\"\", to_png=False):\n",
    "    \"\"\"\n",
    "    Save HTML (and optional PNG if dataframe_image is available) for each metric table.\n",
    "    Returns dict of saved paths.\n",
    "    \"\"\"\n",
    "    saved = {}\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        try:\n",
    "            import dataframe_image as dfi\n",
    "            have_dfi = True\n",
    "        except Exception:\n",
    "            have_dfi = False\n",
    "\n",
    "        for metric, bundle in per_metric.items():\n",
    "            sty = bundle[\"styler\"]\n",
    "            html_path = os.path.join(out_dir, f\"{fname_prefix}{metric}.html\")\n",
    "            with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(sty.to_html())\n",
    "            saved[metric] = {\"html\": html_path}\n",
    "\n",
    "            if to_png:\n",
    "                if have_dfi:\n",
    "                    png_path = os.path.join(out_dir, f\"{fname_prefix}{metric}.png\")\n",
    "                    dfi.export(sty, png_path)   # requires chrome or wkhtmltopdf depending on backend\n",
    "                    saved[metric][\"png\"] = png_path\n",
    "                else:\n",
    "                    print(\"Note: dataframe_image not installed; skipping PNG export.\")\n",
    "    return saved\n",
    "\n",
    "# -------------------------\n",
    "# EXAMPLE USAGE:\n",
    "# -------------------------\n",
    "# aggregated_all is what you already computed earlier.\n",
    "\n",
    "for scenario_name, method_data in aggregated_all.items():\n",
    "    per_metric = build_tables_for_scenario(\n",
    "        method_data,\n",
    "        method_order=METHOD_ORDER,\n",
    "        pretty_map=PRETTY_NAME,\n",
    "        col_specs=COL_SPECS,     # <— here\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {scenario_name} ===\")\n",
    "    for metric in METRICS:\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(per_metric[metric][\"df_fmt_bold_md\"].to_markdown(tablefmt=\"github\"))\n",
    "\n",
    "    ### Optionally export nice HTML/PNG for email or slides\n",
    "    saved_paths = export_tables(per_metric, out_dir=\"./table_exports\",\n",
    "                                fname_prefix=f\"{scenario_name}_\", to_png=False)\n",
    "    print(\"Saved:\", saved_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb17da1e-7563-458d-8ad4-64fd64df167a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1941484341.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    --- Aggregated Results (Original, Sum, Weighted, Max) ---\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "--- Aggregated Results (Original, Sum, Weighted, Max) ---\n",
    "\n",
    "=== Scenario: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated ===\n",
    "\n",
    "IMA (Importance Mass Accuracy):\n",
    "                            original              sum         weighted              max\n",
    "discr                0.1178 ± 0.0273  0.8692 ± 0.0238  0.7617 ± 0.0510  0.8956 ± 0.0193\n",
    "ebm                  0.0336 ± 0.0179  0.1441 ± 0.0599  0.0784 ± 0.0310  0.1187 ± 0.0659\n",
    "ig                   0.7278 ± 0.0947  0.7278 ± 0.0947  0.7278 ± 0.0947  0.7278 ± 0.0947\n",
    "kernel_svm           0.1231 ± 0.0520  0.1231 ± 0.0520  0.1231 ± 0.0520  0.1231 ± 0.0520\n",
    "nam                  0.4062 ± 0.0549  0.5350 ± 0.0364  0.3663 ± 0.0808  0.4708 ± 0.0606\n",
    "pattern_attribution  0.7687 ± 0.1277  0.7687 ± 0.1277  0.7687 ± 0.1277  0.7687 ± 0.1277\n",
    "pattern_gam          0.5973 ± 0.0788  0.6537 ± 0.0521  0.4889 ± 0.1072  0.6180 ± 0.0679\n",
    "pattern_net          0.6141 ± 0.1915  0.6141 ± 0.1915  0.6141 ± 0.1915  0.6141 ± 0.1915\n",
    "pattern_qlr          0.2422 ± 0.0334  0.4286 ± 0.0132  0.3414 ± 0.0063  0.5864 ± 0.0835\n",
    "shap                 0.4130 ± 0.0354  0.4130 ± 0.0354  0.4130 ± 0.0354  0.4130 ± 0.0354\n",
    "\n",
    "EMD:\n",
    "                            original              sum         weighted              max\n",
    "discr                0.7986 ± 0.0207  0.9457 ± 0.0056  0.9176 ± 0.0182  0.9430 ± 0.0052\n",
    "ebm                  0.8151 ± 0.0017  0.7888 ± 0.0304  0.7700 ± 0.0186  0.7796 ± 0.0325\n",
    "ig                   0.8995 ± 0.0460  0.8995 ± 0.0460  0.8995 ± 0.0460  0.8995 ± 0.0460\n",
    "kernel_svm           0.7781 ± 0.0351  0.7781 ± 0.0351  0.7781 ± 0.0351  0.7781 ± 0.0351\n",
    "nam                  0.8256 ± 0.0312  0.8918 ± 0.0115  0.8687 ± 0.0137  0.8779 ± 0.0144\n",
    "pattern_attribution  0.9095 ± 0.0230  0.9095 ± 0.0230  0.9095 ± 0.0230  0.9095 ± 0.0230\n",
    "pattern_gam          0.8095 ± 0.0182  0.9203 ± 0.0112  0.8816 ± 0.0176  0.9144 ± 0.0123\n",
    "pattern_net          0.8891 ± 0.0687  0.8891 ± 0.0687  0.8891 ± 0.0687  0.8891 ± 0.0687\n",
    "pattern_qlr          0.7832 ± 0.0221  0.8818 ± 0.0092  0.8564 ± 0.0100  0.9194 ± 0.0219\n",
    "shap                 0.8734 ± 0.0237  0.8734 ± 0.0237  0.8734 ± 0.0237  0.8734 ± 0.0237\n",
    "\n",
    "FNI-EMD:\n",
    "                            original              sum         weighted              max\n",
    "discr                0.8052 ± 0.0216  0.9729 ± 0.0065  0.9516 ± 0.0112  0.9790 ± 0.0046\n",
    "ebm                  0.8213 ± 0.0017  0.8129 ± 0.0270  0.7850 ± 0.0229  0.8009 ± 0.0317\n",
    "ig                   0.9580 ± 0.0128  0.9580 ± 0.0128  0.9580 ± 0.0128  0.9580 ± 0.0128\n",
    "kernel_svm           0.7869 ± 0.0377  0.7869 ± 0.0377  0.7869 ± 0.0377  0.7869 ± 0.0377\n",
    "nam                  0.8414 ± 0.0304  0.9150 ± 0.0127  0.8853 ± 0.0125  0.9058 ± 0.0167\n",
    "pattern_attribution  0.9603 ± 0.0289  0.9603 ± 0.0289  0.9603 ± 0.0289  0.9603 ± 0.0289\n",
    "pattern_gam          0.8196 ± 0.0202  0.9308 ± 0.0096  0.8970 ± 0.0196  0.9250 ± 0.0133\n",
    "pattern_net          0.9235 ± 0.0400  0.9235 ± 0.0400  0.9235 ± 0.0400  0.9235 ± 0.0400\n",
    "pattern_qlr          0.7941 ± 0.0250  0.8908 ± 0.0052  0.8679 ± 0.0087  0.9260 ± 0.0210\n",
    "shap                 0.9112 ± 0.0105  0.9112 ± 0.0105  0.9112 ± 0.0105  0.9112 ± 0.0105"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
