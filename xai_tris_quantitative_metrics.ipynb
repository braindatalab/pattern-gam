{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5750238f-381e-4838-9279-96a2d244edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot.lp import emd # Needs POT (Python Optimal Transport) library\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from interpret.utils import measure_interactions\n",
    "def FAST(X_train, y_train, n_interactions, init_score=None, feature_names=None, feature_types=None):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    interactions = measure_interactions(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        interactions=n_interactions, \n",
    "        init_score=init_score,  # Can be a model or initial scores; set to None if not used\n",
    "        feature_names = feature_names,\n",
    "        feature_types = feature_types\n",
    "    )\n",
    "    \n",
    "    pairs = []\n",
    "    for (i, j), _ in interactions:\n",
    "        pairs.append((i,j))\n",
    "    return pairs, time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fc5b9f-587c-4f60-ab0a-e4fd454a591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEEDS = [2025]  # Define the seed(s) to process\n",
    "SEEDS = [2025, 1283123, 3043040, 8238238, 123123]\n",
    "SAVE_DIR = \"./models/xai_tris\"  # Directory where models are saved\n",
    "EXPLANATIONS_DIR = \"./explanations/xai_tris\" # Directory to save MLP SHAP/IG .npy files\n",
    "os.makedirs(EXPLANATIONS_DIR, exist_ok=True)\n",
    "# CSV for storing metadata about generated MLP explanations\n",
    "DEVICE_STR = 'cpu' # Use 'cuda:0' or similar if GPU is available and desired\n",
    "\n",
    "seed = SEEDS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c04eef-4a14-4065-a76a-007bb847a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./models/old_xai_tris/explanations.pkl', \"rb\") as f:\n",
    "#     explanations = pkl.load(f)\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09c68a6-fbff-40f7-9404-af2f1ba749a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_3', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_2', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_0', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_1', 'xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_4'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768a42e6-f7f0-4c10-850b-0a65fb58dd6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "D_2D_EDGE (grid edge for main effects): 8\n",
      "D_FLAT (total main effect features): 64\n",
      "Sum of GT_MASK_2D_FLAT: 8\n",
      "Cost matrix for main effects shape: (64, 64)\n",
      "--- Starting Metric Calculation ---\n",
      "\n",
      "--- Aggregated Results ---\n",
      "\n",
      "Scenario Type: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated\n",
      "  Method: pattern_gam\n",
      "    IMA    : Mean = 0.5688, Std = 0.0803\n",
      "    EMD    : Mean = 0.8095, Std = 0.0182\n",
      "    FNI-EMD: Mean = 0.8196, Std = 0.0202\n",
      "  Method: pattern_qlr\n",
      "    IMA    : Mean = 0.2278, Std = 0.0385\n",
      "    EMD    : Mean = 0.7832, Std = 0.0221\n",
      "    FNI-EMD: Mean = 0.7941, Std = 0.0250\n",
      "  Method: kernel_svm\n",
      "    IMA    : Mean = 0.1231, Std = 0.0520\n",
      "    EMD    : Mean = 0.7781, Std = 0.0351\n",
      "    FNI-EMD: Mean = 0.7869, Std = 0.0377\n",
      "  Method: ebm\n",
      "    IMA    : Mean = 0.0304, Std = 0.0184\n",
      "    EMD    : Mean = 0.8151, Std = 0.0017\n",
      "    FNI-EMD: Mean = 0.8213, Std = 0.0017\n",
      "  Method: shap\n",
      "    IMA    : Mean = 0.4130, Std = 0.0354\n",
      "    EMD    : Mean = 0.8734, Std = 0.0237\n",
      "    FNI-EMD: Mean = 0.9112, Std = 0.0105\n",
      "  Method: ig\n",
      "    IMA    : Mean = 0.7278, Std = 0.0947\n",
      "    EMD    : Mean = 0.8995, Std = 0.0460\n",
      "    FNI-EMD: Mean = 0.9580, Std = 0.0128\n",
      "  Method: nam\n",
      "    IMA    : Mean = 0.3641, Std = 0.0440\n",
      "    EMD    : Mean = 0.8256, Std = 0.0312\n",
      "    FNI-EMD: Mean = 0.8414, Std = 0.0304\n",
      "  Method: pattern_net\n",
      "    IMA    : Mean = 0.6141, Std = 0.1915\n",
      "    EMD    : Mean = 0.8891, Std = 0.0687\n",
      "    FNI-EMD: Mean = 0.9235, Std = 0.0400\n",
      "  Method: pattern_attribution\n",
      "    IMA    : Mean = 0.7687, Std = 0.1277\n",
      "    EMD    : Mean = 0.9095, Std = 0.0230\n",
      "    FNI-EMD: Mean = 0.9603, Std = 0.0289\n",
      "  Method: discr\n",
      "    IMA    : Mean = 0.1178, Std = 0.0273\n",
      "    EMD    : Mean = 0.7986, Std = 0.0207\n",
      "    FNI-EMD: Mean = 0.8052, Std = 0.0216\n"
     ]
    }
   ],
   "source": [
    "from interpret.utils import measure_interactions\n",
    "def FAST(X_train, y_train, n_interactions, init_score=None, feature_names=None, feature_types=None):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    interactions = measure_interactions(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        interactions=n_interactions, \n",
    "        init_score=init_score,  # Can be a model or initial scores; set to None if not used\n",
    "        feature_names = feature_names,\n",
    "        feature_types = feature_types\n",
    "    )\n",
    "    \n",
    "    pairs = []\n",
    "    for (i, j), _ in interactions:\n",
    "        pairs.append((i,j))\n",
    "    return pairs, time.time() - t0\n",
    "\n",
    "\n",
    "D_2D_EDGE = 8 \n",
    "D_FLAT = D_2D_EDGE * D_2D_EDGE \n",
    "\n",
    "normal_t = np.array([[1,0],[1,1],[1,0]])\n",
    "normal_l = np.array([[1,0],[1,0],[1,1]])\n",
    "GT_MASK_2D = np.zeros((D_2D_EDGE, D_2D_EDGE), dtype=int)\n",
    "\n",
    "GT_MASK_2D[1:4, 1:3] = normal_t\n",
    "GT_MASK_2D[4:7, 5:7] = normal_l\n",
    "\n",
    "GT_MASK_2D_FLAT = GT_MASK_2D.flatten()\n",
    "\n",
    "\n",
    "# def create_gt_mask_interactions_1d(main_effect_ground_truth_flat, custom_interaction_pairs, d_flat):\n",
    "#     if len(main_effect_ground_truth_flat) != d_flat:\n",
    "#         raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) must match d_flat ({d_flat}).\")\n",
    "#     interaction_ground_truth = []\n",
    "#     for i, j in custom_interaction_pairs:\n",
    "#         if not (0 <= i < d_flat and 0 <= j < d_flat):\n",
    "#             interaction_ground_truth.append(0) # Invalid pair, append 0\n",
    "#             continue\n",
    "#         interaction_ground_truth.append(1 if main_effect_ground_truth_flat[i] == 1 and main_effect_ground_truth_flat[j] == 1 else 0)\n",
    "#     return np.concatenate((main_effect_ground_truth_flat, np.array(interaction_ground_truth, dtype=int)))\n",
    "\n",
    "# def create_qlr_ground_truth_mask_1d(main_effect_ground_truth_flat, d_flat):\n",
    "#     if not isinstance(main_effect_ground_truth_flat, np.ndarray):\n",
    "#         raise TypeError(\"main_effect_ground_truth_flat must be a numpy array.\")\n",
    "#     if main_effect_ground_truth_flat.ndim != 1:\n",
    "#         raise ValueError(\"main_effect_ground_truth_flat must be a 1D array.\")\n",
    "#     if len(main_effect_ground_truth_flat) != d_flat:\n",
    "#         raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) \"\n",
    "#                          f\"must match d_flat ({d_flat}).\")\n",
    "#     if not np.all(np.isin(main_effect_ground_truth_flat, [0, 1])):\n",
    "#         raise ValueError(\"main_effect_ground_truth_flat should only contain 0s and 1s.\")\n",
    "\n",
    "#     num_main_features = d_flat\n",
    "\n",
    "#     # Get indices for the upper triangle, including the diagonal (for x_i*x_j where i <= j)\n",
    "#     # These are the same indices used in the `quadratic_features` function.\n",
    "#     inds_0, inds_1 = np.triu_indices(num_main_features, 0)\n",
    "    \n",
    "#     num_quadratic_terms = len(inds_0)\n",
    "#     quadratic_part_mask = np.zeros(num_quadratic_terms, dtype=int)\n",
    "\n",
    "#     for i in range(num_quadratic_terms):\n",
    "#         idx_feature_1 = inds_0[i]\n",
    "#         idx_feature_2 = inds_1[i]\n",
    "        \n",
    "#         # The mask for the quadratic term is 1 if both corresponding main features are 1\n",
    "#         if main_effect_ground_truth_flat[idx_feature_1] == 1 and \\\n",
    "#            main_effect_ground_truth_flat[idx_feature_2] == 1:\n",
    "#             quadratic_part_mask[i] = 1\n",
    "#         else:\n",
    "#             quadratic_part_mask[i] = 0\n",
    "            \n",
    "#     # Concatenate the main effect mask with the quadratic effect mask\n",
    "#     full_mask = np.concatenate((main_effect_ground_truth_flat, quadratic_part_mask))\n",
    "    \n",
    "#     return full_mask\n",
    "\n",
    "\n",
    "# Helper: get flat-index sets for T and L shapes (row-major flatten)\n",
    "def _xor_shape_index_sets(d_edge, normal_t, normal_l):\n",
    "    T_rows = slice(1, 4)  # [1:4)\n",
    "    T_cols = slice(1, 3)  # [1:3)\n",
    "    L_rows = slice(4, 7)  # [4:7)\n",
    "    L_cols = slice(5, 7)  # [5:7)\n",
    "\n",
    "    # Bounds check like your original code\n",
    "    if d_edge < 7:\n",
    "        # Not enough room; return empty sets to avoid false positives\n",
    "        return set(), set()\n",
    "\n",
    "    mask_t = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_l = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_t[T_rows, T_cols] = normal_t\n",
    "    mask_l[L_rows, L_cols] = normal_l\n",
    "\n",
    "    # Flat indices where the mini-pattern has ones\n",
    "    idx_t = set(np.flatnonzero(mask_t.flatten()))\n",
    "    idx_l = set(np.flatnonzero(mask_l.flatten()))\n",
    "    return idx_t, idx_l\n",
    "\n",
    "\n",
    "def create_gt_mask_interactions_1d(main_effect_ground_truth_flat, custom_interaction_pairs, d_flat):\n",
    "    \"\"\"\n",
    "    XOR ground truth for methods using an explicit interaction list (FAST, etc.).\n",
    "    - Main effects: all zeros (length d_flat)\n",
    "    - Interactions: 1 iff one index in T and the other in L; else 0.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray):\n",
    "        raise TypeError(\"main_effect_ground_truth_flat must be a numpy array.\")\n",
    "    if main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) must match d_flat ({d_flat}).\")\n",
    "\n",
    "    # Build T/L index sets in the 2D grid and map to flat indices\n",
    "    idx_t, idx_l = _xor_shape_index_sets(D_2D_EDGE, normal_t, normal_l)\n",
    "\n",
    "    # Main effects are all zeros for XOR\n",
    "    main_part = np.zeros(d_flat, dtype=int)\n",
    "\n",
    "    # Interactions: only cross-shape pairs are 1\n",
    "    interaction_ground_truth = []\n",
    "    for (i, j) in custom_interaction_pairs:\n",
    "        if not (0 <= i < d_flat and 0 <= j < d_flat):\n",
    "            interaction_ground_truth.append(0)\n",
    "            continue\n",
    "        if i == j:\n",
    "            interaction_ground_truth.append(0)\n",
    "            continue\n",
    "        cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "        interaction_ground_truth.append(1 if cross else 0)\n",
    "\n",
    "    interaction_part = np.array(interaction_ground_truth, dtype=int)\n",
    "    return np.concatenate((main_part, interaction_part))\n",
    "\n",
    "\n",
    "def create_qlr_ground_truth_mask_1d(main_effect_ground_truth_flat, d_flat):\n",
    "    \"\"\"\n",
    "    XOR ground truth for QLR (upper-tri ordering i <= j).\n",
    "    - Main effects: all zeros (length d_flat)\n",
    "    - Quadratic terms: 1 iff i != j and {i,j} is a cross-shape pair (T vs L); else 0.\n",
    "      Diagonal terms i==j are set to 0.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray):\n",
    "        raise TypeError(\"main_effect_ground_truth_flat must be a numpy array.\")\n",
    "    if main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(f\"Length of main_effect_ground_truth_flat ({len(main_effect_ground_truth_flat)}) must match d_flat ({d_flat}).\")\n",
    "\n",
    "    # Build T/L index sets\n",
    "    idx_t, idx_l = _xor_shape_index_sets(D_2D_EDGE, normal_t, normal_l)\n",
    "\n",
    "    # Main effects are all zeros for XOR importance\n",
    "    main_part = np.zeros(d_flat, dtype=int)\n",
    "\n",
    "    # Upper-tri including diagonal, same order as your QLR feature mapping\n",
    "    inds_0, inds_1 = np.triu_indices(d_flat, 0)\n",
    "    quadratic_part_mask = np.zeros(len(inds_0), dtype=int)\n",
    "\n",
    "    for k in range(len(inds_0)):\n",
    "        i = inds_0[k]; j = inds_1[k]\n",
    "        if i == j:\n",
    "            quadratic_part_mask[k] = 0  # no self-importance\n",
    "            continue\n",
    "        cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "        quadratic_part_mask[k] = 1 if cross else 0\n",
    "\n",
    "    return np.concatenate((main_part, quadratic_part_mask))\n",
    "\n",
    "\n",
    "def importance_mass_accuracy(gt_mask, attribution):\n",
    "    if not isinstance(gt_mask, np.ndarray) or not isinstance(attribution, np.ndarray):\n",
    "        return np.nan\n",
    "    if attribution.ndim != 1 or len(gt_mask) != len(attribution):\n",
    "        # print(f\"IMA shape mismatch: gt_mask {gt_mask.shape}, attribution {attribution.shape}\")\n",
    "        return np.nan\n",
    "    \n",
    "    abs_attribution = np.abs(attribution)\n",
    "    mass_in_gt = np.sum(abs_attribution[gt_mask == 1])\n",
    "    total_mass = np.sum(abs_attribution)\n",
    "    \n",
    "    if total_mass == 0:\n",
    "        return 1.0 if mass_in_gt == 0 else 0.0 # Perfect score if both are zero mass\n",
    "    return mass_in_gt / total_mass\n",
    "\n",
    "def create_cost_matrix(grid_edge_length):\n",
    "    # Creates a cost matrix for a grid of grid_edge_length * grid_edge_length features\n",
    "    if grid_edge_length == 0:\n",
    "        return np.array([]).reshape(0,0)\n",
    "    \n",
    "    total_features = grid_edge_length * grid_edge_length\n",
    "    if total_features == 1:\n",
    "        return np.array([[0.0]])\n",
    "        \n",
    "    indices_matrix = np.indices((grid_edge_length, grid_edge_length))\n",
    "    coordinates = []\n",
    "    for r in range(grid_edge_length):\n",
    "        for c in range(grid_edge_length):\n",
    "            coordinates.append((indices_matrix[0][r, c], indices_matrix[1][r, c]))\n",
    "    coordinates = np.array(coordinates)\n",
    "    return cdist(coordinates, coordinates)\n",
    "\n",
    "# Cost matrix for main effects (e.g., 8x8 grid -> 64 features)\n",
    "COST_MATRIX_MAIN_EFFECTS = create_cost_matrix(D_2D_EDGE)\n",
    "\n",
    "def calculate_emd_score_metric(gt_mask_flat, attribution_flat, grid_edge_length, base_cost_matrix, is_fni=False):\n",
    "    # Input checks\n",
    "    if not (isinstance(gt_mask_flat, np.ndarray) and gt_mask_flat.ndim == 1 and\n",
    "            isinstance(attribution_flat, np.ndarray) and attribution_flat.ndim == 1 and\n",
    "            len(gt_mask_flat) == len(attribution_flat) and\n",
    "            len(gt_mask_flat) == grid_edge_length * grid_edge_length):\n",
    "        return np.nan\n",
    "\n",
    "    current_cost_matrix = np.copy(base_cost_matrix)\n",
    "    if is_fni:\n",
    "        gt_indices = np.where(gt_mask_flat == 1)[0]\n",
    "        for r_idx in gt_indices:\n",
    "            for c_idx in gt_indices:\n",
    "                # Ensure indices are within bounds of the cost matrix\n",
    "                if r_idx < current_cost_matrix.shape[0] and c_idx < current_cost_matrix.shape[1]:\n",
    "                    current_cost_matrix[r_idx, c_idx] = 0.0\n",
    "    \n",
    "    sum_gt = np.sum(gt_mask_flat)\n",
    "    abs_attribution = np.abs(attribution_flat)\n",
    "    sum_attr = np.sum(abs_attribution)\n",
    "\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9: # Effectively both empty\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9: # One empty, other not\n",
    "        return 0.0\n",
    "        \n",
    "    dist_gt = gt_mask_flat.astype(np.float64) / sum_gt\n",
    "    dist_attr = abs_attribution.astype(np.float64) / sum_attr\n",
    "    \n",
    "    # Ensure distributions are C-contiguous and float64 for EMD\n",
    "    dist_gt_c = np.ascontiguousarray(dist_gt, dtype=np.float64)\n",
    "    dist_attr_c = np.ascontiguousarray(dist_attr, dtype=np.float64)\n",
    "    current_cost_matrix_c = np.ascontiguousarray(current_cost_matrix, dtype=np.float64)\n",
    "\n",
    "    cost_val = 0.0\n",
    "    if grid_edge_length * grid_edge_length > 1 : # EMD makes sense for >1 feature\n",
    "        try:\n",
    "            # Note: emd returns the cost value directly, not a tuple if log=False\n",
    "            _, cost_val = emd(dist_gt_c, dist_attr_c, current_cost_matrix_c, numItermax=200000, log=True)\n",
    "        except Exception:\n",
    "            return np.nan # EMD calculation failed\n",
    "    \n",
    "    # Dmax = max Euclidean distance in the grid\n",
    "    d_max = np.sqrt(2 * (grid_edge_length - 1)**2) if grid_edge_length > 1 else 0.0\n",
    "\n",
    "    if d_max == 0: # Handles grid_edge_length = 1 (single feature) or cases where d_max is ill-defined\n",
    "        return 1.0 if np.isclose(cost_val, 0) else 0.0\n",
    "    \n",
    "    return 1 - (cost_val['cost'] / d_max)\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "def process_explanations_metrics(explanations_dict, gt_mask_main_flat, d_flat_main, d_edge_main, cost_mat_main):\n",
    "    results_raw_collection = {} \n",
    "\n",
    "    for scenario_full_name, methods_data in explanations_dict.items():\n",
    "        if 'translations' in scenario_full_name:\n",
    "            continue\n",
    "        scenario_parts = scenario_full_name.split('_')\n",
    "        try:\n",
    "            # dataset_ind = int(scenario_parts[-1]) # Not used directly in aggregation key structure here\n",
    "            scenario_base_name = '_'.join(scenario_parts[:-1])\n",
    "        except ValueError:\n",
    "            scenario_base_name = scenario_full_name\n",
    "            # print(f\"Warning: Could not parse dataset index for {scenario_full_name}. Using full name as base.\")\n",
    "\n",
    "        interaction_pairs_for_scenario = []\n",
    "        if 'xor' in scenario_full_name.lower():\n",
    "            data_path = f'./data/xai_tris/{scenario_full_name}.pkl'\n",
    "            with open(data_path, \"rb\") as f:\n",
    "                data = pkl.load(f)\n",
    "                \n",
    "                X_train_tensor = data.x_train.float() \n",
    "                y_train_tensor = data.y_train\n",
    "\n",
    "            try:\n",
    "                interaction_pairs_for_scenario, _ = FAST(X_train_tensor, y_train_tensor, n_interactions=128)\n",
    "            except Exception as e:\n",
    "                # print(f\"Warning: Placeholder FAST failed for {scenario_full_name}: {e}\")\n",
    "                interaction_pairs_for_scenario = []\n",
    "        \n",
    "        if scenario_base_name not in results_raw_collection:\n",
    "            results_raw_collection[scenario_base_name] = {}\n",
    "\n",
    "        for method_name, explanation_content in methods_data.items():\n",
    "            if method_name not in results_raw_collection[scenario_base_name]:\n",
    "                results_raw_collection[scenario_base_name][method_name] = {'IMA': [], 'EMD': [], 'FNI_EMD': []}\n",
    "\n",
    "            current_explanation = explanation_content\n",
    "            if isinstance(current_explanation, list): # For \"ebm 192 <--- LIST\"\n",
    "                current_explanation = np.array(current_explanation)\n",
    "            \n",
    "            if not isinstance(current_explanation, np.ndarray):\n",
    "                # print(f\"Warning: Data for {scenario_full_name}/{method_name} is not array/list. Skipping.\")\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            # Process attribution: average local, flatten global\n",
    "            processed_attr = np.array([])\n",
    "            if current_explanation.ndim > 1 and current_explanation.shape[0] > 1 and \\\n",
    "               not (current_explanation.shape[0] == d_flat_main and current_explanation.ndim == 2 and current_explanation.shape[1] == 1 and d_flat_main > 1):\n",
    "                # processed_attr = np.mean(current_explanation, axis=0).squeeze()\n",
    "                if current_explanation[0].ndim == 3:\n",
    "                    # processed_attr = np.mean(np.vstack(current_explanation.squeeze(2)), axis=0)\n",
    "                    processed_attr = np.mean(np.mean(np.array(current_explanation), axis=0).squeeze(), axis=0)\n",
    "                else:\n",
    "                    processed_attr = np.mean(np.vstack(current_explanation), axis=0)\n",
    "            else:\n",
    "                processed_attr = current_explanation.flatten()\n",
    "            \n",
    "            # --- IMA Calculation ---\n",
    "            gt_mask_for_ima = None\n",
    "            attr_for_ima = None\n",
    "\n",
    "            if method_name in ['pattern_gam', 'ebm', 'nam'] and 'xor' in scenario_full_name.lower():\n",
    "                gt_mask_for_ima = create_gt_mask_interactions_1d(gt_mask_main_flat, interaction_pairs_for_scenario, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            elif method_name == 'pattern_qlr':\n",
    "                gt_mask_for_ima = create_qlr_ground_truth_mask_1d(gt_mask_main_flat, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            else: \n",
    "                gt_mask_for_ima = gt_mask_main_flat\n",
    "                attr_for_ima = processed_attr[:d_flat_main] \n",
    "\n",
    "            # Adjust attribution length for IMA if mismatch (truncate/pad)\n",
    "            if gt_mask_for_ima is not None and attr_for_ima is not None and len(attr_for_ima) != len(gt_mask_for_ima):\n",
    "                # print(f\"Warning IMA {scenario_full_name}/{method_name}: attr len {len(attr_for_ima)}, GT len {len(gt_mask_for_ima)}. Adjusting.\")\n",
    "                temp_attr = np.zeros(len(gt_mask_for_ima))\n",
    "                common_len = min(len(attr_for_ima), len(gt_mask_for_ima))\n",
    "                temp_attr[:common_len] = attr_for_ima[:common_len]\n",
    "                attr_for_ima = temp_attr\n",
    "            \n",
    "            ima_val = importance_mass_accuracy(gt_mask_for_ima, attr_for_ima)\n",
    "            results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "\n",
    "            # --- EMD & FNI-EMD (main effects: first d_flat_main features, d_edge_main grid) ---\n",
    "            attr_main_eff = processed_attr[:d_flat_main]\n",
    "            gt_main_eff = gt_mask_main_flat # GT for EMD/FNI is always main effects\n",
    "\n",
    "            emd_val = np.nan\n",
    "            fni_emd_val = np.nan\n",
    "            if len(attr_main_eff) == d_flat_main and d_flat_main > 0 : # Ensure correct length for main effects\n",
    "                emd_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_emd_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=True)\n",
    "            \n",
    "            results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "            results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_emd_val)\n",
    "\n",
    "    # --- Aggregation of results ---\n",
    "    final_aggregated_results = {}\n",
    "    for sc_base, meth_data in results_raw_collection.items():\n",
    "        final_aggregated_results[sc_base] = {}\n",
    "        for meth, metrics_lists in meth_data.items():\n",
    "            final_aggregated_results[sc_base][meth] = {\n",
    "                'IMA_mean': np.nanmean(metrics_lists['IMA']) if metrics_lists['IMA'] else np.nan,\n",
    "                'IMA_std': np.nanstd(metrics_lists['IMA']) if metrics_lists['IMA'] else np.nan,\n",
    "                'EMD_mean': np.nanmean(metrics_lists['EMD']) if metrics_lists['EMD'] else np.nan,\n",
    "                'EMD_std': np.nanstd(metrics_lists['EMD']) if metrics_lists['EMD'] else np.nan,\n",
    "                'FNI_EMD_mean': np.nanmean(metrics_lists['FNI_EMD']) if metrics_lists['FNI_EMD'] else np.nan,\n",
    "                'FNI_EMD_std': np.nanstd(metrics_lists['FNI_EMD']) if metrics_lists['FNI_EMD'] else np.nan,\n",
    "            }\n",
    "    return final_aggregated_results\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"D_2D_EDGE (grid edge for main effects): {D_2D_EDGE}\")\n",
    "print(f\"D_FLAT (total main effect features): {D_FLAT}\")\n",
    "print(f\"Sum of GT_MASK_2D_FLAT: {np.sum(GT_MASK_2D_FLAT)}\")\n",
    "print(f\"Cost matrix for main effects shape: {COST_MATRIX_MAIN_EFFECTS.shape}\")\n",
    "print(f\"--- Starting Metric Calculation ---\")\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)\n",
    "\n",
    "\n",
    "aggregated_metrics = process_explanations_metrics(\n",
    "    explanations,\n",
    "    GT_MASK_2D_FLAT,\n",
    "    D_FLAT,\n",
    "    D_2D_EDGE,\n",
    "    COST_MATRIX_MAIN_EFFECTS\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Aggregated Results ---\")\n",
    "for scenario_name, method_data in aggregated_metrics.items():\n",
    "    print(f\"\\nScenario Type: {scenario_name}\")\n",
    "    for method, scores in method_data.items():\n",
    "        print(f\"  Method: {method}\")\n",
    "        print(f\"    IMA    : Mean = {scores['IMA_mean']:.4f}, Std = {scores['IMA_std']:.4f}\")\n",
    "        print(f\"    EMD    : Mean = {scores['EMD_mean']:.4f}, Std = {scores['EMD_std']:.4f}\")\n",
    "        print(f\"    FNI-EMD: Mean = {scores['FNI_EMD_mean']:.4f}, Std = {scores['FNI_EMD_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "481a8c35-3933-4747-92b1-f9761fa45df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "D_2D_EDGE (grid edge for main effects): 8\n",
      "D_FLAT (total main effect features): 64\n",
      "Sum of GT_MASK_2D_FLAT (non-XOR main GT): 8\n",
      "Cost matrix for main effects shape: (64, 64)\n",
      "--- Starting Metric Calculation ---\n",
      "\n",
      "--- Aggregated Results ---\n",
      "\n",
      "Scenario Type: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated\n",
      "  Method: pattern_gam\n",
      "    IMA    : Mean = 0.5688, Std = 0.0803\n",
      "    EMD    : Mean = 0.9209, Std = 0.0108\n",
      "    FNI-EMD: Mean = 0.9319, Std = 0.0112\n",
      "  Method: pattern_qlr\n",
      "    IMA    : Mean = 0.2278, Std = 0.0385\n",
      "    EMD    : Mean = 0.8809, Std = 0.0123\n",
      "    FNI-EMD: Mean = 0.8876, Std = 0.0127\n",
      "  Method: kernel_svm\n",
      "    IMA    : Mean = 0.1231, Std = 0.0520\n",
      "    EMD    : Mean = 0.7781, Std = 0.0351\n",
      "    FNI-EMD: Mean = 0.7869, Std = 0.0377\n",
      "  Method: ebm\n",
      "    IMA    : Mean = 0.0304, Std = 0.0184\n",
      "    EMD    : Mean = 0.8376, Std = 0.0549\n",
      "    FNI-EMD: Mean = 0.8392, Std = 0.0541\n",
      "  Method: shap\n",
      "    IMA    : Mean = 0.4130, Std = 0.0354\n",
      "    EMD    : Mean = 0.8734, Std = 0.0237\n",
      "    FNI-EMD: Mean = 0.9112, Std = 0.0105\n",
      "  Method: ig\n",
      "    IMA    : Mean = 0.7278, Std = 0.0947\n",
      "    EMD    : Mean = 0.8995, Std = 0.0460\n",
      "    FNI-EMD: Mean = 0.9580, Std = 0.0128\n",
      "  Method: nam\n",
      "    IMA    : Mean = 0.3641, Std = 0.0440\n",
      "    EMD    : Mean = 0.8895, Std = 0.0196\n",
      "    FNI-EMD: Mean = 0.9070, Std = 0.0233\n",
      "  Method: pattern_net\n",
      "    IMA    : Mean = 0.6141, Std = 0.1915\n",
      "    EMD    : Mean = 0.8891, Std = 0.0687\n",
      "    FNI-EMD: Mean = 0.9235, Std = 0.0400\n",
      "  Method: pattern_attribution\n",
      "    IMA    : Mean = 0.7687, Std = 0.1277\n",
      "    EMD    : Mean = 0.9095, Std = 0.0230\n",
      "    FNI-EMD: Mean = 0.9603, Std = 0.0289\n",
      "  Method: discr\n",
      "    IMA    : Mean = 0.8485, Std = 0.0188\n",
      "    EMD    : Mean = 0.9489, Std = 0.0060\n",
      "    FNI-EMD: Mean = 0.9747, Std = 0.0058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot import emd\n",
    "from interpret.utils import measure_interactions\n",
    "import os\n",
    "\n",
    "# ----------------------\n",
    "# FAST (unchanged)\n",
    "# ----------------------\n",
    "def FAST(X_train, y_train, n_interactions, init_score=None, feature_names=None, feature_types=None):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    interactions = measure_interactions(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        interactions=n_interactions, \n",
    "        init_score=init_score,\n",
    "        feature_names=feature_names,\n",
    "        feature_types=feature_types\n",
    "    )\n",
    "    pairs = []\n",
    "    for (i, j), _ in interactions:\n",
    "        pairs.append((i, j))\n",
    "    return pairs, time.time() - t0\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Config / shapes\n",
    "# ----------------------\n",
    "D_2D_EDGE = 8 \n",
    "D_FLAT = D_2D_EDGE * D_2D_EDGE \n",
    "\n",
    "normal_t = np.array([[1,0],[1,1],[1,0]])\n",
    "normal_l = np.array([[1,0],[1,0],[1,1]])\n",
    "GT_MASK_2D = np.zeros((D_2D_EDGE, D_2D_EDGE), dtype=int)\n",
    "\n",
    "# Build the visual pattern (kept for reference/plots if you need it)\n",
    "if D_2D_EDGE >= 7: \n",
    "    GT_MASK_2D[1:4, 1:3] = normal_t\n",
    "    GT_MASK_2D[4:7, 5:7] = normal_l\n",
    "else:\n",
    "    print(f\"Warning: D_2D_EDGE ({D_2D_EDGE}) is too small for the example GT_MASK_2D pattern. GT mask will be mostly zeros.\")\n",
    "\n",
    "GT_MASK_2D_FLAT = GT_MASK_2D.flatten()  # This is the ORIGINAL main-effects mask (non-XOR meaning)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# XOR helpers\n",
    "# ----------------------\n",
    "def _xor_shape_index_sets(d_edge, normal_t, normal_l):\n",
    "    \"\"\"Return sets of flat indices for the T and L mini-shapes.\"\"\"\n",
    "    T_rows = slice(1, 4)  # [1:4)\n",
    "    T_cols = slice(1, 3)  # [1:3)\n",
    "    L_rows = slice(4, 7)  # [4:7)\n",
    "    L_cols = slice(5, 7)  # [5:7)\n",
    "\n",
    "    if d_edge < 7:\n",
    "        return set(), set()\n",
    "\n",
    "    mask_t = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_l = np.zeros((d_edge, d_edge), dtype=int)\n",
    "    mask_t[T_rows, T_cols] = normal_t\n",
    "    mask_l[L_rows, L_cols] = normal_l\n",
    "\n",
    "    idx_t = set(np.flatnonzero(mask_t.flatten()))\n",
    "    idx_l = set(np.flatnonzero(mask_l.flatten()))\n",
    "    return idx_t, idx_l\n",
    "\n",
    "def _is_xor_scenario(name: str) -> bool:\n",
    "    return 'xor' in str(name).lower()\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Interaction pair builders\n",
    "# ----------------------\n",
    "def qlr_pairs_upper_tri(d):\n",
    "    \"\"\"Pairs (i,j) with i <= j in np.triu_indices order.\"\"\"\n",
    "    i_idx, j_idx = np.triu_indices(d, 0)\n",
    "    return list(zip(i_idx.tolist(), j_idx.tolist()))\n",
    "\n",
    "def get_fast_pairs_for_scenario(scenario_full_name, n_interactions=128):\n",
    "    \"\"\"\n",
    "    Attempt to load the dataset for this scenario and compute FAST pairs.\n",
    "    Returns [] if unavailable.\n",
    "    \"\"\"\n",
    "    data_path = f'./data/xai_tris/{scenario_full_name}.pkl'\n",
    "    if not os.path.exists(data_path):\n",
    "        return []\n",
    "    try:\n",
    "        with open(data_path, \"rb\") as f:\n",
    "            data = pkl.load(f)\n",
    "        X_train_tensor = data.x_train.float()\n",
    "        y_train_tensor = data.y_train\n",
    "        pairs, _ = FAST(X_train_tensor, y_train_tensor, n_interactions=n_interactions)\n",
    "        return pairs\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Ground-truth constructors (64 + interactions)\n",
    "# ----------------------\n",
    "def create_gt_mask_interactions_generic(\n",
    "    main_effect_ground_truth_flat: np.ndarray,\n",
    "    custom_interaction_pairs,\n",
    "    d_flat: int,\n",
    "    d_edge: int,\n",
    "    is_xor: bool,\n",
    "    idx_t=None,\n",
    "    idx_l=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For methods with explicit interaction list (NAM/EBM/PatternGAM).\n",
    "    XOR:\n",
    "        - mains = 0\n",
    "        - interactions = 1 iff one endpoint in T and the other in L; diag ignored (pairs should be i != j).\n",
    "    non-XOR:\n",
    "        - mains = main_effect_ground_truth_flat\n",
    "        - interactions = 1 iff both endpoints are 1 in main_effect_ground_truth_flat.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray) or main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D numpy array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat length must equal d_flat.\")\n",
    "\n",
    "    m = len(custom_interaction_pairs)\n",
    "    if is_xor:\n",
    "        if idx_t is None or idx_l is None:\n",
    "            idx_t, idx_l = _xor_shape_index_sets(d_edge, normal_t, normal_l)\n",
    "        main_part = np.zeros(d_flat, dtype=int)\n",
    "        inter = []\n",
    "        for (i, j) in custom_interaction_pairs:\n",
    "            if not (0 <= i < d_flat and 0 <= j < d_flat) or i == j:\n",
    "                inter.append(0); continue\n",
    "            cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "            inter.append(1 if cross else 0)\n",
    "        inter_part = np.array(inter, dtype=int)\n",
    "        return np.concatenate([main_part, inter_part])\n",
    "    else:\n",
    "        main_part = main_effect_ground_truth_flat.astype(int)\n",
    "        inter = []\n",
    "        for (i, j) in custom_interaction_pairs:\n",
    "            good = (0 <= i < d_flat) and (0 <= j < d_flat)\n",
    "            inter.append(1 if (good and main_part[i] == 1 and main_part[j] == 1) else 0)\n",
    "        inter_part = np.array(inter, dtype=int)\n",
    "        return np.concatenate([main_part, inter_part])\n",
    "\n",
    "\n",
    "def create_qlr_ground_truth_mask_generic(\n",
    "    main_effect_ground_truth_flat: np.ndarray,\n",
    "    d_flat: int,\n",
    "    d_edge: int,\n",
    "    is_xor: bool,\n",
    "    idx_t=None,\n",
    "    idx_l=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For PatternQLR (mains + all degree-2 terms in np.triu order, incl. diagonal).\n",
    "    XOR:\n",
    "        - mains = 0\n",
    "        - quadratic terms: 1 iff i != j and {i,j} is a cross-shape pair (T vs L); diag = 0.\n",
    "    non-XOR:\n",
    "        - mains = main_effect_ground_truth_flat\n",
    "        - quadratic terms: \n",
    "              diag(i,i) = 1 iff main_effect_ground_truth_flat[i] == 1\n",
    "              off-diag(i<j) = 1 iff both endpoints are 1 in main GT.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_effect_ground_truth_flat, np.ndarray) or main_effect_ground_truth_flat.ndim != 1:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat must be a 1D numpy array.\")\n",
    "    if len(main_effect_ground_truth_flat) != d_flat:\n",
    "        raise ValueError(\"main_effect_ground_truth_flat length must equal d_flat.\")\n",
    "\n",
    "    inds_0, inds_1 = np.triu_indices(d_flat, 0)\n",
    "    quad = np.zeros(len(inds_0), dtype=int)\n",
    "\n",
    "    if is_xor:\n",
    "        if idx_t is None or idx_l is None:\n",
    "            idx_t, idx_l = _xor_shape_index_sets(d_edge, normal_t, normal_l)\n",
    "        main_part = np.zeros(d_flat, dtype=int)\n",
    "        for k in range(len(inds_0)):\n",
    "            i, j = int(inds_0[k]), int(inds_1[k])\n",
    "            if i == j:\n",
    "                quad[k] = 0\n",
    "            else:\n",
    "                cross = ((i in idx_t and j in idx_l) or (i in idx_l and j in idx_t))\n",
    "                quad[k] = 1 if cross else 0\n",
    "        return np.concatenate([main_part, quad])\n",
    "    else:\n",
    "        main_part = main_effect_ground_truth_flat.astype(int)\n",
    "        for k in range(len(inds_0)):\n",
    "            i, j = int(inds_0[k]), int(inds_1[k])\n",
    "            if i == j:\n",
    "                quad[k] = 1 if main_part[i] == 1 else 0\n",
    "            else:\n",
    "                quad[k] = 1 if (main_part[i] == 1 and main_part[j] == 1) else 0\n",
    "        return np.concatenate([main_part, quad])\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# EMD / FNI-EMD\n",
    "# ----------------------\n",
    "def calculate_emd_score_metric(gt_mask_flat, attribution_flat, grid_edge_length, base_cost_matrix, is_fni=False):\n",
    "    \"\"\"\n",
    "    64-D EMD/FNI-EMD (main effects grid). Kept for non-interaction methods.\n",
    "    \"\"\"\n",
    "    if not (isinstance(gt_mask_flat, np.ndarray) and gt_mask_flat.ndim == 1 and\n",
    "            isinstance(attribution_flat, np.ndarray) and attribution_flat.ndim == 1 and\n",
    "            len(gt_mask_flat) == len(attribution_flat) and\n",
    "            len(gt_mask_flat) == grid_edge_length * grid_edge_length):\n",
    "        return np.nan\n",
    "\n",
    "    current_cost_matrix = np.copy(base_cost_matrix)\n",
    "    if is_fni:\n",
    "        gt_indices = np.where(gt_mask_flat == 1)[0]\n",
    "        for r_idx in gt_indices:\n",
    "            for c_idx in gt_indices:\n",
    "                if r_idx < current_cost_matrix.shape[0] and c_idx < current_cost_matrix.shape[1]:\n",
    "                    current_cost_matrix[r_idx, c_idx] = 0.0\n",
    "    \n",
    "    sum_gt = np.sum(gt_mask_flat)\n",
    "    abs_attribution = np.abs(attribution_flat)\n",
    "    sum_attr = np.sum(abs_attribution)\n",
    "\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9:\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9:\n",
    "        return 0.0\n",
    "        \n",
    "    dist_gt = gt_mask_flat.astype(np.float64) / sum_gt\n",
    "    dist_attr = abs_attribution.astype(np.float64) / sum_attr\n",
    "\n",
    "    dist_gt_c = np.ascontiguousarray(dist_gt, dtype=np.float64)\n",
    "    dist_attr_c = np.ascontiguousarray(dist_attr, dtype=np.float64)\n",
    "    current_cost_matrix_c = np.ascontiguousarray(current_cost_matrix, dtype=np.float64)\n",
    "\n",
    "    _, log = emd(dist_gt_c, dist_attr_c, current_cost_matrix_c, numItermax=200000, log=True)\n",
    "    d_max = np.sqrt(2 * (grid_edge_length - 1)**2) if grid_edge_length > 1 else 0.0\n",
    "    if d_max == 0:\n",
    "        return 1.0 if np.isclose(log['cost'], 0) else 0.0\n",
    "    return 1 - (log['cost'] / d_max)\n",
    "\n",
    "def _grid_coords_for_main(d_edge):\n",
    "    coords = []\n",
    "    for r in range(d_edge):\n",
    "        for c in range(d_edge):\n",
    "            coords.append((float(r), float(c)))\n",
    "    return np.array(coords, dtype=float)\n",
    "\n",
    "def _coords_for_interactions_from_pairs(d_edge, pairs):\n",
    "    main_coords = _grid_coords_for_main(d_edge)\n",
    "    coords = []\n",
    "    for (i, j) in pairs:\n",
    "        ri, ci = main_coords[i]\n",
    "        rj, cj = main_coords[j]\n",
    "        coords.append(((ri + rj) / 2.0, (ci + cj) / 2.0))\n",
    "    return np.array(coords, dtype=float)\n",
    "\n",
    "def _emd_with_arbitrary_cost(gt_vec, attr_vec, cost_matrix, d_edge, is_fni=False):\n",
    "    \"\"\"EMD/FNI-EMD for arbitrary square cost matrix; normalization keeps main-grid Dmax.\"\"\"\n",
    "    if gt_vec.shape != attr_vec.shape:\n",
    "        return np.nan\n",
    "    if cost_matrix.shape[0] != cost_matrix.shape[1] or cost_matrix.shape[0] != gt_vec.shape[0]:\n",
    "        return np.nan\n",
    "\n",
    "    C = np.array(cost_matrix, dtype=float)\n",
    "    if is_fni:\n",
    "        gt_idx = np.flatnonzero(gt_vec > 0)\n",
    "        if gt_idx.size > 0:\n",
    "            C = C.copy()\n",
    "            C[np.ix_(gt_idx, gt_idx)] = 0.0\n",
    "\n",
    "    sum_gt = float(np.sum(gt_vec))\n",
    "    sum_attr = float(np.sum(attr_vec))\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9:\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9:\n",
    "        return 0.0\n",
    "\n",
    "    p = (gt_vec / sum_gt).astype(np.float64)\n",
    "    q = (attr_vec / sum_attr).astype(np.float64)\n",
    "    _, log = emd(p, q, C, numItermax=200000, log=True)\n",
    "\n",
    "    d_max = np.sqrt(2 * (d_edge - 1)**2) if d_edge > 1 else 0.0\n",
    "    if d_max == 0:\n",
    "        return 1.0 if np.isclose(log['cost'], 0) else 0.0\n",
    "    return 1.0 - (log['cost'] / d_max)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# IMA\n",
    "# ----------------------\n",
    "def importance_mass_accuracy(gt_mask, attribution):\n",
    "    if not isinstance(gt_mask, np.ndarray) or not isinstance(attribution, np.ndarray):\n",
    "        return np.nan\n",
    "    if attribution.ndim != 1 or len(gt_mask) != len(attribution):\n",
    "        return np.nan\n",
    "    \n",
    "    abs_attribution = np.abs(attribution)\n",
    "    mass_in_gt = np.sum(abs_attribution[gt_mask == 1])\n",
    "    total_mass = np.sum(abs_attribution)\n",
    "    \n",
    "    if total_mass == 0:\n",
    "        return 1.0 if mass_in_gt == 0 else 0.0\n",
    "    return mass_in_gt / total_mass\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Cost matrix (64-D main grid)\n",
    "# ----------------------\n",
    "def create_cost_matrix(grid_edge_length):\n",
    "    if grid_edge_length == 0:\n",
    "        return np.array([]).reshape(0, 0)\n",
    "    total = grid_edge_length * grid_edge_length\n",
    "    if total == 1:\n",
    "        return np.array([[0.0]])\n",
    "    indices_matrix = np.indices((grid_edge_length, grid_edge_length))\n",
    "    coordinates = [(indices_matrix[0][r, c], indices_matrix[1][r, c])\n",
    "                   for r in range(grid_edge_length) for c in range(grid_edge_length)]\n",
    "    coordinates = np.array(coordinates)\n",
    "    return cdist(coordinates, coordinates)\n",
    "\n",
    "COST_MATRIX_MAIN_EFFECTS = create_cost_matrix(D_2D_EDGE)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Main processing (original metrics now full-dim when applicable)\n",
    "# ----------------------\n",
    "INTERACTION_METHODS = {'pattern_gam', 'ebm', 'nam', 'discr', 'pattern_qlr'}\n",
    "\n",
    "def process_explanations_metrics(explanations_dict, main_effect_gt_flat, d_flat_main, d_edge_main, cost_mat_main):\n",
    "    \"\"\"\n",
    "    For interaction methods, compute ORIGINAL metrics using the full feature space:\n",
    "      - NAM/EBM/PatternGAM: length = 64 + len(FAST pairs)\n",
    "      - PatternQLR: length = 64 + D*(D+1)/2 (mains + all degree-2 terms in triu order)\n",
    "    For other methods, keep the 64-D main-effects evaluation.\n",
    "    \"\"\"\n",
    "    results_raw_collection = {} \n",
    "\n",
    "    for scenario_full_name, methods_data in explanations_dict.items():\n",
    "        if 'translations' in scenario_full_name:\n",
    "            continue\n",
    "\n",
    "        scenario_parts = scenario_full_name.split('_')\n",
    "        try:\n",
    "            scenario_base_name = '_'.join(scenario_parts[:-1])\n",
    "        except ValueError:\n",
    "            scenario_base_name = scenario_full_name\n",
    "\n",
    "        is_xor = _is_xor_scenario(scenario_full_name)\n",
    "        idx_t, idx_l = _xor_shape_index_sets(d_edge_main, normal_t, normal_l) if is_xor else (None, None)\n",
    "\n",
    "        # Try to get FAST pairs (order must match models' interaction ordering)\n",
    "        pairs_for_scenario = get_fast_pairs_for_scenario(scenario_full_name, n_interactions=128)\n",
    "\n",
    "        if scenario_base_name not in results_raw_collection:\n",
    "            results_raw_collection[scenario_base_name] = {}\n",
    "\n",
    "        for method_name, explanation_content in methods_data.items():\n",
    "            if method_name not in results_raw_collection[scenario_base_name]:\n",
    "                results_raw_collection[scenario_base_name][method_name] = {'IMA': [], 'EMD': [], 'FNI_EMD': []}\n",
    "\n",
    "            # normalize explanation to a single 1D vector\n",
    "            current_explanation = explanation_content\n",
    "            if isinstance(current_explanation, list):\n",
    "                current_explanation = np.array(current_explanation)\n",
    "\n",
    "            if not isinstance(current_explanation, np.ndarray):\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(np.nan)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            if current_explanation.ndim > 1 and current_explanation.shape[0] > 1 and \\\n",
    "               not (current_explanation.shape[0] == d_flat_main and current_explanation.ndim == 2 and current_explanation.shape[1] == 1 and d_flat_main > 1):\n",
    "                if np.ndim(current_explanation[0]) == 3:\n",
    "                    processed_attr = np.mean(np.mean(np.array(current_explanation), axis=0).squeeze(), axis=0)\n",
    "                else:\n",
    "                    processed_attr = np.mean(np.vstack(current_explanation), axis=0)\n",
    "            else:\n",
    "                processed_attr = current_explanation.flatten()\n",
    "\n",
    "            # -----------------------\n",
    "            # Build ground truth & geometry matching the method's mapping\n",
    "            # -----------------------\n",
    "            use_full = (method_name in INTERACTION_METHODS) and (processed_attr.size > d_flat_main)\n",
    "\n",
    "            if method_name in {'nam', 'ebm', 'pattern_gam', 'discr'} and use_full:\n",
    "                # NAM/EBM/PatternGAM: mains + FAST pairs\n",
    "                if len(pairs_for_scenario) == 0:\n",
    "                    # Fall back (cannot fabricate interaction order)\n",
    "                    gt_for_ima = main_effect_gt_flat\n",
    "                    attr_for_ima = processed_attr[:d_flat_main]\n",
    "                    # 64-D EMD/FNI only\n",
    "                    emd_val = calculate_emd_score_metric(main_effect_gt_flat, attr_for_ima, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                    fni_val = calculate_emd_score_metric(main_effect_gt_flat, attr_for_ima, d_edge_main, cost_mat_main, is_fni=True)\n",
    "                    ima_val = importance_mass_accuracy(gt_for_ima, attr_for_ima)\n",
    "                    results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                    results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                    results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "                    continue\n",
    "\n",
    "                # GT (64 + m)\n",
    "                gt_full = create_gt_mask_interactions_generic(\n",
    "                    main_effect_gt_flat, pairs_for_scenario, d_flat_main, d_edge_main, is_xor, idx_t, idx_l\n",
    "                )\n",
    "                m = len(pairs_for_scenario)\n",
    "                # Align attribution length to 64+m\n",
    "                full_len = d_flat_main + m\n",
    "                attr_full = processed_attr[:full_len]\n",
    "                if attr_full.shape[0] != full_len:\n",
    "                    tmp = np.zeros(full_len, dtype=float)\n",
    "                    n = min(len(processed_attr), full_len)\n",
    "                    tmp[:n] = processed_attr[:n]\n",
    "                    attr_full = tmp\n",
    "\n",
    "                # Geometry: mains at grid, interactions at midpoints of FAST pairs\n",
    "                main_coords = _grid_coords_for_main(d_edge_main)         # (64,2)\n",
    "                inter_coords = _coords_for_interactions_from_pairs(d_edge_main, pairs_for_scenario)  # (m,2)\n",
    "                coords = np.vstack([main_coords, inter_coords])          # (64+m,2)\n",
    "                C = cdist(coords, coords)\n",
    "\n",
    "                # IMA / EMD / FNI-EMD in full space\n",
    "                ima_val = importance_mass_accuracy(gt_full, attr_full)\n",
    "                emd_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=False)\n",
    "                fni_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=True)\n",
    "\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "\n",
    "            elif method_name == 'pattern_qlr' and use_full:\n",
    "                # QLR: mains + all quadratic terms in upper-tri order (incl diag)\n",
    "                pairs_triu = qlr_pairs_upper_tri(d_flat_main)\n",
    "                gt_full = create_qlr_ground_truth_mask_generic(\n",
    "                    main_effect_gt_flat, d_flat_main, d_edge_main, is_xor, idx_t, idx_l\n",
    "                )\n",
    "                # Align attribution to (64 + len(triu))\n",
    "                full_len = d_flat_main + len(pairs_triu)\n",
    "                attr_full = processed_attr[:full_len]\n",
    "                if attr_full.shape[0] != full_len:\n",
    "                    tmp = np.zeros(full_len, dtype=float)\n",
    "                    n = min(len(processed_attr), full_len)\n",
    "                    tmp[:n] = processed_attr[:n]\n",
    "                    attr_full = tmp\n",
    "\n",
    "                # Geometry: mains on grid; interactions at midpoints for triu pairs\n",
    "                main_coords = _grid_coords_for_main(d_edge_main)\n",
    "                inter_coords = _coords_for_interactions_from_pairs(d_edge_main, pairs_triu)\n",
    "                coords = np.vstack([main_coords, inter_coords])\n",
    "                C = cdist(coords, coords)\n",
    "\n",
    "                ima_val = importance_mass_accuracy(gt_full, attr_full)\n",
    "                emd_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=False)\n",
    "                fni_val = _emd_with_arbitrary_cost(gt_full.astype(float), np.abs(attr_full).astype(float), C, d_edge_main, is_fni=True)\n",
    "\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "\n",
    "            else:\n",
    "                # Non-interaction methods or methods without interaction tail -> 64-D original behavior\n",
    "                attr_main_eff = processed_attr[:d_flat_main]\n",
    "                gt_main_eff = main_effect_gt_flat\n",
    "\n",
    "                # IMA: 64-D\n",
    "                ima_val = importance_mass_accuracy(gt_main_eff, attr_main_eff)\n",
    "\n",
    "                # EMD & FNI-EMD: 64-D\n",
    "                emd_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_val = calculate_emd_score_metric(gt_main_eff, attr_main_eff, d_edge_main, cost_mat_main, is_fni=True)\n",
    "\n",
    "                results_raw_collection[scenario_base_name][method_name]['IMA'].append(ima_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['EMD'].append(emd_val)\n",
    "                results_raw_collection[scenario_base_name][method_name]['FNI_EMD'].append(fni_val)\n",
    "\n",
    "    # --- Aggregation ---\n",
    "    final_aggregated_results = {}\n",
    "    for sc_base, meth_data in results_raw_collection.items():\n",
    "        final_aggregated_results[sc_base] = {}\n",
    "        for meth, metrics_lists in meth_data.items():\n",
    "            final_aggregated_results[sc_base][meth] = {\n",
    "                'IMA_mean': np.nanmean(metrics_lists['IMA']) if metrics_lists['IMA'] else np.nan,\n",
    "                'IMA_std':  np.nanstd(metrics_lists['IMA'])  if metrics_lists['IMA'] else np.nan,\n",
    "                'EMD_mean': np.nanmean(metrics_lists['EMD']) if metrics_lists['EMD'] else np.nan,\n",
    "                'EMD_std':  np.nanstd(metrics_lists['EMD'])  if metrics_lists['EMD'] else np.nan,\n",
    "                'FNI_EMD_mean': np.nanmean(metrics_lists['FNI_EMD']) if metrics_lists['FNI_EMD'] else np.nan,\n",
    "                'FNI_EMD_std':  np.nanstd(metrics_lists['FNI_EMD'])  if metrics_lists['FNI_EMD'] else np.nan,\n",
    "            }\n",
    "    return final_aggregated_results\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Run\n",
    "# ----------------------\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"D_2D_EDGE (grid edge for main effects): {D_2D_EDGE}\")\n",
    "print(f\"D_FLAT (total main effect features): {D_FLAT}\")\n",
    "print(f\"Sum of GT_MASK_2D_FLAT (non-XOR main GT): {np.sum(GT_MASK_2D_FLAT)}\")\n",
    "print(f\"Cost matrix for main effects shape: {COST_MATRIX_MAIN_EFFECTS.shape}\")\n",
    "print(f\"--- Starting Metric Calculation ---\")\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)\n",
    "\n",
    "aggregated_metrics = process_explanations_metrics(\n",
    "    explanations,\n",
    "    GT_MASK_2D_FLAT,   # For XOR runs, mains are overridden to 0 inside the GT builders for interaction methods\n",
    "    D_FLAT,\n",
    "    D_2D_EDGE,\n",
    "    COST_MATRIX_MAIN_EFFECTS\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Aggregated Results ---\")\n",
    "for scenario_name, method_data in aggregated_metrics.items():\n",
    "    print(f\"\\nScenario Type: {scenario_name}\")\n",
    "    for method, scores in method_data.items():\n",
    "        print(f\"  Method: {method}\")\n",
    "        print(f\"    IMA    : Mean = {scores['IMA_mean']:.4f}, Std = {scores['IMA_std']:.4f}\")\n",
    "        print(f\"    EMD    : Mean = {scores['EMD_mean']:.4f}, Std = {scores['EMD_std']:.4f}\")\n",
    "        print(f\"    FNI-EMD: Mean = {scores['FNI_EMD_mean']:.4f}, Std = {scores['FNI_EMD_std']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efe0afc-e6d5-4fe6-807b-37e6163e6aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating LaTeX Tables with Final Custom Row and Column Layout ---\n",
      "\n",
      "% --- LaTeX Table for IMA (final layout, bolded best) ---\n",
      "% LaTeX Table for IMA with custom layout and best result emboldened\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Importance Mass Accuracy (IMA). Values are mean $\\pm$ standard deviation. Best result per row is emboldened.}\n",
      "\\label{tab:ima_results_final_layout}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{l|cccccccccc}\n",
      "\\hline\n",
      "Scenario & pattern\\_gam & pattern\\_qlr & nam & ebm & kernel\\_svm & pattern\\_net & pattern\\_attribution & shap & ig & discr \\\\ \\hline\\hline\n",
      "XOR DIST CORR & $0.57 \\pm 0.08$ & $0.23 \\pm 0.04$ & $0.36 \\pm 0.04$ & $0.03 \\pm 0.02$ & $0.12 \\pm 0.05$ & $0.61 \\pm 0.19$ & $\\mathbf{0.77 \\pm 0.13}$ & $0.41 \\pm 0.04$ & $0.73 \\pm 0.09$ & $0.12 \\pm 0.03$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "% --- End of LaTeX Table ---\n",
      "\n",
      "% --- LaTeX Table for EMD (final layout, bolded best) ---\n",
      "% LaTeX Table for EMD with custom layout and best result emboldened\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Earth Mover's Distance (EMD). Values are mean $\\pm$ standard deviation. Best result per row is emboldened.}\n",
      "\\label{tab:emd_results_final_layout}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{l|cccccccccc}\n",
      "\\hline\n",
      "Scenario & pattern\\_gam & pattern\\_qlr & nam & ebm & kernel\\_svm & pattern\\_net & pattern\\_attribution & shap & ig & discr \\\\ \\hline\\hline\n",
      "XOR DIST CORR & $0.81 \\pm 0.02$ & $0.78 \\pm 0.02$ & $0.83 \\pm 0.03$ & $0.82 \\pm 0.00$ & $0.78 \\pm 0.04$ & $0.89 \\pm 0.07$ & $\\mathbf{0.91 \\pm 0.02}$ & $0.87 \\pm 0.02$ & $0.90 \\pm 0.05$ & $0.80 \\pm 0.02$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "% --- End of LaTeX Table ---\n",
      "\n",
      "% --- LaTeX Table for FNI-EMD (final layout, bolded best) ---\n",
      "% LaTeX Table for FNI-EMD with custom layout and best result emboldened\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Feature Preservation Index EMD (FNI-EMD). Values are mean $\\pm$ standard deviation. Best result per row is emboldened.}\n",
      "\\label{tab:fniemd_results_final_layout}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{l|cccccccccc}\n",
      "\\hline\n",
      "Scenario & pattern\\_gam & pattern\\_qlr & nam & ebm & kernel\\_svm & pattern\\_net & pattern\\_attribution & shap & ig & discr \\\\ \\hline\\hline\n",
      "XOR DIST CORR & $0.82 \\pm 0.02$ & $0.79 \\pm 0.02$ & $0.84 \\pm 0.03$ & $0.82 \\pm 0.00$ & $0.79 \\pm 0.04$ & $0.92 \\pm 0.04$ & $\\mathbf{0.96 \\pm 0.03}$ & $0.91 \\pm 0.01$ & $0.96 \\pm 0.01$ & $0.81 \\pm 0.02$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "% --- End of LaTeX Table ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_scenario_name_for_table(scenario_base_name):\n",
    "    \"\"\"\n",
    "    Parses a scenario base name into a formatted string for table rows.\n",
    "    \"\"\"\n",
    "    name_lower = scenario_base_name.lower()\n",
    "    \n",
    "    base_type_str = \"OTHER\" \n",
    "    if \"xor\" in name_lower:\n",
    "        base_type_str = \"XOR\"\n",
    "    elif \"multiplicative\" in name_lower:\n",
    "        base_type_str = \"MULT\"\n",
    "    elif \"linear\" in name_lower: \n",
    "        base_type_str = \"LIN\"\n",
    "    elif \"additive\" in name_lower: \n",
    "        base_type_str = \"LIN\" \n",
    "\n",
    "    dist_str = \"\"\n",
    "    if \"_distractor\" in name_lower or \"distractor_\" in name_lower:\n",
    "        dist_str = \"DIST\"\n",
    "        \n",
    "    bg_str = \"UNK_BG\" \n",
    "    if \"white\" in name_lower:\n",
    "        bg_str = \"WHITE\"\n",
    "    elif \"correlated\" in name_lower:\n",
    "        bg_str = \"CORR\"\n",
    "        \n",
    "    return f\"{base_type_str} {dist_str} {bg_str}\".replace(\"  \", \" \").strip()\n",
    "\n",
    "def get_scenario_sort_key_v2(parsed_scenario_name):\n",
    "    \"\"\"\n",
    "    Generates a sort key tuple for a parsed scenario name to achieve the desired row order:\n",
    "    Primary group: Base Type (LIN, MULT, XOR, OTHER)\n",
    "    Secondary group (within Base Type): Non-DIST vs DIST\n",
    "    Tertiary group (within above): WHITE, CORR, UNK_BG\n",
    "    \"\"\"\n",
    "    parts = parsed_scenario_name.split(' ') \n",
    "\n",
    "    base_type = parts[0] \n",
    "    base_type_key = 3 \n",
    "    if base_type == \"LIN\": base_type_key = 0\n",
    "    elif base_type == \"MULT\": base_type_key = 1\n",
    "    elif base_type == \"XOR\": base_type_key = 2\n",
    "    \n",
    "    is_dist_key = 1 if \"DIST\" in parts else 0\n",
    "\n",
    "    bg_key = 2 \n",
    "    if \"WHITE\" in parts: bg_key = 0\n",
    "    elif \"CORR\" in parts: bg_key = 1\n",
    "        \n",
    "    return (base_type_key, is_dist_key, bg_key)\n",
    "\n",
    "\n",
    "def format_latex_value(mean_val, std_val, precision=2, is_bold=False):\n",
    "    \"\"\"Formats mean and std into LaTeX string, handling NaN and bolding.\"\"\"\n",
    "    if mean_val is None or std_val is None or np.isnan(mean_val) or np.isnan(std_val):\n",
    "        return \"-\"\n",
    "    \n",
    "    mean_str = f\"{mean_val:.{precision}f}\"\n",
    "    std_str = f\"{std_val:.{precision}f}\"\n",
    "    core_expression = f\"{mean_str} \\\\pm {std_str}\"\n",
    "    \n",
    "    if is_bold:\n",
    "        return f\"$\\\\mathbf{{{core_expression}}}$\"\n",
    "    else:\n",
    "        return f\"${core_expression}$\"\n",
    "\n",
    "def generate_latex_tables_final_layout(aggregated_metrics): # Renamed main function\n",
    "    \"\"\"\n",
    "    Generates three LaTeX tables (IMA, EMD, FNI-EMD) from aggregated metrics,\n",
    "    with specified row and column sorting, and emboldening the best result per row.\n",
    "    \"\"\"\n",
    "    data_for_tables = {}\n",
    "    all_method_names_in_data = set()\n",
    "\n",
    "    for scenario_base_name, methods_data in aggregated_metrics.items():\n",
    "        parsed_name = parse_scenario_name_for_table(scenario_base_name)\n",
    "        if parsed_name not in data_for_tables:\n",
    "            data_for_tables[parsed_name] = {}\n",
    "        \n",
    "        for method_name, metrics_values in methods_data.items():\n",
    "            all_method_names_in_data.add(method_name)\n",
    "            data_for_tables[parsed_name][method_name] = metrics_values\n",
    "\n",
    "    # Sort row labels using the custom key\n",
    "    sorted_row_labels = sorted(list(data_for_tables.keys()), key=get_scenario_sort_key_v2)\n",
    "    \n",
    "    # Define custom column order\n",
    "    custom_column_order = [\n",
    "        'pattern_gam', 'pattern_qlr', 'nam', 'ebm', 'kernel_svm', \n",
    "        'pattern_net', 'pattern_attribution', 'shap', 'ig'\n",
    "    ]\n",
    "\n",
    "    # Create the final ordered list of method names for columns\n",
    "    ordered_method_columns = [method for method in custom_column_order if method in all_method_names_in_data]\n",
    "    \n",
    "    remaining_methods_in_data = sorted(\n",
    "        [method for method in all_method_names_in_data if method not in ordered_method_columns]\n",
    "    )\n",
    "    ordered_method_columns.extend(remaining_methods_in_data)\n",
    "\n",
    "\n",
    "    latex_output_tables = {}\n",
    "    metrics_config = [\n",
    "        (\"IMA\", \"IMA_mean\", \"IMA_std\", \"Importance Mass Accuracy (IMA)\"),\n",
    "        (\"EMD\", \"EMD_mean\", \"EMD_std\", \"Earth Mover's Distance (EMD)\"),\n",
    "        (\"FNI-EMD\", \"FNI_EMD_mean\", \"FNI_EMD_std\", \"Feature Preservation Index EMD (FNI-EMD)\")\n",
    "    ]\n",
    "\n",
    "    for metric_key, mean_key, std_key, caption_title in metrics_config:\n",
    "        num_columns = len(ordered_method_columns)\n",
    "        table_cols_format = \"l|\" + \"c\" * num_columns \n",
    "        \n",
    "        latex_str = f\"% LaTeX Table for {metric_key} with custom layout and best result emboldened\\n\"\n",
    "        latex_str += \"\\\\begin{table}[htbp]\\n\"\n",
    "        latex_str += \"\\\\centering\\n\"\n",
    "        latex_str += f\"\\\\caption{{{caption_title}. Values are mean $\\\\pm$ standard deviation. Best result per row is emboldened.}}\\n\"\n",
    "        latex_str += f\"\\\\label{{tab:{metric_key.lower().replace('-', '')}_results_final_layout}}\\n\"\n",
    "        latex_str += f\"\\\\resizebox{{\\\\textwidth}}{{!}}{{\\n\" \n",
    "        latex_str += f\"\\\\begin{{tabular}}{{{table_cols_format}}}\\n\"\n",
    "        latex_str += \"\\\\hline\\n\"\n",
    "        \n",
    "        header_methods = [name.replace(\"_\", \"\\\\_\") for name in ordered_method_columns]\n",
    "        latex_str += \"Scenario & \" + \" & \".join(header_methods) + \" \\\\\\\\ \\\\hline\\\\hline\\n\"\n",
    "        \n",
    "        for row_label in sorted_row_labels:\n",
    "            means_for_current_row = []\n",
    "            for method_name_iter in ordered_method_columns: # Use the new column order here\n",
    "                val = data_for_tables.get(row_label, {}).get(method_name_iter, {}).get(mean_key)\n",
    "                if val is not None and not np.isnan(val):\n",
    "                    means_for_current_row.append(val)\n",
    "                else:\n",
    "                    means_for_current_row.append(-np.inf) \n",
    "\n",
    "            max_mean_in_row = -np.inf \n",
    "            if any(m != -np.inf for m in means_for_current_row):\n",
    "                max_mean_in_row = np.nanmax([m if m != -np.inf else np.nan for m in means_for_current_row])\n",
    "\n",
    "            row_values_formatted = [row_label] \n",
    "            for method_name in ordered_method_columns: # And here for data fetching\n",
    "                method_metrics = data_for_tables.get(row_label, {}).get(method_name, {})\n",
    "                mean_val = method_metrics.get(mean_key)\n",
    "                std_val = method_metrics.get(std_key)\n",
    "                \n",
    "                is_best_in_row = False\n",
    "                if mean_val is not None and not np.isnan(mean_val) and \\\n",
    "                   max_mean_in_row != -np.inf and not np.isnan(max_mean_in_row):\n",
    "                    if np.isclose(mean_val, max_mean_in_row):\n",
    "                        is_best_in_row = True\n",
    "                \n",
    "                row_values_formatted.append(format_latex_value(mean_val, std_val, is_bold=is_best_in_row))\n",
    "            \n",
    "            latex_str += \" & \".join(row_values_formatted) + \" \\\\\\\\\\n\"\n",
    "            \n",
    "        latex_str += \"\\\\hline\\n\"\n",
    "        latex_str += \"\\\\end{tabular}\\n\"\n",
    "        latex_str += \"}\\n\" \n",
    "        latex_str += \"\\\\end{table}\\n\"\n",
    "        \n",
    "        latex_output_tables[metric_key] = latex_str\n",
    "        \n",
    "    return latex_output_tables\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Sample aggregated_metrics dictionary to test sorting and column order\n",
    "\n",
    "\n",
    "    print(\"--- Generating LaTeX Tables with Final Custom Row and Column Layout ---\")\n",
    "    latex_tables_final_layout = generate_latex_tables_final_layout(aggregated_metrics)\n",
    "\n",
    "    for metric_name, table_code in latex_tables_final_layout.items():\n",
    "        print(f\"\\n% --- LaTeX Table for {metric_name} (final layout, bolded best) ---\")\n",
    "        print(table_code)\n",
    "        print(\"% --- End of LaTeX Table ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc9c1b4-2ae3-400f-bcb5-fb39d9fb5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "D_2D_EDGE (grid edge for main effects): 8\n",
      "D_FLAT (total main effect features): 64\n",
      "Sum of GT_MASK_2D_FLAT: 8\n",
      "Cost matrix for main effects shape: (64, 64)\n",
      "--- Starting Metric Calculation (with redistribution) ---\n",
      "\n",
      "--- Aggregated Results (Original, Sum, Weighted, Max) ---\n",
      "\n",
      "=== Scenario: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated ===\n",
      "\n",
      "IMA (Importance Mass Accuracy):\n",
      "                            original              sum         weighted              max\n",
      "discr                0.1178  0.0273  0.8692  0.0238  0.7617  0.0510  0.8956  0.0193\n",
      "ebm                  0.0304  0.0184  0.1441  0.0599  0.0784  0.0310  0.1187  0.0659\n",
      "ig                   0.7278  0.0947  0.7278  0.0947  0.7278  0.0947  0.7278  0.0947\n",
      "kernel_svm           0.1231  0.0520  0.1231  0.0520  0.1231  0.0520  0.1231  0.0520\n",
      "nam                  0.3641  0.0440  0.5350  0.0364  0.3663  0.0808  0.4708  0.0606\n",
      "pattern_attribution  0.7687  0.1277  0.7687  0.1277  0.7687  0.1277  0.7687  0.1277\n",
      "pattern_gam          0.5688  0.0803  0.6537  0.0521  0.4889  0.1072  0.6180  0.0679\n",
      "pattern_net          0.6141  0.1915  0.6141  0.1915  0.6141  0.1915  0.6141  0.1915\n",
      "pattern_qlr          0.2278  0.0385  0.4286  0.0132  0.3414  0.0063  0.5864  0.0835\n",
      "shap                 0.4130  0.0354  0.4130  0.0354  0.4130  0.0354  0.4130  0.0354\n",
      "\n",
      "EMD:\n",
      "                            original              sum         weighted              max\n",
      "discr                0.7986  0.0207  0.9457  0.0056  0.9176  0.0182  0.9430  0.0052\n",
      "ebm                  0.8151  0.0017  0.7888  0.0304  0.7700  0.0186  0.7796  0.0325\n",
      "ig                   0.8995  0.0460  0.8995  0.0460  0.8995  0.0460  0.8995  0.0460\n",
      "kernel_svm           0.7781  0.0351  0.7781  0.0351  0.7781  0.0351  0.7781  0.0351\n",
      "nam                  0.8256  0.0312  0.8918  0.0115  0.8687  0.0137  0.8779  0.0144\n",
      "pattern_attribution  0.9095  0.0230  0.9095  0.0230  0.9095  0.0230  0.9095  0.0230\n",
      "pattern_gam          0.8095  0.0182  0.9203  0.0112  0.8816  0.0176  0.9144  0.0123\n",
      "pattern_net          0.8891  0.0687  0.8891  0.0687  0.8891  0.0687  0.8891  0.0687\n",
      "pattern_qlr          0.7832  0.0221  0.8818  0.0092  0.8564  0.0100  0.9194  0.0219\n",
      "shap                 0.8734  0.0237  0.8734  0.0237  0.8734  0.0237  0.8734  0.0237\n",
      "\n",
      "FNI-EMD:\n",
      "                            original              sum         weighted              max\n",
      "discr                0.8052  0.0216  0.9729  0.0065  0.9516  0.0112  0.9790  0.0046\n",
      "ebm                  0.8213  0.0017  0.8129  0.0270  0.7850  0.0229  0.8009  0.0317\n",
      "ig                   0.9580  0.0128  0.9580  0.0128  0.9580  0.0128  0.9580  0.0128\n",
      "kernel_svm           0.7869  0.0377  0.7869  0.0377  0.7869  0.0377  0.7869  0.0377\n",
      "nam                  0.8414  0.0304  0.9150  0.0127  0.8853  0.0125  0.9058  0.0167\n",
      "pattern_attribution  0.9603  0.0289  0.9603  0.0289  0.9603  0.0289  0.9603  0.0289\n",
      "pattern_gam          0.8196  0.0202  0.9308  0.0096  0.8970  0.0196  0.9250  0.0133\n",
      "pattern_net          0.9235  0.0400  0.9235  0.0400  0.9235  0.0400  0.9235  0.0400\n",
      "pattern_qlr          0.7941  0.0250  0.8908  0.0052  0.8679  0.0087  0.9260  0.0210\n",
      "shap                 0.9112  0.0105  0.9112  0.0105  0.9112  0.0105  0.9112  0.0105\n"
     ]
    }
   ],
   "source": [
    "# ==== ADDITIONS / REPLACEMENTS START HERE ====\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot import emd\n",
    "\n",
    "# -----------------------------\n",
    "# (1) Redistribution functions\n",
    "# -----------------------------\n",
    "\n",
    "# --- original sum version (absolute attributions; each pair split 0.5/0.5) ---\n",
    "def transform_interaction_sum(pattern, interaction_pairs=(), d=64):\n",
    "    pattern = np.asarray(pattern)\n",
    "    feat_imp = np.zeros(d, dtype=float)\n",
    "    feat_imp += np.abs(pattern[:d])\n",
    "    inter_vals = np.abs(pattern[d:])\n",
    "    for k, (i, j) in enumerate(interaction_pairs):\n",
    "        v = inter_vals[k]\n",
    "        feat_imp[i] += 0.5 * v\n",
    "        feat_imp[j] += 0.5 * v\n",
    "    return feat_imp\n",
    "\n",
    "# --- weighted sum version (divide pairwise mass by node degree) ---\n",
    "def transform_interaction_weighted_sum(pattern, interaction_pairs=(), d=64):\n",
    "    pattern = np.asarray(pattern)\n",
    "    main_abs = np.abs(pattern[:d])\n",
    "    inter_vals = np.abs(pattern[d:])\n",
    "\n",
    "    inter_sum = np.zeros(d, dtype=float)\n",
    "    degree = np.zeros(d, dtype=float)\n",
    "\n",
    "    for k, (i, j) in enumerate(interaction_pairs):\n",
    "        v = inter_vals[k]\n",
    "        inter_sum[i] += v\n",
    "        inter_sum[j] += v\n",
    "        degree[i] += 1.0\n",
    "        degree[j] += 1.0\n",
    "\n",
    "    # divide per-feature interaction mass by its incident count when > 0\n",
    "    out = main_abs.copy()\n",
    "    nonzero = degree > 0\n",
    "    out[nonzero] += inter_sum[nonzero] / degree[nonzero]\n",
    "    out[~nonzero] += 0.0\n",
    "    return out\n",
    "\n",
    "# --- max redistribution, signed (metrics later take abs anyway) ---\n",
    "def transform_interaction_max_signed(pattern, interaction_pairs=(), d=None):\n",
    "    pattern = np.asarray(pattern)\n",
    "    m = len(interaction_pairs)\n",
    "    if d is None:\n",
    "        d = pattern.size - m\n",
    "    if d + m != pattern.size or d <= 0:\n",
    "        raise ValueError(\"Length mismatch: expected len(pattern) == d + len(interaction_pairs).\")\n",
    "    main = pattern[:d]\n",
    "    inter = pattern[d:] if m > 0 else np.empty(0, dtype=pattern.dtype)\n",
    "    adj = [[] for _ in range(d)]\n",
    "    for k, (i, j) in enumerate(interaction_pairs):\n",
    "        if not (0 <= i < d and 0 <= j < d):\n",
    "            raise ValueError(f\"interaction_pairs[{k}] = ({i},{j}) out of range [0,{d-1}]\")\n",
    "        adj[i].append(k); adj[j].append(k)\n",
    "    out = np.empty(d, dtype=float)\n",
    "    for i in range(d):\n",
    "        best_val = float(main[i]); best_abs = abs(best_val)\n",
    "        for k in adj[i]:\n",
    "            v = float(inter[k]); av = abs(v)\n",
    "            if av > best_abs:\n",
    "                best_val = v; best_abs = av\n",
    "        out[i] = best_val\n",
    "    return out\n",
    "\n",
    "# helper: unsigned version of max (for symmetry with the other two)\n",
    "def transform_interaction_max_abs(pattern, interaction_pairs=(), d=64):\n",
    "    return np.abs(transform_interaction_max_signed(pattern, interaction_pairs, d=d))\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# (2) QLR interaction-pair construction\n",
    "# ---------------------------------------\n",
    "def qlr_pairs_upper_tri(d):\n",
    "    \"\"\"Pairs (i,j) with i <= j, in the same order as np.triu_indices(d, 0).\"\"\"\n",
    "    i_idx, j_idx = np.triu_indices(d, 0)\n",
    "    return list(zip(i_idx.tolist(), j_idx.tolist()))\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# (3) Metric functions (FNI -> FNI rename applied)\n",
    "# -------------------------------------------------\n",
    "def importance_mass_accuracy(gt_mask, attribution):\n",
    "    if not isinstance(gt_mask, np.ndarray) or not isinstance(attribution, np.ndarray):\n",
    "        return np.nan\n",
    "    if attribution.ndim != 1 or len(gt_mask) != len(attribution):\n",
    "        return np.nan\n",
    "    abs_attr = np.abs(attribution)\n",
    "    mass_in_gt = np.sum(abs_attr[gt_mask == 1])\n",
    "    total_mass = np.sum(abs_attr)\n",
    "    if total_mass == 0:\n",
    "        return 1.0 if mass_in_gt == 0 else 0.0\n",
    "    return mass_in_gt / total_mass\n",
    "\n",
    "def create_cost_matrix(grid_edge_length):\n",
    "    if grid_edge_length == 0:\n",
    "        return np.array([]).reshape(0,0)\n",
    "    total = grid_edge_length * grid_edge_length\n",
    "    if total == 1:\n",
    "        return np.array([[0.0]])\n",
    "    indices_matrix = np.indices((grid_edge_length, grid_edge_length))\n",
    "    coordinates = [(indices_matrix[0][r, c], indices_matrix[1][r, c])\n",
    "                   for r in range(grid_edge_length) for c in range(grid_edge_length)]\n",
    "    coordinates = np.array(coordinates)\n",
    "    return cdist(coordinates, coordinates)\n",
    "\n",
    "def calculate_emd_score_metric(gt_mask_flat, attribution_flat, grid_edge_length, base_cost_matrix, is_fni=False):\n",
    "    # Same implementation as your original, only the flag/name changed to is_fni.\n",
    "    if not (isinstance(gt_mask_flat, np.ndarray) and gt_mask_flat.ndim == 1 and\n",
    "            isinstance(attribution_flat, np.ndarray) and attribution_flat.ndim == 1 and\n",
    "            len(gt_mask_flat) == len(attribution_flat) and\n",
    "            len(gt_mask_flat) == grid_edge_length * grid_edge_length):\n",
    "        return np.nan\n",
    "\n",
    "    current_cost_matrix = np.copy(base_cost_matrix)\n",
    "    if is_fni:\n",
    "        gt_indices = np.where(gt_mask_flat == 1)[0]\n",
    "        for r_idx in gt_indices:\n",
    "            for c_idx in gt_indices:\n",
    "                if r_idx < current_cost_matrix.shape[0] and c_idx < current_cost_matrix.shape[1]:\n",
    "                    current_cost_matrix[r_idx, c_idx] = 0.0\n",
    "\n",
    "    sum_gt = np.sum(gt_mask_flat)\n",
    "    abs_attribution = np.abs(attribution_flat)\n",
    "    sum_attr = np.sum(abs_attribution)\n",
    "\n",
    "    if sum_gt < 1e-9 and sum_attr < 1e-9:\n",
    "        return 1.0\n",
    "    if sum_gt < 1e-9 or sum_attr < 1e-9:\n",
    "        return 0.0\n",
    "\n",
    "    dist_gt = gt_mask_flat.astype(np.float64) / sum_gt\n",
    "    dist_attr = abs_attribution.astype(np.float64) / sum_attr\n",
    "\n",
    "    dist_gt_c = np.ascontiguousarray(dist_gt, dtype=np.float64)\n",
    "    dist_attr_c = np.ascontiguousarray(dist_attr, dtype=np.float64)\n",
    "    current_cost_matrix_c = np.ascontiguousarray(current_cost_matrix, dtype=np.float64)\n",
    "\n",
    "    cost_val = 0.0\n",
    "    if grid_edge_length * grid_edge_length > 1:\n",
    "        try:\n",
    "            _, cost_val = emd(dist_gt_c, dist_attr_c, current_cost_matrix_c, numItermax=200000, log=True)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    d_max = np.sqrt(2 * (grid_edge_length - 1)**2) if grid_edge_length > 1 else 0.0\n",
    "    if d_max == 0:\n",
    "        return 1.0 if np.isclose(cost_val, 0) else 0.0\n",
    "\n",
    "    return 1 - (cost_val['cost'] / d_max)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# (4) Main processing extended with redistribution + FNI terminology\n",
    "# --------------------------------------------------------------------\n",
    "def process_explanations_metrics_with_redistribution(\n",
    "    explanations_dict, gt_mask_main_flat, d_flat_main, d_edge_main, cost_mat_main,\n",
    "    fast_func_for_pairs  # function FAST to recover interaction pairs when needed\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes metrics in four variants:\n",
    "      - original (your current behavior)\n",
    "      - sum redistribution (64-D)\n",
    "      - weighted sum redistribution (64-D)\n",
    "      - max redistribution (64-D)\n",
    "\n",
    "    Returns nested dict: results[scenario_base][method][metric_variant]['IMA'|'EMD'|'FNI-EMD'] -> list of values,\n",
    "    and aggregated means/stds.\n",
    "    \"\"\"\n",
    "    # raw collections\n",
    "    results_raw = {}  # results_raw[scenario_base][method][variant]['IMA'|'EMD'|'FNI-EMD'] -> list\n",
    "\n",
    "    for scenario_full_name, methods_data in explanations_dict.items():\n",
    "        if 'translations' in scenario_full_name:\n",
    "            continue\n",
    "\n",
    "        parts = scenario_full_name.split('_')\n",
    "        try:\n",
    "            scenario_base_name = '_'.join(parts[:-1])\n",
    "        except ValueError:\n",
    "            scenario_base_name = scenario_full_name\n",
    "\n",
    "        # default: no interaction pairs\n",
    "        interaction_pairs_for_scenario = []\n",
    "        if 'xor' in scenario_full_name.lower():\n",
    "            # load training data to re-run FAST as you do\n",
    "            data_path = f'./data/xai_tris/{scenario_full_name}.pkl'\n",
    "            try:\n",
    "                with open(data_path, \"rb\") as f:\n",
    "                    data = pkl.load(f)\n",
    "                X_train_tensor = data.x_train.float()\n",
    "                y_train_tensor = data.y_train\n",
    "                interaction_pairs_for_scenario, _ = fast_func_for_pairs(\n",
    "                    X_train_tensor, y_train_tensor, n_interactions=128\n",
    "                )\n",
    "            except Exception:\n",
    "                interaction_pairs_for_scenario = []\n",
    "\n",
    "        if scenario_base_name not in results_raw:\n",
    "            results_raw[scenario_base_name] = {}\n",
    "\n",
    "        for method_name, explanation_content in methods_data.items():\n",
    "            if method_name not in results_raw[scenario_base_name]:\n",
    "                results_raw[scenario_base_name][method_name] = {\n",
    "                    'original': {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                    'sum':      {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                    'weighted': {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                    'max':      {'IMA': [], 'EMD': [], 'FNI-EMD': []},\n",
    "                }\n",
    "\n",
    "            # normalize explanation to 1D vector (global) or mean over samples\n",
    "            current_explanation = explanation_content\n",
    "            if isinstance(current_explanation, list):\n",
    "                current_explanation = np.array(current_explanation)\n",
    "\n",
    "            if not isinstance(current_explanation, np.ndarray):\n",
    "                # store NaNs for all four variants\n",
    "                for v in ['original','sum','weighted','max']:\n",
    "                    for m in ['IMA','EMD','FNI-EMD']:\n",
    "                        results_raw[scenario_base_name][method_name][v][m].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            if current_explanation.ndim > 1 and current_explanation.shape[0] > 1 and \\\n",
    "               not (current_explanation.shape[0] == d_flat_main and current_explanation.ndim == 2 and current_explanation.shape[1] == 1 and d_flat_main > 1):\n",
    "                if np.ndim(current_explanation[0]) == 3:\n",
    "                    processed_attr = np.mean(np.mean(np.array(current_explanation), axis=0).squeeze(), axis=0)\n",
    "                else:\n",
    "                    processed_attr = np.mean(np.vstack(current_explanation), axis=0)\n",
    "            else:\n",
    "                processed_attr = current_explanation.flatten()\n",
    "\n",
    "            # -----------------------\n",
    "            # (4a) ORIGINAL metrics\n",
    "            # -----------------------\n",
    "            # IMA: replicate your prior logic for GT construction per method\n",
    "            XOR_GT_MASK_MAIN_FLAT = np.zeros(D_FLAT, dtype=int)\n",
    "            \n",
    "            if method_name in ['pattern_gam', 'ebm', 'nam'] and 'xor' in scenario_full_name.lower():\n",
    "                gt_mask_for_ima = create_gt_mask_interactions_1d(XOR_GT_MASK_MAIN_FLAT, interaction_pairs_for_scenario, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            elif method_name == 'pattern_qlr':\n",
    "                gt_mask_for_ima = create_qlr_ground_truth_mask_1d(XOR_GT_MASK_MAIN_FLAT, d_flat_main)\n",
    "                attr_for_ima = processed_attr\n",
    "            else:\n",
    "                gt_mask_for_ima = gt_mask_main_flat\n",
    "                attr_for_ima = processed_attr[:d_flat_main]\n",
    "\n",
    "            if len(attr_for_ima) != len(gt_mask_for_ima):\n",
    "                tmp = np.zeros(len(gt_mask_for_ima))\n",
    "                n = min(len(attr_for_ima), len(gt_mask_for_ima))\n",
    "                tmp[:n] = attr_for_ima[:n]\n",
    "                attr_for_ima = tmp\n",
    "\n",
    "            ima_val = importance_mass_accuracy(gt_mask_for_ima, attr_for_ima)\n",
    "\n",
    "            # EMD/FNI-EMD on main effects only\n",
    "            attr_main_eff = processed_attr[:d_flat_main]\n",
    "            emd_val = np.nan\n",
    "            fni_emd_val = np.nan\n",
    "            if len(attr_main_eff) == d_flat_main and d_flat_main > 0:\n",
    "                emd_val = calculate_emd_score_metric(gt_mask_main_flat, attr_main_eff, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_emd_val = calculate_emd_score_metric(gt_mask_main_flat, attr_main_eff, d_edge_main, cost_mat_main, is_fni=True)\n",
    "\n",
    "            results_raw[scenario_base_name][method_name]['original']['IMA'].append(ima_val)\n",
    "            results_raw[scenario_base_name][method_name]['original']['EMD'].append(emd_val)\n",
    "            results_raw[scenario_base_name][method_name]['original']['FNI-EMD'].append(fni_emd_val)\n",
    "\n",
    "            # ---------------------------------------------------\n",
    "            # (4b) REDISTRIBUTIONS back to 64-D and 64-D metrics\n",
    "            # ---------------------------------------------------\n",
    "            # Decide interaction pairs for redistribution\n",
    "            # For QLR: pairs are upper-tri on 64-D (in the same order used to build z^QLR)\n",
    "            # For others: use FAST pairs when available.\n",
    "            pairs = []\n",
    "            d_expected = d_flat_main\n",
    "\n",
    "            if method_name == 'pattern_qlr':\n",
    "                pairs = qlr_pairs_upper_tri(d_expected)\n",
    "            else:\n",
    "                pairs = interaction_pairs_for_scenario\n",
    "\n",
    "            # make the pair list fit the tail length if mismatch\n",
    "            m_expected = len(pairs)\n",
    "            m_from_vec = max(0, len(processed_attr) - d_expected)\n",
    "            if m_from_vec <= 0:\n",
    "                # nothing to redistribute; fall back to plain 64-D main effects\n",
    "                red_sum = np.abs(processed_attr[:d_expected])\n",
    "                red_weighted = red_sum.copy()\n",
    "                red_max = red_sum.copy()\n",
    "            else:\n",
    "                if m_expected != m_from_vec:\n",
    "                    # trim or pad pairs (padding cannot invent structure -> trim to fit)\n",
    "                    pairs = pairs[:m_from_vec]\n",
    "                    m_expected = len(pairs)\n",
    "                    if d_expected + m_expected != len(processed_attr):\n",
    "                        # as a last resort, skip redistribution (use main effects only)\n",
    "                        red_sum = np.abs(processed_attr[:d_expected])\n",
    "                        red_weighted = red_sum.copy()\n",
    "                        red_max = red_sum.copy()\n",
    "                    else:\n",
    "                        red_sum = transform_interaction_sum(processed_attr, pairs, d=d_expected)\n",
    "                        red_weighted = transform_interaction_weighted_sum(processed_attr, pairs, d=d_expected)\n",
    "                        # max uses signed; convert to abs for metric parity\n",
    "                        red_max = transform_interaction_max_abs(processed_attr, pairs, d=d_expected)\n",
    "                else:\n",
    "                    red_sum = transform_interaction_sum(processed_attr, pairs, d=d_expected)\n",
    "                    red_weighted = transform_interaction_weighted_sum(processed_attr, pairs, d=d_expected)\n",
    "                    red_max = transform_interaction_max_abs(processed_attr, pairs, d=d_expected)\n",
    "\n",
    "            # Metrics on redistributed 64-D vectors\n",
    "            for variant_name, vattr in [('sum', red_sum), ('weighted', red_weighted), ('max', red_max)]:\n",
    "                ima_r = importance_mass_accuracy(gt_mask_main_flat, vattr)\n",
    "                emd_r = calculate_emd_score_metric(gt_mask_main_flat, vattr, d_edge_main, cost_mat_main, is_fni=False)\n",
    "                fni_r = calculate_emd_score_metric(gt_mask_main_flat, vattr, d_edge_main, cost_mat_main, is_fni=True)\n",
    "                results_raw[scenario_base_name][method_name][variant_name]['IMA'].append(ima_r)\n",
    "                results_raw[scenario_base_name][method_name][variant_name]['EMD'].append(emd_r)\n",
    "                results_raw[scenario_base_name][method_name][variant_name]['FNI-EMD'].append(fni_r)\n",
    "\n",
    "    # ----------------------\n",
    "    # aggregate mean / std\n",
    "    # ----------------------\n",
    "    aggregated = {}\n",
    "    for sc_base, meth_data in results_raw.items():\n",
    "        aggregated[sc_base] = {}\n",
    "        for meth, variants in meth_data.items():\n",
    "            aggregated[sc_base][meth] = {}\n",
    "            for variant, metric_lists in variants.items():\n",
    "                aggregated[sc_base][meth][variant] = {\n",
    "                    'IMA_mean': np.nanmean(metric_lists['IMA']) if metric_lists['IMA'] else np.nan,\n",
    "                    'IMA_std':  np.nanstd(metric_lists['IMA'])  if metric_lists['IMA'] else np.nan,\n",
    "                    'EMD_mean': np.nanmean(metric_lists['EMD']) if metric_lists['EMD'] else np.nan,\n",
    "                    'EMD_std':  np.nanstd(metric_lists['EMD'])  if metric_lists['EMD'] else np.nan,\n",
    "                    'FNI-EMD_mean': np.nanmean(metric_lists['FNI-EMD']) if metric_lists['FNI-EMD'] else np.nan,\n",
    "                    'FNI-EMD_std':  np.nanstd(metric_lists['FNI-EMD'])  if metric_lists['FNI-EMD'] else np.nan,\n",
    "                }\n",
    "    return results_raw, aggregated\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# (5) Pretty printing: compact tables per metric\n",
    "# --------------------------------------------------------\n",
    "def print_metric_tables(aggregated_results):\n",
    "    \"\"\"\n",
    "    For each scenario, prints three tables (IMA / EMD / FNI-EMD).\n",
    "    Rows: methods; Columns: original / sum / weighted / max as Mean  Std (4 decimals).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    for scenario_name, method_data in aggregated_results.items():\n",
    "        methods = sorted(method_data.keys())\n",
    "\n",
    "        # build per-metric dataframes\n",
    "        cols = ['original','sum','weighted','max']\n",
    "        def fmt(m, s):\n",
    "            if np.isnan(m) or np.isnan(s):\n",
    "                return \"nan\"\n",
    "            return f\"{m:.4f}  {s:.4f}\"\n",
    "\n",
    "        tables = {'IMA': [], 'EMD': [], 'FNI-EMD': []}\n",
    "        for meth in methods:\n",
    "            row_ima, row_emd, row_fni = [], [], []\n",
    "            for v in cols:\n",
    "                stats = method_data[meth][v]\n",
    "                row_ima.append(fmt(stats['IMA_mean'], stats['IMA_std']))\n",
    "                row_emd.append(fmt(stats['EMD_mean'], stats['EMD_std']))\n",
    "                row_fni.append(fmt(stats['FNI-EMD_mean'], stats['FNI-EMD_std']))\n",
    "            tables['IMA'].append(row_ima)\n",
    "            tables['EMD'].append(row_emd)\n",
    "            tables['FNI-EMD'].append(row_fni)\n",
    "\n",
    "        print(f\"\\n=== Scenario: {scenario_name} ===\")\n",
    "        df_ima = pd.DataFrame(tables['IMA'], index=methods, columns=cols)\n",
    "        df_emd = pd.DataFrame(tables['EMD'], index=methods, columns=cols)\n",
    "        df_fni = pd.DataFrame(tables['FNI-EMD'], index=methods, columns=cols)\n",
    "\n",
    "        print(\"\\nIMA (Importance Mass Accuracy):\")\n",
    "        print(df_ima.to_string())\n",
    "\n",
    "        print(\"\\nEMD:\")\n",
    "        print(df_emd.to_string())\n",
    "\n",
    "        print(\"\\nFNI-EMD:\")\n",
    "        print(df_fni.to_string())\n",
    "\n",
    "\n",
    "# ======================\n",
    "# ===== USAGE EXAMPLE ==\n",
    "# ======================\n",
    "# (Keep your existing configuration / GT / COST matrix creation as-is.)\n",
    "# Ensure the following are already defined in your script before this section:\n",
    "# - D_2D_EDGE, D_FLAT, GT_MASK_2D_FLAT, COST_MATRIX_MAIN_EFFECTS\n",
    "# - FAST (as provided), create_gt_mask_interactions_1d, create_qlr_ground_truth_mask_1d\n",
    "# - calculate_emd_score_metric (replaced above to use is_fni and 'FNI-EMD' naming)\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"D_2D_EDGE (grid edge for main effects): {D_2D_EDGE}\")\n",
    "print(f\"D_FLAT (total main effect features): {D_FLAT}\")\n",
    "print(f\"Sum of GT_MASK_2D_FLAT: {np.sum(GT_MASK_2D_FLAT)}\")\n",
    "print(f\"Cost matrix for main effects shape: {COST_MATRIX_MAIN_EFFECTS.shape}\")\n",
    "print(f\"--- Starting Metric Calculation (with redistribution) ---\")\n",
    "\n",
    "with open('./models/xai_tris/explanations_xor_dist_corr_std_qlr.pkl', \"rb\") as f:\n",
    "    explanations = pkl.load(f)\n",
    "\n",
    "# Compute\n",
    "results_raw_all, aggregated_all = process_explanations_metrics_with_redistribution(\n",
    "    explanations,\n",
    "    GT_MASK_2D_FLAT,\n",
    "    D_FLAT,\n",
    "    D_2D_EDGE,\n",
    "    COST_MATRIX_MAIN_EFFECTS,\n",
    "    FAST  # pass your FAST function for pair discovery\n",
    ")\n",
    "\n",
    "# Print compact tables per scenario\n",
    "print(\"\\n--- Aggregated Results (Original, Sum, Weighted, Max) ---\")\n",
    "print_metric_tables(aggregated_all)\n",
    "\n",
    "# ==== END ADDITIONS / REPLACEMENTS ====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6374998d-12a8-4d7e-a407-4e5377ba7c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated ===\n",
      "\n",
      "IMA:\n",
      "|               | Original (feature space)   | Sum (redistributed)   | Weighted sum (redistributed)   | Max (redistributed)   |\n",
      "|---------------|----------------------------|-----------------------|--------------------------------|-----------------------|\n",
      "| DISCR         | 0.1178  0.0273            | **0.8692  0.0238**   | 0.7617  0.0510                | **0.8956  0.0193**   |\n",
      "| PatternGAM    | 0.5688  0.0803            | 0.6537  0.0521       | 0.4889  0.1072                | 0.6180  0.0679       |\n",
      "| PatternQLR    | 0.2278  0.0385            | 0.4286  0.0132       | 0.3414  0.0063                | 0.5864  0.0835       |\n",
      "| KernelPattern | 0.1231  0.0520            | 0.1231  0.0520       | 0.1231  0.0520                | 0.1231  0.0520       |\n",
      "| PatternAttr   | **0.7687  0.1277**        | 0.7687  0.1277       | **0.7687  0.1277**            | 0.7687  0.1277       |\n",
      "| PatternNet    | 0.6141  0.1915            | 0.6141  0.1915       | 0.6141  0.1915                | 0.6141  0.1915       |\n",
      "| NAM           | 0.3641  0.0440            | 0.5350  0.0364       | 0.3663  0.0808                | 0.4708  0.0606       |\n",
      "| EBM           | 0.0304  0.0184            | 0.1441  0.0599       | 0.0784  0.0310                | 0.1187  0.0659       |\n",
      "| SHAP          | 0.4130  0.0354            | 0.4130  0.0354       | 0.4130  0.0354                | 0.4130  0.0354       |\n",
      "| IG            | 0.7278  0.0947            | 0.7278  0.0947       | 0.7278  0.0947                | 0.7278  0.0947       |\n",
      "\n",
      "EMD:\n",
      "|               | Original (feature space)   | Sum (redistributed)   | Weighted sum (redistributed)   | Max (redistributed)   |\n",
      "|---------------|----------------------------|-----------------------|--------------------------------|-----------------------|\n",
      "| DISCR         | 0.7986  0.0207            | **0.9457  0.0056**   | **0.9176  0.0182**            | **0.9430  0.0052**   |\n",
      "| PatternGAM    | 0.8095  0.0182            | 0.9203  0.0112       | 0.8816  0.0176                | 0.9144  0.0123       |\n",
      "| PatternQLR    | 0.7832  0.0221            | 0.8818  0.0092       | 0.8564  0.0100                | 0.9194  0.0219       |\n",
      "| KernelPattern | 0.7781  0.0351            | 0.7781  0.0351       | 0.7781  0.0351                | 0.7781  0.0351       |\n",
      "| PatternAttr   | **0.9095  0.0230**        | 0.9095  0.0230       | 0.9095  0.0230                | 0.9095  0.0230       |\n",
      "| PatternNet    | 0.8891  0.0687            | 0.8891  0.0687       | 0.8891  0.0687                | 0.8891  0.0687       |\n",
      "| NAM           | 0.8256  0.0312            | 0.8918  0.0115       | 0.8687  0.0137                | 0.8779  0.0144       |\n",
      "| EBM           | 0.8151  0.0017            | 0.7888  0.0304       | 0.7700  0.0186                | 0.7796  0.0325       |\n",
      "| SHAP          | 0.8734  0.0237            | 0.8734  0.0237       | 0.8734  0.0237                | 0.8734  0.0237       |\n",
      "| IG            | 0.8995  0.0460            | 0.8995  0.0460       | 0.8995  0.0460                | 0.8995  0.0460       |\n",
      "\n",
      "FNI-EMD:\n",
      "|               | Original (feature space)   | Sum (redistributed)   | Weighted sum (redistributed)   | Max (redistributed)   |\n",
      "|---------------|----------------------------|-----------------------|--------------------------------|-----------------------|\n",
      "| DISCR         | 0.8052  0.0216            | **0.9729  0.0065**   | 0.9516  0.0112                | **0.9790  0.0046**   |\n",
      "| PatternGAM    | 0.8196  0.0202            | 0.9308  0.0096       | 0.8970  0.0196                | 0.9250  0.0133       |\n",
      "| PatternQLR    | 0.7941  0.0250            | 0.8908  0.0052       | 0.8679  0.0087                | 0.9260  0.0210       |\n",
      "| KernelPattern | 0.7869  0.0377            | 0.7869  0.0377       | 0.7869  0.0377                | 0.7869  0.0377       |\n",
      "| PatternAttr   | **0.9603  0.0289**        | 0.9603  0.0289       | **0.9603  0.0289**            | 0.9603  0.0289       |\n",
      "| PatternNet    | 0.9235  0.0400            | 0.9235  0.0400       | 0.9235  0.0400                | 0.9235  0.0400       |\n",
      "| NAM           | 0.8414  0.0304            | 0.9150  0.0127       | 0.8853  0.0125                | 0.9058  0.0167       |\n",
      "| EBM           | 0.8213  0.0017            | 0.8129  0.0270       | 0.7850  0.0229                | 0.8009  0.0317       |\n",
      "| SHAP          | 0.9112  0.0105            | 0.9112  0.0105       | 0.9112  0.0105                | 0.9112  0.0105       |\n",
      "| IG            | 0.9580  0.0128            | 0.9580  0.0128       | 0.9580  0.0128                | 0.9580  0.0128       |\n",
      "Saved: {'IMA': {'html': './table_exports/xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_IMA.html'}, 'EMD': {'html': './table_exports/xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_EMD.html'}, 'FNI-EMD': {'html': './table_exports/xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated_FNI-EMD.html'}}\n"
     ]
    }
   ],
   "source": [
    "# ======= Pretty tables with ordering, renaming, bolding, and exports =======\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Methods: order + pretty names \n",
    "METHOD_ORDER = [\n",
    "    \"discr\", \"pattern_gam\", \"pattern_qlr\", \"kernel_svm\", \n",
    "    \"pattern_attribution\", \"pattern_net\", \"nam\", \"ebm\", \"shap\", \"ig\"\n",
    "]\n",
    "\n",
    "PRETTY_NAME = {\n",
    "    \"discr\": \"DISCR\",\n",
    "    \"kernel_svm\": \"KernelPattern\",\n",
    "    \"shap\": \"SHAP\",\n",
    "    \"ig\": \"IG\",\n",
    "    \"pattern_attribution\": \"PatternAttr\",\n",
    "    \"pattern_net\": \"PatternNet\",\n",
    "    \"nam\": \"NAM\",\n",
    "    \"ebm\": \"EBM\",\n",
    "    \"pattern_gam\": \"PatternGAM\",\n",
    "    \"pattern_qlr\": \"PatternQLR\",\n",
    "}\n",
    "\n",
    "COL_SPECS = [\n",
    "    (\"original\", \"Original (feature space)\"),\n",
    "    (\"sum\",      \"Sum (redistributed)\"),\n",
    "    (\"weighted\", \"Weighted sum (redistributed)\"),\n",
    "    (\"max\",      \"Max (redistributed)\"),\n",
    "]\n",
    "# If you want a different order or subset, just reorder/remove tuples above.\n",
    "# Example:\n",
    "# COL_SPECS = [(\"sum\",\"Sum\"), (\"weighted\",\"Weighted\"), (\"max\",\"Max\"), (\"original\",\"Original\")]\n",
    "\n",
    "COL_ORDER = [\"original\", \"sum\", \"weighted\", \"max\"] \n",
    "\n",
    "\n",
    "METRICS = [\"IMA\", \"EMD\", \"FNI-EMD\"]    \n",
    "\n",
    "def _fmt_cell(mean, std):\n",
    "    if np.isnan(mean) or np.isnan(std):\n",
    "        return \"nan\"\n",
    "    return f\"{mean:.4f}  {std:.4f}\"\n",
    "\n",
    "def _bold_winners_as_markdown(df_means, df_strings):\n",
    "    \"\"\"\n",
    "    Bold the max value per column in df_strings (string cells), using df_means (numeric) to decide winners.\n",
    "    Ties: bold all tied maxima.\n",
    "    \"\"\"\n",
    "    out = df_strings.copy()\n",
    "    for col in df_means.columns:\n",
    "        col_vals = df_means[col]\n",
    "        if col_vals.isna().all():\n",
    "            continue\n",
    "        max_val = np.nanmax(col_vals.values.astype(float))\n",
    "        winners = (np.abs(col_vals - max_val) < 1e-12)  # tie-safe\n",
    "        for idx in df_means.index[winners]:\n",
    "            out.loc[idx, col] = f\"**{out.loc[idx, col]}**\"\n",
    "    return out\n",
    "\n",
    "def _styler_from_strings_and_means(df_strings, df_means, caption=None):\n",
    "    \"\"\"\n",
    "    Create a pandas Styler that shows df_strings but bolds the winners from df_means.\n",
    "    \"\"\"\n",
    "    # build boolean mask for winners\n",
    "    mask = pd.DataFrame(False, index=df_means.index, columns=df_means.columns)\n",
    "    for col in df_means.columns:\n",
    "        col_vals = df_means[col]\n",
    "        if col_vals.isna().all():\n",
    "            continue\n",
    "        m = np.nanmax(col_vals.values.astype(float))\n",
    "        mask[col] = (np.abs(col_vals - m) < 1e-12)\n",
    "\n",
    "    def bold_mask(s):\n",
    "        return ['font-weight: bold' if m else '' for m in mask[s.name]]\n",
    "\n",
    "    sty = (df_strings.style\n",
    "           .apply(bold_mask, axis=0)\n",
    "           .set_properties(**{\"white-space\": \"nowrap\"})\n",
    "           .set_table_styles([\n",
    "               {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "               {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\"), (\"padding\", \"6px 10px\")]},\n",
    "               {\"selector\": \"caption\", \"props\": [(\"caption-side\", \"top\"), (\"font-weight\", \"bold\"), (\"margin-bottom\", \"8px\")]}\n",
    "           ])\n",
    "          )\n",
    "    if caption:\n",
    "        sty = sty.set_caption(caption)\n",
    "    return sty\n",
    "\n",
    "def build_tables_for_scenario(method_data, method_order, pretty_map, col_specs):\n",
    "    \"\"\"\n",
    "    col_specs: list of (internal_key, pretty_label)\n",
    "    \"\"\"\n",
    "    methods_present = [m for m in method_order if m in method_data]\n",
    "    pretty_index = [pretty_map.get(m, m) for m in methods_present]\n",
    "\n",
    "    # Split specs into internal keys (used to fetch stats) and labels (shown in table)\n",
    "    col_keys   = [k for k, _ in col_specs]\n",
    "    col_labels = [l for _, l in col_specs]\n",
    "\n",
    "    per_metric = {}\n",
    "    for metric in METRICS:\n",
    "        means = []\n",
    "        stds  = []\n",
    "        for m in methods_present:\n",
    "            row_means, row_stds = [], []\n",
    "            for ckey in col_keys:\n",
    "                stats = method_data[m][ckey]\n",
    "                mean_key = f\"{metric}_mean\" if metric != \"FNI-EMD\" else \"FNI-EMD_mean\"\n",
    "                std_key  = f\"{metric}_std\"  if metric != \"FNI-EMD\" else \"FNI-EMD_std\"\n",
    "                row_means.append(stats.get(mean_key, np.nan))\n",
    "                row_stds.append(stats.get(std_key, np.nan))\n",
    "            means.append(row_means)\n",
    "            stds.append(row_stds)\n",
    "\n",
    "        # Use pretty labels as the displayed column headers\n",
    "        df_means = pd.DataFrame(means, index=pretty_index, columns=col_labels, dtype=float)\n",
    "        df_stds  = pd.DataFrame(stds,  index=pretty_index, columns=col_labels, dtype=float)\n",
    "\n",
    "        # Format\n",
    "        df_fmt = pd.DataFrame(index=pretty_index, columns=col_labels, dtype=object)\n",
    "        for i in df_fmt.index:\n",
    "            for j in df_fmt.columns:\n",
    "                df_fmt.loc[i, j] = _fmt_cell(df_means.loc[i, j], df_stds.loc[i, j])\n",
    "\n",
    "        # Bold winners by comparing numeric df_means; labels are fine here\n",
    "        df_fmt_bold_md = _bold_winners_as_markdown(df_means, df_fmt)\n",
    "        styler = _styler_from_strings_and_means(df_fmt, df_means, caption=f\"{metric}\")\n",
    "\n",
    "        per_metric[metric] = {\n",
    "            \"df_means\": df_means, \"df_stds\": df_stds,\n",
    "            \"df_fmt\": df_fmt, \"df_fmt_bold_md\": df_fmt_bold_md,\n",
    "            \"styler\": styler\n",
    "        }\n",
    "    return per_metric\n",
    "\n",
    "\n",
    "def export_tables(per_metric, out_dir=None, fname_prefix=\"\", to_png=False):\n",
    "    \"\"\"\n",
    "    Save HTML (and optional PNG if dataframe_image is available) for each metric table.\n",
    "    Returns dict of saved paths.\n",
    "    \"\"\"\n",
    "    saved = {}\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        try:\n",
    "            import dataframe_image as dfi\n",
    "            have_dfi = True\n",
    "        except Exception:\n",
    "            have_dfi = False\n",
    "\n",
    "        for metric, bundle in per_metric.items():\n",
    "            sty = bundle[\"styler\"]\n",
    "            html_path = os.path.join(out_dir, f\"{fname_prefix}{metric}.html\")\n",
    "            with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(sty.to_html())\n",
    "            saved[metric] = {\"html\": html_path}\n",
    "\n",
    "            if to_png:\n",
    "                if have_dfi:\n",
    "                    png_path = os.path.join(out_dir, f\"{fname_prefix}{metric}.png\")\n",
    "                    dfi.export(sty, png_path)   # requires chrome or wkhtmltopdf depending on backend\n",
    "                    saved[metric][\"png\"] = png_path\n",
    "                else:\n",
    "                    print(\"Note: dataframe_image not installed; skipping PNG export.\")\n",
    "    return saved\n",
    "\n",
    "# -------------------------\n",
    "# EXAMPLE USAGE:\n",
    "# -------------------------\n",
    "# aggregated_all is what you already computed earlier.\n",
    "\n",
    "for scenario_name, method_data in aggregated_all.items():\n",
    "    per_metric = build_tables_for_scenario(\n",
    "        method_data,\n",
    "        method_order=METHOD_ORDER,\n",
    "        pretty_map=PRETTY_NAME,\n",
    "        col_specs=COL_SPECS,     # < here\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {scenario_name} ===\")\n",
    "    for metric in METRICS:\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(per_metric[metric][\"df_fmt_bold_md\"].to_markdown(tablefmt=\"github\"))\n",
    "\n",
    "    ### Optionally export nice HTML/PNG for email or slides\n",
    "    saved_paths = export_tables(per_metric, out_dir=\"./table_exports\",\n",
    "                                fname_prefix=f\"{scenario_name}_\", to_png=False)\n",
    "    print(\"Saved:\", saved_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb17da1e-7563-458d-8ad4-64fd64df167a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1941484341.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    --- Aggregated Results (Original, Sum, Weighted, Max) ---\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "--- Aggregated Results (Original, Sum, Weighted, Max) ---\n",
    "\n",
    "=== Scenario: xor_distractor_additive_1d1p_0.20_0.40_0.40_correlated ===\n",
    "\n",
    "IMA (Importance Mass Accuracy):\n",
    "                            original              sum         weighted              max\n",
    "discr                0.1178  0.0273  0.8692  0.0238  0.7617  0.0510  0.8956  0.0193\n",
    "ebm                  0.0336  0.0179  0.1441  0.0599  0.0784  0.0310  0.1187  0.0659\n",
    "ig                   0.7278  0.0947  0.7278  0.0947  0.7278  0.0947  0.7278  0.0947\n",
    "kernel_svm           0.1231  0.0520  0.1231  0.0520  0.1231  0.0520  0.1231  0.0520\n",
    "nam                  0.4062  0.0549  0.5350  0.0364  0.3663  0.0808  0.4708  0.0606\n",
    "pattern_attribution  0.7687  0.1277  0.7687  0.1277  0.7687  0.1277  0.7687  0.1277\n",
    "pattern_gam          0.5973  0.0788  0.6537  0.0521  0.4889  0.1072  0.6180  0.0679\n",
    "pattern_net          0.6141  0.1915  0.6141  0.1915  0.6141  0.1915  0.6141  0.1915\n",
    "pattern_qlr          0.2422  0.0334  0.4286  0.0132  0.3414  0.0063  0.5864  0.0835\n",
    "shap                 0.4130  0.0354  0.4130  0.0354  0.4130  0.0354  0.4130  0.0354\n",
    "\n",
    "EMD:\n",
    "                            original              sum         weighted              max\n",
    "discr                0.7986  0.0207  0.9457  0.0056  0.9176  0.0182  0.9430  0.0052\n",
    "ebm                  0.8151  0.0017  0.7888  0.0304  0.7700  0.0186  0.7796  0.0325\n",
    "ig                   0.8995  0.0460  0.8995  0.0460  0.8995  0.0460  0.8995  0.0460\n",
    "kernel_svm           0.7781  0.0351  0.7781  0.0351  0.7781  0.0351  0.7781  0.0351\n",
    "nam                  0.8256  0.0312  0.8918  0.0115  0.8687  0.0137  0.8779  0.0144\n",
    "pattern_attribution  0.9095  0.0230  0.9095  0.0230  0.9095  0.0230  0.9095  0.0230\n",
    "pattern_gam          0.8095  0.0182  0.9203  0.0112  0.8816  0.0176  0.9144  0.0123\n",
    "pattern_net          0.8891  0.0687  0.8891  0.0687  0.8891  0.0687  0.8891  0.0687\n",
    "pattern_qlr          0.7832  0.0221  0.8818  0.0092  0.8564  0.0100  0.9194  0.0219\n",
    "shap                 0.8734  0.0237  0.8734  0.0237  0.8734  0.0237  0.8734  0.0237\n",
    "\n",
    "FNI-EMD:\n",
    "                            original              sum         weighted              max\n",
    "discr                0.8052  0.0216  0.9729  0.0065  0.9516  0.0112  0.9790  0.0046\n",
    "ebm                  0.8213  0.0017  0.8129  0.0270  0.7850  0.0229  0.8009  0.0317\n",
    "ig                   0.9580  0.0128  0.9580  0.0128  0.9580  0.0128  0.9580  0.0128\n",
    "kernel_svm           0.7869  0.0377  0.7869  0.0377  0.7869  0.0377  0.7869  0.0377\n",
    "nam                  0.8414  0.0304  0.9150  0.0127  0.8853  0.0125  0.9058  0.0167\n",
    "pattern_attribution  0.9603  0.0289  0.9603  0.0289  0.9603  0.0289  0.9603  0.0289\n",
    "pattern_gam          0.8196  0.0202  0.9308  0.0096  0.8970  0.0196  0.9250  0.0133\n",
    "pattern_net          0.9235  0.0400  0.9235  0.0400  0.9235  0.0400  0.9235  0.0400\n",
    "pattern_qlr          0.7941  0.0250  0.8908  0.0052  0.8679  0.0087  0.9260  0.0210\n",
    "shap                 0.9112  0.0105  0.9112  0.0105  0.9112  0.0105  0.9112  0.0105"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
